<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Welcome to Junlei&#39;s word!</title>
  
  
  <link href="http://junlei-zhou.com/atom.xml" rel="self"/>
  
  <link href="http://junlei-zhou.com/"/>
  <updated>2025-04-03T10:54:42.377Z</updated>
  <id>http://junlei-zhou.com/</id>
  
  <author>
    <name>坚竹韧周</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Diffusion-Interviews</title>
    <link href="http://junlei-zhou.com/2025/04/03/Diffusion-Interviews/"/>
    <id>http://junlei-zhou.com/2025/04/03/Diffusion-Interviews/</id>
    <published>2025-04-03T10:53:07.000Z</published>
    <updated>2025-04-03T10:54:42.377Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h3 id="生成对抗网络gans请解释gans是什么以及它们的构成要素">1.生成对抗网络（GANs）：请解释GANs是什么，以及它们的构成要素</h3><p>生成对抗网络（Generative Adversarial Networks，简称GAN）是一种深度学习模型，由 Ian Goodfellow等人受<strong>零和博弈</strong>的思想在 2014年提出。其核心思想是通过训练两个相互竞争的神经网络——生成器（Generator）和判别器（Discriminator）——来生成与真实数据相似的新数据。</p><p><strong>构成要素：</strong></p><ol type="1"><li><strong>生成器（Generator）：</strong>生成器的任务是接收随机噪声作为输入，并将其转换为具有真实数据分布特征的伪造数据。其目标是生成足够逼真的数据，以欺骗判别器，使其无法区分生成的数据和真实数据。</li><li><strong>判别器（Discriminator）：</strong>判别器的任务是区分输入数据是真实的还是由生成器生成的伪造数据。它接受一组数据作为输入，并输出一个概率值，表示该数据为真实数据的可能性。判别器通过不断学习，提高对真实和伪造数据的辨别能力。</li></ol><p><strong>工作原理：</strong></p><p>GAN 的训练过程可以视为生成器和判别器之间的“博弈”：</p><ul><li><strong>生成器</strong>尝试生成逼真的数据，以欺骗判别器。</li><li><strong>判别器</strong>则努力提高其辨别能力，准确区分真实数据和生成的数据。</li></ul><p>这种相互对抗的训练方式促使生成器不断提升其生成数据的质量，最终达到以假乱真的效果。</p><blockquote><p>GAN理论上能够完美捕捉训练样本的分布。然而，训练生成对抗网络（GANs）直到它们达到<strong>纳什均衡</strong>是难以保证的，因为梯度下降只是有时确保生成器和判别器会收敛到这样的均衡，使得GANs在训练期间比变分自编码器（VAEs）更不稳定。此外，GANs在生成离散数据方面存在困难，并且解释性较差，导致研究人员探索新的生成算法。</p><p><strong>零和博弈：</strong></p><p>零和博弈（Zero-sumGame）是博弈论中的一个概念，指在参与博弈的各方中，一方的收益必然导致另一方的损失，即所有参与者的收益和损失相加总和为零。在这种博弈中，参与者之间的利益是完全对立的，无法通过合作实现共赢。典型的例子包括赌博、期货交易和选举等。</p><p><strong>纳什均衡：</strong></p><p>纳什均衡（NashEquilibrium）是指在一个包含两个或以上参与者的非合作博弈中，假设每个参与者都知道其他参与者的策略且保持不变的情况下，没有任何参与者可以通过单方面改变自身策略而获得更大利益。换言之，在纳什均衡状态下，每个参与者的策略都是对其他参与者策略的最佳回应。经典的例子是“囚徒困境”，其中两个囚犯在无法沟通的情况下，各自选择对自己最有利的策略，最终导致双方都处于次优的结果。</p></blockquote><h3 id="评估gan生成图像的质量你如何衡量gan生成图像的质量">2.评估GAN生成图像的质量：你如何衡量GAN生成图像的质量？</h3><p>评估生成对抗网络（GAN）生成图像的质量是确保模型性能的关键环节。常用的评估方法主要分为以下几类：</p><p><strong>1. 基于分类模型的指标：</strong></p><ul><li><p><strong>Inception Score（IS）：</strong> IS 利用预训练的Inception V3 模型评估生成图像的质量和多样性。具体而言，IS计算生成图像的条件标签分布 $p(y|x) $的熵和边际分布 <span class="math inline">\(p(y)\)</span> 的熵之间的 KL 散度。较高的 IS值通常表示生成图像既清晰又多样。然而，IS仅依赖于特定的分类模型，可能无法全面反映图像质量。</p><p><span class="math inline">\(IS = \exp \left( \mathbb{E}_x \left[D_{KL}(p(y|x) \parallel p(y)) \right] \right)\)</span></p><p>其中：</p><ul><li><span class="math inline">\(p(y|x)\)</span> 是 Inception模型对生成图像 x 的类别预测分布。</li><li><span class="math inline">\(p(y)\)</span>是所有生成图像的类别预测的边际分布。</li><li><span class="math inline">\(D_{KL}\)</span> 表示 Kullback-Leibler散度，用于衡量两个分布之间的差异。</li><li><span class="math inline">\(\mathbb{E}_x\)</span>表示对所有生成图像取期望。</li></ul><p>IS 值越高，表示生成图像的质量和多样性越好。</p></li><li><p><strong>Fréchet Inception Distance（FID）：</strong> FID通过比较生成图像和真实图像在 Inception网络特征空间的分布，评估两者的相似度。FID 计算两组图像特征分布之间的Fréchet 距离，值越小表示生成图像与真实图像越相似。FID 被广泛认为比 IS更能准确反映图像质量和多样性。</p><p><span class="math inline">\(FID = \|\mu_r - \mu_g\|^2 +\mathrm{Tr}(\Sigma_r + \Sigma_g - 2\sqrt{\Sigma_r\Sigma_g})\)</span></p><p>其中：</p><ul><li><span class="math inline">\(\mu_r\)</span> 和 <span class="math inline">\(\mu_g\)</span>分别是真实图像和生成图像特征的均值向量。</li><li><span class="math inline">\(\Sigma_r\)</span> 和 <span class="math inline">\(\Sigma_g\)</span>分别是真实图像和生成图像特征的协方差矩阵。</li><li><span class="math inline">\(\mathrm{Tr}\)</span>表示矩阵的迹（对角线元素之和）。</li></ul><p>FID 值越低，表示生成图像的质量越接近真实图像。</p></li></ul><p><strong>2. 基于图像质量的指标：</strong></p><ul><li><p><strong>结构相似性指数（SSIM）：</strong> SSIM通过比较两幅图像的亮度、对比度和结构信息，衡量它们的相似度。SSIM值范围从 -1 到 1，值越接近 1 表示两幅图像越相似。在评估 GAN生成图像时，SSIM 可用于衡量生成图像与参考图像之间的相似度。</p><p><span class="math inline">\(SSIM(x, y) = \frac{(2\mu_x\mu_y +C_1)(2\sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 +\sigma_y^2 + C_2)}\)</span></p><p>其中：</p><ul><li><span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span> 是两幅图像。</li><li><span class="math inline">\(\mu_x\)</span> 和 <span class="math inline">\(\mu_y\)</span> 分别是图像 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span> 的平均亮度。</li><li><span class="math inline">\(\sigma_x^2\)</span> 和 <span class="math inline">\(\sigma_y^2\)</span> 分别是图像 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span> 的方差。</li><li><span class="math inline">\(\sigma_{xy}\)</span> 是图像 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span> 之间的协方差。</li><li><span class="math inline">\(C_1\)</span> 和 <span class="math inline">\(C_2\)</span>是用于稳定计算的小常数，防止分母为零。</li></ul><p>SSIM 值范围为 [-1, 1]，值越接近 1，表示两幅图像越相似。</p></li><li><p><strong>峰值信噪比（PSNR）：</strong> PSNR衡量生成图像与参考图像之间的像素级差异，通常用于评估图像重建质量。PSNR值越高，表示两幅图像越相似。然而，PSNR主要关注像素级差异，可能无法充分反映感知质量。</p><p><span class="math inline">\(PSNR = 10 \cdot \log_{10} \left(\frac{\text{MAX}^2}{\text{MSE}} \right)\)</span></p><p>其中：</p><ul><li>MAX 是图像像素值的最大可能取值（对于 8 位图像，通常为 255）。</li><li>MSE 是均方误差，计算两幅图像对应像素差值的平方的平均值。</li></ul></li><li><p><strong>感知相似度（LPIPS）：</strong> LPIPS通过计算深度学习模型提取的特征之间的距离，评估两幅图像在感知上的相似度。LPIPS值越小，表示两幅图像在感知上越相似。</p></li></ul><p><strong>3. 基于统计学的指标：</strong></p><ul><li><strong>最大平均差异（MMD）：</strong> MMD衡量两个分布之间的距离，可用于评估生成图像与真实图像分布的一致性。较小的MMD 值表示两者分布更为相似。</li></ul><p><strong>4. 基于人类感知的评估：</strong></p><ul><li><strong>主观评估：</strong>邀请人类评估者对生成图像的质量进行评分，通常采用均方根误差（MOS）等方法。这种方法直接反映人类对图像质量的感知，但耗时且主观性强。</li></ul><h3 id="扩散模型与gansvaeflow的比较扩散模型和gansvaeflow在生成图像方面有何不同">3.扩散模型与GANs、VAE、Flow的比较：扩散模型和GANs、VAE、Flow在生成图像方面有何不同？</h3><p>在图像生成领域，<strong>扩散模型</strong>、<strong>生成对抗网络（GANs）</strong>、<strong>变分自编码器（VAE）</strong>和 <strong>流模型（Flow）</strong>是四种主要的生成模型，它们在生成图像的方式和特性上各有不同。</p><p><strong>1. 扩散模型（Diffusion Models）：</strong></p><ul><li><p><strong>原理：</strong>扩散模型受非平衡热力学启发，通过定义一个扩散过程的马尔可夫链，逐渐向数据添加随机噪声，然后学习逆扩散过程，从噪声中重构所需的数据样本。</p></li><li><p><strong>优点：</strong></p><p>✅<strong>高质量生成</strong>：能够生成极高质量的图像，保留丰富的细节，与真实数据非常接近。✅ <strong>稳定训练</strong>：相较于 GANs，不存在模式崩溃（modecollapse）问题。 ✅<strong>良好的概率估计</strong>：学习的是明确的概率密度，可以直接进行采样和插值。✅<strong>生成过程可控</strong>：可以使用条件扩散（如控制图像风格、类别）来提高生成的可控性。</p></li><li><p><strong>缺点：</strong></p><p>❌<strong>计算成本高</strong>：采样过程通常需要多步（上千次迭代），导致推理速度慢。❌<strong>存储需求大</strong>：训练时需要存储大量的去噪过程，计算和存储成本高。❌ <strong>训练时间长</strong>：相比 GANs 和VAE，训练时间更长。</p></li></ul><p><strong>2. 生成对抗网络（GANs）：</strong></p><ul><li><p><strong>原理：</strong> GAN由生成器和判别器两个模型组成。生成器负责生成尽可能接近真实数据的虚假样本，判别器则从生成器产生的样本中区分出真实数据。这两个模型通过最大最小博弈的方式同时训练。</p></li><li><p><strong>优点：</strong></p><p>✅<strong>生成速度快</strong>：一次前向传播即可生成图像，相比扩散模型更高效。✅<strong>高质量图像</strong>：可以生成非常逼真的图像，特别适用于图像超分辨率、风格转换等任务。✅<strong>广泛应用</strong>：在多种图像合成、视频生成、艺术创作等场景取得成功。</p></li><li><p><strong>缺点：</strong></p><p>❌ <strong>模式崩溃（ModeCollapse）</strong>：可能仅生成某些特定模式，而忽略数据的完整分布。 ❌<strong>训练不稳定</strong>：生成器和判别器之间的博弈可能导致梯度消失或梯度爆炸，调参较难。❌ <strong>难以计算明确的概率密度</strong>：GANs主要基于对抗损失优化，而不是明确学习数据的概率密度，导致缺乏概率可解释性。</p></li></ul><p><strong>3. 变分自编码器（VAE）：</strong></p><ul><li><p><strong>原理：</strong> VAE通过最大化证据下限（ELBO），不明确地优化了数据的对数可能性。</p></li><li><p><strong>优点：</strong></p><p>✅ <strong>训练稳定</strong>：损失函数具有明确的数学意义，不存在 GANs的对抗训练不稳定问题。 ✅<strong>概率建模</strong>：直接学习数据的概率密度，可以进行潜空间操作，如数据插值、风格迁移等。✅ <strong>易于优化</strong>：不需要像 GANs那样精细调整训练策略。</p></li><li><p><strong>缺点：</strong> 生成的样本可能不如 GAN那样逼真，且依赖于替代损失（surrogate loss）。</p><p>❌ <strong>生成图像质量较差</strong>：生成图像通常比 GANs和扩散模型模糊，细节较少。 ❌<strong>存在样本模糊问题</strong>：使用高斯分布进行潜变量建模，可能导致过度平滑的生成结果。❌ <strong>可能存在 KL 散度塌陷</strong>：如果 KL 散度项过强，可能导致VAE 生成的样本过于接近先验分布，而缺乏足够的多样性。</p></li></ul><p><strong>4. 流模型（Flow Models）：</strong></p><ul><li><p><strong>原理：</strong>流模型是一种基于可逆变换的深度生成模型，通过一系列可逆的变换，将简单分布（如均匀分布或正态分布）转换为复杂的数据分布。</p></li><li><p><strong>优点：</strong>可以高效地进行样本生成和密度估计，具有可逆性，便于反向传播和优化。</p><p>✅<strong>可逆变换</strong>：每一步变换都是可逆的，能够进行精确的概率密度估计。✅ <strong>稳定训练</strong>：相比 GANs，没有对抗训练的梯度问题。 ✅<strong>生成过程快</strong>：相比扩散模型，流模型可以快速生成样本。 ✅<strong>适用于密度建模</strong>：在概率密度建模任务（如语音合成、图像建模）上有优势。</p></li><li><p><strong>缺点：</strong>设计合适的可逆变换可能具有挑战性，对于高维数据，流模型可能难以捕捉到复杂的依赖关系。</p><p>❌<strong>存储和计算开销大</strong>：每一层的变换必须是可逆的，导致模型通常需要较大的存储空间和计算资源。❌<strong>难以捕捉复杂模式</strong>：由于每一层变换都是严格可逆的，可能导致对数据的建模能力受限。❌<strong>生成质量受限</strong>：在高分辨率图像上，流模型的生成质量通常不如GANs 或扩散模型。</p></li></ul><table><colgroup><col style="width: 12%"><col style="width: 12%"><col style="width: 14%"><col style="width: 12%"><col style="width: 16%"><col style="width: 12%"><col style="width: 20%"></colgroup><thead><tr class="header"><th><strong>模型</strong></th><th><strong>图像质量</strong></th><th><strong>训练稳定性</strong></th><th><strong>生成速度</strong></th><th><strong>概率密度估计</strong></th><th><strong>计算成本</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr class="odd"><td><strong>扩散模型</strong></td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐</td><td>⭐⭐⭐⭐⭐</td><td>❌ 高</td><td>高质量图像生成、去噪</td></tr><tr class="even"><td><strong>GANs</strong></td><td>⭐⭐⭐⭐⭐</td><td>❌ 训练不稳定</td><td>⭐⭐⭐⭐⭐</td><td>❌ 无概率密度</td><td>⭐⭐⭐</td><td>超写实图像合成</td></tr><tr class="odd"><td><strong>VAE</strong></td><td>⭐⭐⭐</td><td>⭐⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐</td><td>图像编码、风格迁移</td></tr><tr class="even"><td><strong>Flow</strong></td><td>⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐</td><td>⭐⭐⭐⭐⭐</td><td>❌ 高</td><td>密度估计、数据建模</td></tr></tbody></table><h3 id="处理gans的模式崩溃问题为什么gans会出现模式崩溃在训练gans时你如何避免模式崩溃">4.处理GANs的模式崩溃问题：为什么GANs会出现模式崩溃，在训练GANs时，你如何避免模式崩溃？</h3><p>模式崩溃是指 <strong>GANs生成器仅能生成某些有限模式的样本，而无法覆盖完整的真实数据分布</strong>。其主要原因包括：</p><p><strong>对抗训练不稳定</strong></p><ul><li>生成器和判别器之间的训练过程是一个动态博弈（min-maxoptimization），如果优化不平衡（例如，判别器过强或生成器过强），训练可能会陷入局部最优，使生成器无法学习完整的数据分布。</li></ul><p><strong>梯度消失或梯度爆炸</strong></p><ul><li>在传统 GAN的交叉熵损失下，如果判别器训练得太强，生成器的梯度可能会趋近于0，导致学习停滞（梯度消失）。</li><li>反之，如果训练参数选择不当，梯度可能过大，导致训练不稳定（梯度爆炸）。</li></ul><p><strong>生成器探索空间受限</strong></p><ul><li>生成器优化过程中可能会发现某些容易欺骗判别器的模式，并持续生成相似样本，而不去探索完整的数据分布。</li></ul><p><strong>Batch Normalization 的副作用</strong></p><ul><li>在某些情况下，Batch Normalization 可能会导致生成器在 batch级别形成相似的输出，减少样本多样性，进而加剧模式崩溃。</li></ul><hr><p>为了解决模式崩溃问题，可以采用以下策略：</p><p><strong>1. 改进损失函数</strong></p><ul><li><strong>Wasserstein GAN（WGAN）</strong><ul><li>采用 <strong>Wasserstein 距离</strong>（Earth Mover's Distance,EMD），避免标准 GAN 交叉熵损失带来的梯度消失问题。</li><li>WGAN中，判别器（Critic）不输出概率，而是直接输出一个分数，用于衡量生成分布与真实分布的距离。</li><li>WGAN 需要加入权重裁剪（weight clipping）或梯度惩罚（gradientpenalty）来保证训练稳定性。</li></ul></li><li><strong>LS-GAN（Least Squares GAN）</strong><ul><li>使用最小二乘损失（Least SquaresLoss）替代交叉熵损失，可以提供更稳定的梯度，避免梯度消失。</li></ul></li></ul><p><strong>2. 引入正则化方法</strong></p><ul><li><strong>梯度惩罚（Gradient Penalty, GP）</strong><ul><li>在 WGAN-GP（Wasserstein GAN with GradientPenalty）中，额外加入梯度惩罚，约束判别器的梯度变化，保持稳定优化。</li></ul></li><li><strong>谱归一化（Spectral Normalization）</strong><ul><li>在判别器中加入 Spectral Normalization约束权重，避免判别器过强，防止模式崩溃。</li></ul></li></ul><p><strong>3. 采用更强的训练技巧</strong></p><ul><li><strong>Minibatch Discrimination</strong><ul><li>让判别器学习整个 minibatch内的样本之间的关系，避免生成器仅学习单一模式。</li></ul></li><li><strong>增加噪声扰动（Instance Noise）</strong><ul><li>在训练过程中，对真实数据和生成数据都添加随机噪声，防止判别器过早学习到确定的模式。</li></ul></li></ul><p><strong>4. 采用更强的 GAN 变体</strong></p><ul><li><strong>Unrolled GAN</strong><ul><li>通过多步更新判别器的梯度，使生成器能提前考虑判别器的未来变化，减少模式崩溃的可能性。</li></ul></li><li><strong>BigGAN</strong><ul><li>采用更大的 batch size、通道注意力（ChannelAttention）、自适应归一化（Adaptive BatchNormalization）等策略，提高多样性。</li></ul></li></ul><p><strong>5. 采用多判别器策略</strong></p><ul><li><strong>Multiple Discriminators</strong><ul><li>使用多个判别器，每个判别器关注不同的特征层级，有助于防止生成器专注于欺骗单个判别器，而忽略数据多样性。</li></ul></li></ul><table><colgroup><col style="width: 26%"><col style="width: 48%"><col style="width: 24%"></colgroup><thead><tr class="header"><th><strong>方法</strong></th><th><strong>作用</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr class="odd"><td>WGAN/WGAN-GP</td><td>解决梯度消失问题，提高训练稳定性</td><td>适用于高质量图像生成</td></tr><tr class="even"><td>LS-GAN</td><td>避免交叉熵损失的问题，使训练更稳定</td><td>适用于一般 GAN 训练</td></tr><tr class="odd"><td>Minibatch Discrimination</td><td>增强生成数据的多样性，防止模式崩溃</td><td>适用于小样本数据生成</td></tr><tr class="even"><td>Instance Noise</td><td>让 GAN 训练更加平滑，减少模式崩溃</td><td>适用于复杂数据分布</td></tr><tr class="odd"><td>Spectral Normalization</td><td>限制判别器的学习能力，防止模式崩溃</td><td>适用于大规模模型</td></tr><tr class="even"><td>多判别器策略</td><td>让生成器面对多个判别器，提高生成数据的多样性</td><td>适用于高分辨率图像生成</td></tr></tbody></table><h3 id="变分自编码器vaes描述vaes的工作原理以及它们在生成任务中的应用">5.变分自编码器（VAEs）：描述VAEs的工作原理，以及它们在生成任务中的应用。</h3><p>变分自编码器（VAE）是一种<strong>概率生成模型</strong>，用于学习数据的潜在分布，并从中生成新样本。它是自编码器（Autoencoder,AE）的一种改进版本，结合了 <strong>概率建模</strong> 和<strong>深度学习</strong>的能力，使其既可以进行数据压缩（编码-解码），又能进行数据生成。</p><hr><p><strong>主要构成</strong></p><p>VAE 主要由两个神经网络组成：</p><ul><li><strong>编码器（Encoder）</strong>：将输入数据 <span class="math inline">\(x\)</span> 映射到一个 <strong>潜在空间（latentspace）</strong>，生成一个 <strong>概率分布参数</strong>（均值 <span class="math inline">\(\mu\)</span> 和标准差 <span class="math inline">\(\sigma\)</span>），从而获得潜在变量 <span class="math inline">\(z\)</span> 的分布。</li><li><strong>解码器（Decoder）</strong>：从潜在变量 <span class="math inline">\(z\)</span> 生成数据 <span class="math inline">\(x&#39;\)</span>，希望 <span class="math inline">\(x&#39;\)</span> 能尽可能接近原始数据 <span class="math inline">\(x\)</span>。</li></ul><hr><p><strong>工作流程</strong></p><ol type="1"><li><p><strong>输入数据 <span class="math inline">\(x\)</span>经过编码器</strong>，输出一个<strong>高斯分布</strong>的均值 <span class="math inline">\(\mu\)</span> 和方差 <span class="math inline">\(\sigma^2\)</span>： <span class="math display">\[q(z|x) = \mathcal{N}(\mu(x), \sigma^2(x))\]</span></p></li><li><p><strong>采样潜在变量 <span class="math inline">\(z\)</span></strong>： <span class="math display">\[z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)\]</span> （使用 <strong>重参数技巧（Reparameterization Trick）</strong>进行可微分采样）</p></li><li><p><strong>解码器从 <span class="math inline">\(z\)</span> 生成<span class="math inline">\(x&#39;\)</span></strong>： <span class="math display">\[p(x|z) = f(z)\]</span> 其中 <span class="math inline">\(f(z)\)</span>为神经网络。</p></li><li><p><strong>优化目标（ELBO, 证据下界）</strong>：目标是最小化数据重建误差和 KL 散度： <span class="math display">\[\mathcal{L} = \mathbb{E}_{q(z|x)} [\log p(x|z)] - D_{KL}(q(z|x)\parallel p(z))\]</span></p><ul><li>第一项是<strong>重建损失</strong>，确保生成数据与原始数据相似。</li><li>第二项是<strong>KL 散度</strong>，确保潜在分布 <span class="math inline">\(q(z|x)\)</span> 逼近先验分布 <span class="math inline">\(p(z)\)</span>。</li></ul></li></ol><hr><p><strong>VAE 在生成任务中的应用</strong></p><ol type="1"><li><strong>图像生成</strong><ul><li>可用于 <strong>手写数字生成（如MNIST）</strong>，以及复杂图像合成（如 CelebA、LSUN）。</li><li>例如，<strong>VAE-GAN</strong> 结合 VAE 和GANs，提高生成图像质量。</li></ul></li><li><strong>数据去噪</strong><ul><li>训练 VAE 让其学习干净的图像分布，可以用于去噪任务（如<strong>Denoising VAE</strong>）。</li></ul></li><li><strong>风格迁移</strong><ul><li>VAE 可用于学习数据的风格空间，并生成具有不同风格的图像。</li></ul></li><li><strong>异常检测</strong><ul><li>由于 VAE能学习数据的潜在分布，输入异常数据时，重建误差较大，可用于异常检测（如<strong>工业故障检测、医学图像异常检测</strong>）。</li></ul></li><li><strong>文本生成</strong><ul><li>VAE 可用于自然语言生成（如 VAE-basedTransformer），帮助生成多样化文本。</li></ul></li></ol><h3 id="简述ddpm的算法原理">6. 简述DDPM的算法原理</h3><p>去噪扩散概率模型（Denoising Diffusion Probabilistic Models，简称DDPM）是一类生成模型，旨在通过逐步去除噪声的方式，从随机噪声中生成高质量的数据样本。其核心思想包括两个主要过程：<strong>前向扩散过程</strong>和<strong>反向去噪过程</strong>。</p><p><strong>1. 前向扩散过程（Forward Diffusion Process）：</strong></p><p>在训练阶段，DDPM对原始数据（如图像）逐步添加高斯噪声，形成一个马尔可夫链，直至数据被完全转化为接近各向同性的高斯噪声。具体步骤如下：</p><ul><li><p>给定原始数据样本 <span class="math inline">\(x_0\)</span>，在每个时间步 <span class="math inline">\(t\)</span> 中，引入一个小的正数 <span class="math inline">\(\beta_t\)</span>（称为噪声调度器），用于控制噪声的增加量。</p></li><li><p>通过以下递归公式添加噪声： <span class="math display">\[x_t = \sqrt{1 - \beta_t} \cdot x_{t-1} + \sqrt{\beta_t} \cdot\epsilon_{t-1}\]</span> 其中，<span class="math inline">\(\epsilon_{t-1}\)</span>表示从标准正态分布中采样的噪声项。</p></li><li><p>经过足够多的步骤（通常为<span class="math inline">\(1000\)</span>步），原始数据逐渐被噪声淹没，最终接近标准高斯分布。</p></li></ul><p><strong>2. 反向去噪过程（Reverse Denoising Process）：</strong></p><p>在生成阶段，DDPM从纯噪声开始，逐步去除噪声，逆转前向过程，生成新的数据样本。具体步骤如下：</p><ul><li>从标准高斯分布中采样一个初始噪声样本 <span class="math inline">\(x_T\)</span>。</li><li>利用一个经过训练的神经网络模型（通常采用 U-Net架构），预测并去除在每个时间步 <span class="math inline">\(t\)</span>的噪声，生成 <span class="math inline">\(x_{t-1}\)</span>。</li><li>通过迭代上述步骤，最终生成一个新的数据样本 <span class="math inline">\(x_0\)</span>，其分布与原始数据相似。</li></ul><p><strong>训练目标：</strong></p><p>DDPM的训练目标是学习一个模型，使其能够准确预测并去除各个时间步中的噪声。训练过程中，最小化以下损失函数：<span class="math display">\[L(\theta) = \mathbb{E}_{x_0, \epsilon, t} \left[ \left\| \epsilon -\epsilon_\theta(x_t, t) \right\|^2 \right]\]</span> 其中，<span class="math inline">\(\epsilon_\theta\)</span>是带有参数 <span class="math inline">\(\theta\)</span>的神经网络，用于预测噪声项 <span class="math inline">\(\epsilon\)</span>。</p><p><strong>总结：</strong></p><p>DDPM通过在前向过程添加噪声，将数据映射到高斯分布，然后在反向过程去除噪声，逐步生成新的数据样本。</p><h3 id="什么是马尔可夫过程ddpm中的马尔可夫链是如何定义的">7.什么是马尔可夫过程？DDPM中的马尔可夫链是如何定义的?</h3><p><strong>马尔可夫过程</strong></p><p>马尔可夫过程（MarkovProcess）是一种随机过程，其核心特性是<strong>无记忆性</strong>（马尔可夫性），即未来状态仅依赖于当前状态，与历史状态无关。换句话说，对于一个马尔可夫过程，给定当前状态，未来的演化只与这个状态有关，而不需要考虑之前的所有信息。数学上定义为：<br><span class="math display">\[P(X_{t+1} = x_{t+1} \mid X_0 = x_0, X_1 = x_1, \dots, X_t = x_t) =P(X_{t+1} = x_{t+1} \mid X_t = x_t)\]</span></p><p>常见的马尔可夫过程包括马尔可夫链（离散状态）、布朗运动（连续状态）等。</p><hr><p><strong>DDPM中的马尔可夫链定义</strong></p><p>DDPM（Denoising Diffusion ProbabilisticModels）是一种基于扩散过程的生成模型，其核心是通过<strong>前向加噪</strong>和<strong>反向去噪</strong>的马尔可夫链实现数据生成。具体定义如下：</p><ol type="1"><li><strong>前向过程（加噪）</strong></li></ol><ul><li><p><strong>目标</strong>：将数据 <span class="math inline">\(x_0\)</span>（如图像）逐步添加高斯噪声，最终转化为纯噪声<span class="math inline">\(x_T \sim \mathcal{N}(0,I)\)</span>。</p></li><li><p><strong>马尔可夫链结构</strong>：每一步加噪仅依赖当前状态，状态转移定义为：<br><span class="math display">\[q(x_t \mid x_{t-1}) = \mathcal{N}\left(x_t; \sqrt{1 - \beta_t} x_{t-1},\beta_t I \right)\]</span></p><p>这意味着第 <span class="math inline">\(t\)</span> 步的状态 <span class="math inline">\(x_t\)</span> 只依赖于前一步 <span class="math inline">\(x_{t-1}\)</span>，而与之前的状态无关，整个。其中<span class="math inline">\(\beta_t \in (0,1)\)</span>是预先设定的噪声调度参数，控制每一步的噪声强度。</p></li><li><p><strong>累积效应</strong>：通过重参数化技巧，可直接从 $x_0 $计算任意 <span class="math inline">\(x_t\)</span>：<br><span class="math display">\[q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}\, x_0,\,(1-\bar{\alpha}_t)\, I) \\x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon, \quad \epsilon\sim \mathcal{N}(0, I)\]</span> 其中 <span class="math inline">\(\alpha_t = \prod_{i=1}^t (1 -\beta_i)\)</span>。</p></li></ul><ol start="2" type="1"><li><strong>反向过程（去噪）</strong></li></ol><ul><li><p><strong>目标</strong>：从噪声 $ x_T $ 出发，逐步去噪生成数据 $x_0 $。</p></li><li><p><strong>马尔可夫链结构</strong>：每一步去噪依赖当前状态，状态转移通过神经网络学习：<br><span class="math display">\[p_\theta(x_{t-1} \mid x_t) = \mathcal{N}\left(x_{t-1}; \mu_\theta(x_t,t), \Sigma_\theta(x_t, t) \right)\]</span></p><p>其中 <span class="math inline">\(\mu_\theta\)</span> 和 <span class="math inline">\(\Sigma_\theta\)</span>是模型预测的均值和方差。</p></li><li><p><strong>关键设计</strong>：</p><ul><li><p>通常固定方差 <span class="math inline">\(\Sigma_\theta\)</span>（如 <span class="math inline">\(\Sigma_t = \sigma_t^2 I\)</span>），仅学习均值<span class="math inline">\(\mu_\theta\)</span>。</p></li><li><p>通过预测噪声 <span class="math inline">\(\epsilon_\theta(x_t,t)\)</span> 间接计算均值：</p><p><span class="math display">\[\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t -\frac{\beta_t}{\sqrt{1 - \alpha_t}} \epsilon_\theta(x_t, t) \right)\]</span></p></li></ul></li></ul><ol start="3" type="1"><li><strong>训练目标</strong></li></ol><p>最小化真实反向过程 $ q(x_{t-1} x_t) $ 和模型预测 $p_(x_{t-1} x_t) $的KL散度，最终简化为： <span class="math display">\[\mathcal{L} = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon -\epsilon_\theta(x_t, t) \|^2 \right]\]</span></p><p>即直接让网络预测每一步加入的噪声 <span class="math inline">\(\epsilon\)</span>。</p><hr><p><strong>为什么DDPM使用马尔可夫链？</strong></p><ol type="1"><li><strong>简化建模</strong>：每一步仅依赖当前状态，避免复杂的历史依赖。<br></li><li><strong>高效计算</strong>：允许通过闭式公式直接从<span class="math inline">\(x_0\)</span> 计算任意 <span class="math inline">\(x_t\)</span> ，加速训练。<br></li><li><strong>稳定生成</strong>：马尔可夫链的局部性使反向过程可分解为多个简单步骤，逐步修正生成结果。</li></ol><h3 id="为什么ddpm前向过程中前期加噪少后期加噪多">8.为什么DDPM前向过程中前期加噪少，后期加噪多？</h3><p>在DDPM的前向加噪过程中，噪声的添加遵循特定的调度策略，通常在初期添加较少的噪声，后期逐步增加噪声量。这种设计主要基于以下考虑：</p><ol type="1"><li><strong>数据破坏的均匀性：</strong>在前向过程（也称扩散过程）中，目标是通过逐步添加高斯噪声，将原始数据转变为接近各向同性的高斯噪声。由于原始数据在初期具有丰富的结构和信息，添加少量噪声即可显著改变其分布。而在后期，数据已被大量噪声覆盖，需要添加更多的噪声以继续有效地破坏剩余的结构信息，确保每一步的噪声扩散幅度保持相对均匀。</li><li><strong>高频与低频信息的影响：</strong>图像等数据通常包含高频和低频信息。高频信息（如边缘和纹理）对噪声更为敏感，少量噪声即可破坏这些细节。因此，在前期添加较少的噪声，有助于先破坏高频信息。随着高频信息的破坏，后期需要增加噪声量来进一步影响低频信息，确保整个数据分布逐步趋于高斯噪声。</li><li><strong>反向去噪过程的稳定性：</strong>在训练反向去噪模型时，前向过程的噪声调度影响着模型的学习难度。初期较小的噪声添加使得模型在学习去噪时，先专注于恢复高频细节，逐步适应复杂的结构信息。随着训练的进行，模型逐渐学习到如何处理更高水平的噪声，从而在后期能够有效地恢复低频信息。这种逐步递增的噪声调度，有助于提高反向去噪过程的稳定性和生成样本的质量。</li></ol><h3 id="什么是重参数化技巧-diffusionmodels和vae中的重参数化技巧是如何使用的">9.什么是重参数化技巧?DiffusionModels和VAE中的重参数化技巧是如何使用的?</h3><p><strong>重参数化技巧（Reparameterization Trick）</strong></p><p><strong>定义与目的</strong>重参数化技巧是一种在概率生成模型中处理随机变量的方法，其核心思想是将随机变量的采样过程分解为<strong>确定性参数</strong>和<strong>独立噪声</strong>的组合。通过这种方式，原本不可导的采样操作变得可导，使得梯度可以通过反向传播优化模型参数。其核心公式为：<br><span class="math display">\[z = g_\theta(\epsilon) \quad \text{其中} \quad \epsilon \sim p(\epsilon)\]</span></p><p>这里，<span class="math inline">\(z\)</span> 是目标随机变量，<span class="math inline">\(g_\theta\)</span> 是以参数 <span class="math inline">\(\theta\)</span> 为输入的确定性函数，<span class="math inline">\(\epsilon\)</span> 是独立于 <span class="math inline">\(\theta\)</span> 的噪声（如高斯分布）。</p><p><strong>解决的问题</strong></p><ul><li>直接对随机变量采样（如 $z (, ^2)$）会导致梯度无法回传，因为采样操作本身是离散且不可导的。</li><li>重参数化将随机性转移到外部噪声 $ $，使得梯度可以通过 $ g_$传递到参数$$。</li></ul><hr><p><strong>在变分自编码器（VAE）中的使用</strong></p><p><strong>背景</strong> VAE通过编码器将输入 $ x $ 映射到潜在空间分布 $q_(z|x) $，再从该分布采样 $ z $，并通过解码器重构数据。直接采样 $ z (,^2) $ 会阻断梯度传播。</p><p><strong>重参数化实现</strong> 将潜在变量 $ z $ 表示为：<br><span class="math display">\[z = \mu + \sigma \odot \epsilon \quad \text{其中} \quad \epsilon \sim\mathcal{N}(0, I)\]</span></p><ul><li>$ $ 和 $ $ 是编码器输出的均值和方差，作为确定性参数。</li><li>$ $ 是独立的高斯噪声，不依赖模型参数。</li></ul><p><strong>梯度传播</strong></p><ul><li><p>损失函数对 $ $ 和 $ $ 的梯度可通过$ z $传递到编码器网络，例如：<br><span class="math display">\[\frac{\partial z}{\partial \mu} = 1, \quad \frac{\partial z}{\partial\sigma} = \epsilon\]</span></p></li><li><p>这使得VAE可以端到端训练，优化编码器和解码器的参数。</p></li></ul><hr><p><strong>在扩散模型（Diffusion Models）中的使用</strong></p><p><strong>背景</strong><br>扩散模型通过前向过程逐步添加噪声将数据 $ x_0 $ 破坏为纯噪声 $ x_T$，再通过反向过程去噪生成数据。前向过程需要高效计算任意时间步的 $ x_t$。</p><p><strong>前向过程的重参数化</strong><br>直接通过闭式公式计算 $ x_t <span class="math inline">\(，避免逐步迭代：\)</span>$ x_t = x_0 + (0, I)$$</p><ul><li>$ <em>t = </em>{i=1}^t (1 - _i) $ 是累积噪声调度系数，$ _i $控制每一步的噪声强度。</li><li>随机性来自独立噪声 $ $，而 $ _t $ 是确定性参数。</li></ul><p><strong>反向过程的训练目标</strong><br>模型需要预测前向过程中加入的噪声 $ <span class="math inline">\(，损失函数为：\)</span>$ = _{t, x_0, } $$</p><ul><li>通过重参数化，$ x_t $ 的计算可导，梯度可传递到噪声预测网络 $_$。</li></ul><hr><p><strong>VAE与扩散模型的重参数化对比</strong></p><table><colgroup><col style="width: 12%"><col style="width: 32%"><col style="width: 55%"></colgroup><thead><tr class="header"><th><strong>维度</strong></th><th><strong>VAE</strong></th><th><strong>扩散模型</strong></th></tr></thead><tbody><tr class="odd"><td><strong>应用场景</strong></td><td>潜在变量采样</td><td>前向噪声生成与反向去噪</td></tr><tr class="even"><td><strong>核心公式</strong></td><td>$ z = + $</td><td>$ x_t = x_0 + $</td></tr><tr class="odd"><td><strong>随机性来源</strong></td><td>潜在空间的高斯噪声 $ $</td><td>前向过程的加噪噪声 $ $</td></tr><tr class="even"><td><strong>优化目标</strong></td><td>重构损失与KL散度</td><td>噪声预测的均方误差</td></tr><tr class="odd"><td><strong>数学意义</strong></td><td>分离潜在变量的随机性与参数</td><td>分离时间步的随机性与确定性调度</td></tr></tbody></table><h3 id="vae和diffusionmodels中的变分推断是什么">10.VAE和DiffusionModels中的变分推断是什么?</h3><p><strong>变分推断（Variational Inference）的核心思想</strong></p><p>变分推断是是一种用于近似复杂概率分布的技术，广泛应用于机器学习领域，特别是在生成模型中。其核心思想是将复杂的后验分布近似为一个易处理的分布，并通过最小化两者之间的差异来进行优化，过程如下：</p><ol type="1"><li><p>引入一个参数化的近似分布 $ q_(z x)$，称为<strong>变分分布</strong>（通常选择简单分布，如高斯分布）。</p></li><li><p>通过优化 $ q_$ 的参数 $ $，使其尽可能接近真实后验 $ p(z x)$。</p></li><li><p>优化的目标是<strong>最小化 $ q_(z x) $ 与 $ p(z x) $的KL散度</strong>，即：</p><p><span class="math display">\[\text{KL}\left(q_\phi(z \mid x) \| p(z \mid x)\right) =\mathbb{E}_{q_\phi} \left[ \log \frac{q_\phi(z \mid x)}{p(z \mid x)}\right]\]</span> 由于直接计算KL散度需要知道 $ p(z x) <span class="math inline">\(，变分推断转而最大化**证据下界（ELBO, EvidenceLower BOund）**：\)</span>$ = <em>{q</em>} - (q_(z x) | p(z)) $$</p><p>其中 $ p(z) $ 是隐变量的先验分布。</p></li></ol><hr><p><strong>VAE中的变分推断</strong></p><p><strong>1. 问题定义</strong></p><p>VAE的目标是学习数据的生成过程 $ p_(x z) $，其中 $ z $是隐变量。直接计算后验 $ p(z x) $ 难以处理，因此使用变分推断近似。</p><p><strong>2. 变分分布设计</strong></p><ul><li><p><strong>编码器</strong>（推断网络）：将输入 $ x $映射到隐变量分布参数 $ <em>(x) $ 和 $ </em>(x) <span class="math inline">\(，即：\)</span>$ q_(z x) = (z; <em>(x), </em>(x)^2I ) $$</p></li><li><p><strong>解码器</strong>（生成网络）：从 $ z $ 生成数据 $ x $，即$ p_(x z) $。</p></li></ul><p><strong>3. 优化目标（ELBO）</strong></p><p>通过最大化证据下界（ELBO）来最小化<span class="math inline">\(q(z|x)\)</span> 与 <span class="math inline">\(p(z|x)\)</span> 之间的Kullback-Leibler（KL）散度，从而使 <span class="math inline">\(q(z|x)\)</span> 尽可能接近 <span class="math inline">\(p(z|x)\)</span>。VAE的损失函数是负的ELBO，包含两部分：<br><span class="math display">\[\mathcal{L}_{\text{VAE}} = -\mathbb{E}_{q_\phi(z \mid x)} \left[ \logp_\theta(x \mid z) \right] + \text{KL}\left(q_\phi(z \mid x) \|p(z)\right)\]</span></p><ul><li><strong>重构项</strong>：鼓励解码器生成的数据 $ p_(x z) $接近真实数据。<br></li><li><strong>正则项</strong>：约束隐变量分布 $ q_(z x) $ 接近先验 $ p(z)$（通常为标准高斯分布）。</li></ul><p><strong>4. 重参数化技巧</strong></p><p>为梯度回传，隐变量 $ z $ 通过重参数化生成：<br><span class="math display">\[z = \mu_\phi(x) + \sigma_\phi(x) \odot \epsilon, \quad \epsilon \sim\mathcal{N}(0, I)\]</span></p><p>这使得采样过程可导，梯度可通过 $ <em>(x) $ 和 $ </em>(x) $传递到编码器。</p><hr><p><strong>扩散模型（Diffusion Models）中的变分推断</strong></p><p><strong>1. 问题定义</strong></p><p>扩散模型通过马尔可夫链逐步将数据 $ x_0 $ 加噪为 $ x_T (0, I)$，再学习反向过程 $ p_(x_{t-1} x_t) $ 生成数据。<br>其目标是<strong>最大化数据似然</strong> $ p_(x_0)$，但因积分难以计算，转而优化变分下界。</p><p><strong>2. 变分分布设计</strong></p><ul><li><p><strong>前向过程</strong>：定义固定的加噪过程 $ q(x_{1:T} x_0)<span class="math inline">\(，每一步为：\)</span>$ q(x_t x_{t-1}) =(x_t; x_{t-1}, _t I ) $$</p></li><li><p><strong>反向过程</strong>：通过神经网络学习 $ p_(x_{t-1} x_t)$，近似真实反向分布 $ q(x_{t-1} x_t, x_0) $。</p></li></ul><p><strong>3. 优化目标（变分下界）</strong></p><p>通过最小化前向过程和反向过程之间的 KL散度，优化模型参数，使反向过程能够有效地去噪，生成高质量的数据样本。扩散模型的损失函数是负的变分下界：<br><span class="math display">\[\mathcal{L} = \mathbb{E}_{q(x_{1:T} \mid x_0)} \left[ \log \frac{q(x_{T}\mid x_0)}{p_\theta(x_T)} + \sum_{t&gt;1} \log \frac{q(x_{t-1} \mid x_t,x_0)}{p_\theta(x_{t-1} \mid x_t)} - \log p_\theta(x_0 \mid x_1) \right]\]</span></p><p>经化简后，损失函数简化为<strong>噪声预测的均方误差</strong>：<br><span class="math display">\[\mathcal{L} = \mathbb{E}_{t, x_0, \epsilon} \left[ \| \epsilon -\epsilon_\theta(x_t, t) \|^2 \right]\]</span></p><p>其中 $ x_t = x_0 + <span class="math inline">\(，\)</span> _$是预测噪声的网络。</p><p><strong>4. 变分推断的作用</strong></p><ul><li><strong>前向过程</strong>：提供可解析计算的中间分布 $ q(x_t x_0)$。<br></li><li><strong>反向过程</strong>：通过变分推断优化 $ p_(x_{t-1} x_t)$，使其逼近真实反向分布 $ q(x_{t-1} x_t, x_0) $。<br></li><li><strong>关键设计</strong>：利用马尔可夫链分解，将复杂的联合分布优化转化为逐时间步的局部优化。</li></ul><hr><p><strong>VAE与扩散模型变分推断的对比</strong></p><table><colgroup><col style="width: 13%"><col style="width: 27%"><col style="width: 58%"></colgroup><thead><tr class="header"><th><strong>维度</strong></th><th><strong>VAE</strong></th><th><strong>扩散模型</strong></th></tr></thead><tbody><tr class="odd"><td><strong>隐变量结构</strong></td><td>单一静态隐变量 $ z $</td><td>时间序列隐变量 $ x_1, x_2, , x_T $</td></tr><tr class="even"><td><strong>变分分布</strong></td><td>$ q_(z x) $</td><td>$ q(x_{1:T} x_0) $（固定）与 $ p_(x_{t-1} x_t) $</td></tr><tr class="odd"><td><strong>优化目标</strong></td><td>最大化ELBO</td><td>最大化变分下界（简化为噪声预测损失）</td></tr><tr class="even"><td><strong>时间依赖性</strong></td><td>无</td><td>马尔可夫链的时间步依赖</td></tr><tr class="odd"><td><strong>隐变量意义</strong></td><td>数据的压缩表征</td><td>逐步加噪/去噪的中间状态</td></tr><tr class="even"><td><strong>核心技术</strong></td><td>编码器-解码器结构 + 重参数化</td><td>前向过程闭式解 + 噪声预测网络</td></tr></tbody></table><ol type="1"><li><strong>共同点</strong>：<ul><li>均使用变分推断近似复杂后验分布。<br></li><li>依赖重参数化技巧实现梯度传播（VAE用于隐变量采样，扩散模型用于前向过程闭式计算）。</li></ul></li><li><strong>差异点</strong>：<ul><li>VAE处理静态隐变量，扩散模型处理序列隐变量。<br></li><li>VAE的变分分布是自由参数化的，扩散模型的前向过程是固定的，仅优化反向过程。</li></ul></li></ol><h3 id="diffusion中的cfg机制与negativeprompt实现的原理">11.Diffusion中的CFG机制与NegativePrompt实现的原理</h3><p><strong>Classifier-Free Guidance（CFG）</strong>是扩散模型（DiffusionModels）中用于引导生成过程的方法，旨在提升生成样本与条件输入（如文本提示）之间的匹配度。其核心思想是通过<strong>联合训练有条件生成和无条件生成</strong>，并在推理时通过加权调整两者的差异，实现对生成结果的精准控制。在Stable Diffusion 等模型中，CFG通过调整生成内容对提示词的依赖程度，从而在生成质量和多样性之间取得平衡。</p><p><strong>CFG 的工作机制：</strong></p><p>在训练阶段，模型以一定概率接收带有条件（如文本描述）的输入，另一些情况下则接收无条件输入。这种训练方式使模型能够学习到有条件和无条件生成的能力。在推理阶段，CFG通过以下方式引导生成过程：</p><ol type="1"><li><p><strong>无条件预测（Unconditional Prediction）：</strong></p><p>代表模型对“通用数据分布”的理解（如自然图像的一般特征）。</p><p>模型在不考虑条件输入的情况下，随机丢弃条件（如以空文本或固定占位符替代），预测噪声$ _(x_t, t, ) $。</p></li><li><p><strong>有条件预测（Conditional Prediction）：</strong></p><p>代表模型对“特定条件约束”的理解（如“一只猫”的语义）。</p><p>模型在考虑条件输入的情况下，基于文本条件 $ c $ 预测噪声 $ _(x_t, t,c) $。</p><p><strong>权重共享</strong>：两种任务共享同一网络参数，仅通过条件掩码区分。</p></li><li><p><strong>引导生成：</strong>通过调整无条件和有条件预测之间的权重，公式为：</p><p><strong>加权噪声预测</strong>：将有条件预测与无条件预测的差异作为“引导方向”，通过<strong>指导尺度$ s $</strong> 控制引导强度：</p><p><span class="math inline">\(\epsilon_\text{guided} =\epsilon_\theta(x_t, t, \emptyset) + s \cdot \left( \epsilon_\theta(x_t,t, c) - \epsilon_\theta(x_t, t, \emptyset) \right)\)</span></p><ul><li><strong>$ <em>(x_t, t, c) - </em>(x_t, t, )$</strong>：条件与无条件预测的差异，代表文本条件对生成方向的修正。</li><li><strong>$ s $</strong>：放大条件的作用（通常 $ s $，如StableDiffusion默认 $ s=7.5 $）。</li></ul></li></ol><p><strong>Negative Prompt的工作原理</strong></p><p>引入负面提示词后，模型在无条件采样阶段使用负面提示词进行指导。具体而言，模型首先根据正面提示词进行有条件采样，然后在无条件采样中引入负面提示词，以避免生成不期望的特征。这一过程可以表示为：<span class="math display">\[\epsilon_\text{final} = \epsilon_+ + s \cdot (\epsilon_+ - \epsilon_-)\]</span> 或更常见的形式（与CFG结合）： <span class="math display">\[\epsilon_\text{final} = \epsilon_\emptyset + s_+ \cdot (\epsilon_+ -\epsilon_\emptyset) - s_- \cdot (\epsilon_- - \epsilon_\emptyset)\]</span> 其中：</p><ul><li><p><strong>正向条件</strong>：使用正向提示词 <span class="math inline">\(c_+\)</span> 预测噪声 <span class="math inline">\(\epsilon_+ = \epsilon_\theta(x_t, t,c_+)\)</span>。</p></li><li><p><strong>负向条件</strong>：使用负向提示词 <span class="math inline">\(c_-\)</span> 预测噪声 <span class="math inline">\(\epsilon_- = \epsilon_\theta(x_t, t,c_-)\)</span>。</p></li><li><p><span class="math inline">\(s_+\)</span> 和 <span class="math inline">\(s_-\)</span>分别控制正向和负向条件的强度（通常设为相同值）。</p></li><li><p><strong>直观理解</strong>：在梯度上升（去噪）过程中，同时增强正向条件的信号，抑制负向条件的信号。</p></li></ul><p>该公式表明，模型在生成过程中会朝向正面提示词的方向前进，同时远离负面提示词的方向，从而实现对生成内容的精确控制。</p><h3 id="ddim是怎样加速采样的简述ddim的原理">12.DDIM是怎样加速采样的(简述DDIM的原理)？</h3><p><strong>DDIM（Denoising Diffusion Implicit Models）</strong>是对扩散模型（如DDPM）的一种改进，旨在通过减少采样步骤来加速图像生成过程。其核心思想在于重新设计去噪过程，使之成为一个确定性的映射，从而在保持生成质量的同时，提高采样效率。</p><p><strong>1. 非马尔可夫链反向过程</strong></p><p>传统的 DDPM 在去噪过程中依赖于随机采样，而 DDIM将去噪过程设定为确定性映射，即在每个时间步直接计算去噪结果，无需引入随机性。这样，模型在相同的初始条件下会生成相同的样本，提高了生成过程的可控性。<strong>DDIM的关键改进</strong>：</p><p>传统扩散模型（如DDPM）的反向过程是马尔可夫链，每一步仅依赖前一步的状态，必须逐次迭代。</p><ul><li>设计一种<strong>非马尔可夫链的反向过程</strong>，允许跳跃式地更新隐变量。通过重新参数化，直接建模从任意时间步$ t $ 到目标步 $ t-Δ $ 的映射（$ Δ $ 为步长跳跃量）。</li></ul><p><strong>数学形式</strong>： DDIM的反向过程公式为： <span class="math display">\[x_{t-1}=\sqrt{\alpha_{t-1}}\underbrace{\left(\frac{x_t-\sqrt{1-\alpha_t}\epsilon_\theta^{(t)}(x_t)}{\sqrt{\alpha_t}}\right)}_{\text{“predicted}\boldsymbol{x}_0\mathrm{”}}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2}\cdot\epsilon_\theta^{(t)}(\boldsymbol{x}_t)}_{\text{“directionpointing to}\boldsymbol{x}_t\mathrm{”}}+\underbrace{\sigma_t\epsilon_t}_{\text{randomnoise}}\]</span> 其中，$ _t (, ) $ 是独立于 $ _t $ 的标准高斯噪声，我们定义 $<em>0 := 1 $。不同的 $ $ 值会导致不同的生成过程，但都使用相同的模型 $</em>$ ($$ 是噪声预测网络)，因此无需重新训练模型。当对于所有的 $ t <span class="math inline">\(，\)</span> _t = $时，前向过程成为马尔可夫过程，生成过程则成为 DDPM。</p><p>进一步的，在DDIM中，从时间步 <span class="math inline">\(t\)</span>到 <span class="math inline">\(t-\Delta\)</span> 的采样过程可以表示为：<span class="math display">\[x_{t-Δ} = \sqrt{\bar{\alpha}_{t-Δ}} \left( \frac{x_t - \sqrt{1-\alpha_t}\epsilon_\theta(x_t, t)}{\sqrt{\alpha_t}} \right) + \sqrt{1 -\bar{\alpha}_{t-Δ}} \epsilon_\theta(x_t, t)\]</span></p><ul><li><strong>跳跃采样</strong>：DDIM允许在去噪过程中跳过一些时间步，而不是严格按照每个时间步进行采样。通过选择一个子序列的时间步，模型可以在较少的步骤内完成去噪过程，从而加速采样（例如从$ t=100 $ 更新到 $ t=80 $），大幅减少总迭代次数。</li></ul><p><strong>2. 确定性生成路径</strong></p><p>DDPM的反向过程是随机的（每一步加入新噪声），而DDIM通过<strong>固定噪声预测方向</strong>，使生成过程确定性化：</p><ul><li>在采样时，噪声预测值 $ _(x_t, t) $ 完全由当前状态 $ x_t $决定，不再随机采样噪声。<br></li><li><strong>效果</strong>：相同初始噪声 $ x_T $下，DDIM每次生成的结果一致，减少了随机性带来的计算冗余。</li></ul><p><strong>3. 无需重新训练模型</strong></p><p>DDIM直接复用DDPM训练好的噪声预测网络 $_$，仅修改采样算法，因此无需额外训练成本。</p><h3 id="什么是基于分数的生成模型">13. 什么是基于分数的生成模型？</h3><p><strong>基于分数的生成模型（Score-Based GenerativeModels，SGMs）</strong>是一种生成模型，其核心思想是学习数据分布的梯度（即分数函数），然后利用该梯度信息从噪声中逐步生成符合目标分布的新样本。</p><p><strong>主要概念：</strong></p><ol type="1"><li><strong>分数函数（Score Function）：</strong>指数据分布对数概率密度函数的梯度，表示为 <span class="math inline">\(\nabla_{\mathbf{x}} \logp(\mathbf{x})\)</span>。分数表示数据空间中每个点的“变化方向”，指导如何调整样本以更符合真实分布。该函数指示了数据空间中概率密度增加最快的方向。</li><li><strong>朗之万动力学（Langevin Dynamics）：</strong>一种基于梯度的信息采样方法。通过在数据空间中沿着分数函数的方向进行随机行走，逐步逼近真实数据分布，从而生成新的样本。</li></ol><p><strong>工作原理：</strong></p><ul><li><p><strong>训练阶段：</strong>模型通过在带有不同尺度噪声的数据上学习分数函数，以准确估计各个噪声水平下的数据分布梯度。</p><ul><li><p><strong>扰动数据（加噪）</strong></p><p>通过逐渐添加噪声，将原始数据分布 $ p() $ 转化为一系列噪声扰动分布 $p_t() <span class="math inline">\(（\)</span> t <span class="math inline">\(）。例如：\)</span>$ p_t() = p(_0) (; _0, _t^2 I)d_0 $$ 其中 $ _t $ 随时间增加而增大，最终 $ p_T() (0, I) $。</p></li><li><p><strong>分数匹配训练</strong></p><p>最小化评分网络 $ s_(, t) $ 与真实分数之间的差异： <span class="math display">\[\mathcal{L} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_t} \left[\lambda(t) \| s_\theta(\mathbf{x}_t, t) - \nabla_{\mathbf{x}_t} \logp_t(\mathbf{x}_t \mid \mathbf{x}_0) \|^2 \right]\]</span></p><p>其中 $ (t) $ 是权重函数，$ _{_t} p_t(_t _0) = $。</p></li></ul></li><li><p><strong>生成阶段：</strong> 从随机噪声 $ _T (0, I) $开始，利用朗之万动力学或随机微分方程（SDE），沿着学习到的分数函数方向逐步去噪，最终生成与真实数据分布相符的样本。</p><ul><li><p><strong>朗之万动力学</strong>： <span class="math display">\[\mathbf{x}_{t-1} = \mathbf{x}_t + \epsilon \cdot s_\theta(\mathbf{x}_t,t) + \sqrt{2\epsilon} \cdot \mathbf{z}, \quad \mathbf{z} \sim\mathcal{N}(0, I)\]</span></p></li><li><p><strong>SDE求解器</strong>：将生成过程视为反向求解扩散SDE：<br><span class="math display">\[d\mathbf{x} = [-\frac{1}{2}\beta(t)\mathbf{x} - \beta(t)s_\theta(\mathbf{x}, t)] dt + \sqrt{\beta(t)} d\mathbf{w}\]</span></p><p>其中 $ (t) $​ 控制噪声调度。</p></li></ul></li><li><p><strong>目 标</strong>： 训练一个神经网络 $ s_(, t)$（称为<strong>评分网络</strong>），使其逼近不同噪声水平下的数据分数，从而生成高质量样本。</p></li></ul><p><strong>应用场景</strong></p><ol type="1"><li><strong>图像生成</strong>：生成高分辨率、多样化的图像（如OpenAI的GLIDE）。</li><li><strong>音频合成</strong>：生成音乐或语音片段。</li><li><strong>数据增强</strong>：为小样本任务生成合成数据。</li><li><strong>科学建模</strong>：分子生成、物理模拟等。</li></ol><p><strong>优势与挑战</strong></p><ul><li><strong>优势</strong>：<ul><li>无需对抗训练，避免模式崩溃。</li><li>生成样本多样性高，质量稳定。</li><li>理论框架统一，可扩展性强。</li></ul></li><li><strong>挑战</strong>：<ul><li>采样速度较慢（需数十至数百步迭代）。</li><li>对噪声调度和超参数敏感。</li><li>高维数据训练计算成本大。</li></ul></li></ul><h3 id="在diffusion中常见的条件注入的方法有哪些">14.在Diffusion中常见的条件注入的方法有哪些?</h3><p>在扩散模型中，条件注入（Conditioning）是通过将外部信息（如文本、类别标签、图像等）融入生成过程，从而控制生成结果的核心技术。以下是常见的条件注入方法及其原理和应用：</p><p><strong>1. Classifier Guidance（分类器引导）</strong></p><ul><li><p><strong>原理</strong>：在生成过程中，利用<strong>预训练的分类器</strong>（如ResNet）提供梯度信号，指导生成样本向特定类别靠近。</p><ul><li><p>在反向去噪时，噪声预测网络不仅预测去噪方向，还结合分类器对当前样本的条件概率梯度：<br><span class="math display">\[\epsilon_\theta(x_t, t, y) = \epsilon_\theta(x_t, t) + s \cdot\nabla_{x_t} \log p_\phi(y \mid x_t)\]</span></p></li><li><p>其中 $ y $ 是类别标签，$ s $ 是引导强度，$ p_$是分类器的概率输出。</p></li></ul></li><li><p><strong>优点</strong>：无需修改扩散模型结构，直接利用外部分类器。</p></li><li><p><strong>缺点</strong>：依赖额外分类器的训练，可能引入偏差。</p></li><li><p><strong>应用</strong>：早期扩散模型（如DDPM+）的类别条件生成。</p></li></ul><p><strong>2. Classifier-Free Guidance（CFG，无分类器引导）</strong></p><ul><li><strong>原理</strong>：联合训练有条件生成和无条件生成，通过加权两者的差异实现引导，详见<strong>问题11</strong>.</li><li><strong>优点</strong>：无需额外分类器，生成控制更灵活。<br></li><li><strong>缺点</strong>：训练时需要随机丢弃条件（如概率设为10%~20%）。</li></ul><p><strong>3. Cross-Attention（交叉注意力）</strong></p><ul><li><p><strong>原理</strong>：在扩散模型的噪声预测网络（如UNet）中插入<strong>交叉注意力层</strong>，将条件信息（如文本嵌入）作为Key和Value，与图像特征（Query）交互：<br><span class="math display">\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right) V\]</span></p><ul><li><strong>Q</strong>：图像特征的投影。<br></li><li><strong>K, V</strong>：条件编码（如CLIP文本嵌入）的投影。</li></ul></li><li><p><strong>优点</strong>：支持细粒度的语义对齐（如文本与图像的局部对应）。</p></li></ul><p><strong>4. 条件嵌入拼接（Embedding Concatenation）</strong></p><ul><li><strong>原理</strong>：将条件信息（如类别标签、图像特征）编码为向量，直接<strong>拼接到扩散模型的输入或中间层</strong>：<ul><li>对于图像条件，可将条件图像通过编码器提取特征，与噪声图像拼接。<br></li><li>对于标签条件，可将类别嵌入向量拼接到每个残差块的输入。<br></li></ul></li><li><strong>优点</strong>：实现简单，计算高效。<br></li><li><strong>缺点</strong>：对复杂条件（如长文本）的表征能力有限。<br></li><li><strong>应用</strong>：类别条件图像生成（如ImageNet扩散模型）、图像修复。</li></ul><p><strong>5. 自适应归一化（Adaptive Normalization）</strong></p><ul><li><p><strong>原理</strong>：利用条件信息动态调整归一化层（如BatchNorm、GroupNorm）的缩放因子（Scale）和偏置（Bias）：<br><span class="math display">\[\text{Norm}(x) = \gamma(y) \cdot \frac{x - \mu}{\sigma} + \beta(y)\]</span></p><ul><li>$ (y), (y) $：由条件编码 $ y $ 通过小型网络（如MLP）生成。</li></ul></li><li><p><strong>变体</strong>：</p><ul><li><strong>SPADE</strong>（空间自适应归一化）：根据条件图像生成空间维度的缩放和偏置。<br></li><li><strong>AdaGN</strong>（自适应组归一化）：将条件嵌入映射到归一化参数。</li></ul></li><li><p><strong>优点</strong>：支持细粒度的空间条件控制。</p></li><li><p><strong>应用</strong>：图像到图像转换（如超分辨率、语义分割图生成）</p></li></ul><p><strong>6. 基于CLIP的引导（CLIP-Guided Diffusion）</strong></p><ul><li><p><strong>原理</strong>：利用多模态模型CLIP的图文对齐能力，计算生成图像与文本条件的相似度梯度，优化生成方向：<br><span class="math display">\[\epsilon_\theta(x_t, t, y) = \epsilon_\theta(x_t, t) + s \cdot\nabla_{x_t} \text{CLIP-Similarity}(x_t, y)\]</span></p></li><li><p><strong>优点</strong>：无需训练，直接利用预训练CLIP模型。</p></li><li><p><strong>缺点</strong>：计算开销大，梯度方向可能不稳定。</p></li><li><p><strong>应用</strong>：文本驱动的图像风格迁移、零样本生成。</p></li></ul><hr><p><strong>方法对比</strong></p><table><colgroup><col style="width: 27%"><col style="width: 20%"><col style="width: 20%"><col style="width: 17%"><col style="width: 14%"></colgroup><thead><tr class="header"><th><strong>方法</strong></th><th><strong>条件类型</strong></th><th><strong>训练成本</strong></th><th><strong>生成质量</strong></th><th><strong>灵活性</strong></th></tr></thead><tbody><tr class="odd"><td>Classifier Guidance</td><td>类别标签</td><td>高（需分类器）</td><td>中等</td><td>低</td></tr><tr class="even"><td>Classifier-Free</td><td>文本、多模态</td><td>中（联合训练）</td><td>高</td><td>高</td></tr><tr class="odd"><td>Cross-Attention</td><td>文本、语义</td><td>高</td><td>高</td><td>高</td></tr><tr class="even"><td>嵌入拼接</td><td>标签、简单特征</td><td>低</td><td>中等</td><td>低</td></tr><tr class="odd"><td>自适应归一化</td><td>图像、空间条件</td><td>中</td><td>高</td><td>中</td></tr><tr class="even"><td>CLIP引导</td><td>文本、零样本</td><td>低（无需训练）</td><td>中等</td><td>高</td></tr></tbody></table><h3 id="stablediffusion中是如何注入文本信息的">15.StableDiffusion中是如何注入文本信息的?</h3><p>在 Stable Diffusion 模型中，文本信息的注入主要通过以下步骤实现：</p><ol type="1"><li><strong>文本编码：</strong>首先，输入的文本提示（prompt）通过预训练的 CLIP（ContrastiveLanguage-ImagePre-training）文本编码器进行处理，生成对应的文本嵌入向量。</li><li><strong>交叉注意力机制：</strong> 在 U-Net 结构的解码器部分，StableDiffusion引入了交叉注意力（Cross-Attention）机制。具体而言，文本嵌入向量作为“键”（Key）和“值”（Value），而图像特征作为“查询”（Query），通过交叉注意力机制使模型能够在生成图像的过程中关注与文本描述相关的特征。</li><li><strong>条件融合：</strong>通过交叉注意力机制，文本信息被有效地融合到图像生成过程中，使得生成的图像与输入的文本提示相匹配。</li></ol><p>通过上述机制，Stable Diffusion能够在图像生成过程中有效地利用文本信息，实现从文本到图像的生成。</p><h3 id="latent-diffusionldm相比ddpm有哪些改进">16. LatentDiffusion(LDM)相比DDPM有哪些改进？</h3><p><strong>潜在扩散模型（Latent Diffusion Models, LDM）</strong> 相较于<strong>去噪扩散概率模型（Denoising Diffusion Probabilistic Models,DDPM）</strong>，主要在以下方面进行了改进：</p><ol type="1"><li><strong>在潜在空间进行扩散过程：</strong><ul><li><strong>DDPM：</strong>直接在高维的像素空间中进行扩散和去噪过程，处理高分辨率图像时计算开销较大。</li><li><strong>LDM：</strong>首先使用自动编码器（Autoencoder）将图像映射到低维的潜在空间，然后在该潜在空间中进行扩散过程，最后通过解码器将生成的潜在表示还原为图像。这样显著降低了计算资源的需求，提高了训练和推理效率。</li></ul></li><li><strong>引入条件生成机制：</strong><ul><li><strong>DDPM：</strong>主要用于无条件生成任务，缺乏对特定条件的控制能力。</li><li><strong>LDM：</strong>通过交叉注意力（Cross-Attention）机制，将条件信息（如文本描述）融入扩散过程，使模型能够在生成过程中接受特定条件的引导，实现条件生成。</li></ul></li></ol><h3 id="diffusion中timestep的作用是什么diffusion是如何添加timestep信息的">16.Diffusion中timestep的作用是什么？diffusion是如何添加timestep信息的?</h3><p><strong>timestep 的作用</strong></p><ul><li><p><strong>控制噪声添加和去除的过程</strong>：</p><p>前向过程中模型逐步向数据添加噪声，每个时间步对应一个特定的噪声水平，直至数据接近于纯噪声。时间步决定了在每一步中添加的噪声量。</p><p>反向过程中模型从纯噪声开始，逐步去除噪声以生成数据。时间步在此过程中指示了当前去噪的阶段和程度。</p></li><li><p><strong>作为模型的输入条件</strong>：时间步信息被作为额外的输入提供给模型，帮助模型了解当前数据所处的扩散阶段，以便模型能够根据不同的时间步来学习相应的去噪策略，准确地预测和去除噪声，生成更准确的样本。</p></li></ul><p><strong>添加 timestep 信息的方式</strong></p><ul><li><p><strong>嵌入到模型输入中</strong>：通常将时间步编码为一个低维向量，然后将其与输入数据进行拼接。例如，将时间步表示为一个独热编码向量，或者通过一个可学习的嵌入层将时间步映射为一个固定维度的向量，再与图像的特征向量等进行拼接，一起输入到神经网络中进行处理。这样，模型在处理数据时就能够同时利用时间步信息和数据本身的特征来进行去噪操作。</p></li><li><p><strong>融合到模型结构中</strong>：除了将时间步作为输入嵌入外，还可以将时间步信息融入到模型的结构中。例如，在一些扩散模型中，会根据时间步来调整模型中的一些参数或模块，使得模型能够根据不同的时间步自适应地调整去噪过程。常见的做法是使用时间步相关的权重矩阵或偏置项，在模型的卷积层、全连接层等操作中引入时间步的影响，从而让模型能够更好地捕捉不同时间步下数据的特点和噪声分布。</p><p>常用的方法是正弦-余弦位置编码（sinusoidal positionalencoding），其公式如下：</p><p>- 对于位置 $ t $ 和维度索引 $ i $：</p><p>- $ PE(t, 2i) = () $</p><p>- $PE(t, 2i+1) = () $</p><p>其中，$ d $是嵌入向量的维度。这种编码方式能够捕捉时间步的周期性变化，为模型提供多尺度的特征表示，帮助模型在生成过程中做出更加精确的去噪决策。</p></li></ul><h3 id="什么是noise-scheduler扩散模型中的参数和分别代表什么">17.什么是noise scheduler(扩散模型中的参数和分别代表什么)?</h3><p>在扩散模型中，<strong>噪声调度器（Noise Scheduler）</strong>是控制前向扩散过程（逐步加噪）和反向生成过程（逐步去噪）的关键组件。确保模型在训练和生成阶段的有效性。它定义了以下核心内容：</p><ol type="1"><li><strong>每个时间步 $ t $的噪声强度</strong>（如何逐步破坏数据）。</li><li><strong>反向生成时的参数</strong>（如何逐步恢复数据）。</li></ol><p>其核心参数和公式通常围绕 <strong>噪声方差 <span class="math inline">\(\beta_t\)</span></strong> 和 <strong>累积调度系数<span class="math inline">\(\alpha_t\)</span></strong>展开。以下是对噪声调度器的详细说明：</p><p><strong>噪声调度器的核心参数</strong></p><p><strong>(1) <span class="math inline">\(\beta_t\)</span>（噪声方差）</strong></p><ul><li><strong>定义</strong>：在时间步 $ t $添加的高斯噪声的方差（即噪声强度）。</li><li><strong>取值范围</strong>：$ _t (0, 1) $，通常随着 $ t $增加而单调递增。</li><li><strong>作用</strong>：控制每一步加噪的幅度。较大的 $ _t $表示当前步添加的噪声更多。</li><li><strong>常见调度策略</strong>：<ul><li><strong>线性调度</strong>：$ <em>t = </em>{} + (<em>{} - </em>{})$。</li><li><strong>余弦调度</strong>：$ _t = 1 - $，其中 $ _t = ( )$（改进的噪声衰减）。</li><li><strong>平方调度</strong>：$ <em>t = (</em>{}^{0.5} + (<em>{}^{0.5}- </em>{}^{0.5})) )^2 $。</li></ul></li></ul><p><strong>(2) <span class="math inline">\(\alpha_t\)</span>（保留系数）</strong></p><ul><li><strong>定义</strong>：累积保留的原始信号比例，满足 $ _t = 1 - _t$。</li><li><strong>物理意义</strong>：表示在时间步 $ t $，原始数据 $ x_0 $的保留强度。例如，$ _t = 0.8 $ 表示当前步保留了 80% 的原始信号，添加了20% 的噪声。</li><li><strong>随时间衰减</strong>：随着 $ t $ 增大，$ _t $逐渐减小（保留的信号越来越少）。</li></ul><p><strong>(3) <span class="math inline">\(\bar{\alpha}_t\)</span>（累积调度系数）</strong></p><ul><li><p><strong>定义</strong>：从初始时间步到时间步 $ t $的累积保留系数： <span class="math display">\[\bar{\alpha}_t = \prod_{i=1}^t \alpha_i = \prod_{i=1}^t (1 - \beta_i)\]</span></p></li><li><p><strong>作用</strong>：允许直接从 $ x_0 $ 计算任意时间步 $ x_t $的加噪结果（无需逐步迭代）： <span class="math display">\[x_t = \sqrt{\bar{\alpha}_t} \cdot x_0 + \sqrt{1 - \bar{\alpha}_t} \cdot\epsilon, \quad \epsilon \sim \mathcal{N}(0, I)\]</span></p></li></ul><p><strong>(4) <span class="math inline">\(\sigma_t\)</span>（反向过程的噪声校正项）</strong></p><ul><li><strong>定义</strong>：在反向生成过程中，控制采样步骤的噪声强度（如DDIM中的确定性生成需要调整$ _t $）。</li><li><strong>常见设置</strong>：<ul><li><strong>随机采样（DDPM）</strong>：$ _t = $。</li><li><strong>确定性采样（DDIM）</strong>：$ _t = 0 $。</li></ul></li></ul><p><strong>噪声调度器的核心公式</strong></p><p><strong>(1) 前向扩散过程</strong> <span class="math display">\[q(x_t \mid x_{t-1}) = \mathcal{N}\left(x_t; \sqrt{1 - \beta_t} \cdotx_{t-1}, \beta_t I \right)\]</span> 或直接计算任意 $ x_t <span class="math inline">\(：\)</span>$x_t = x_0 + $$</p><p><strong>(2) 反向生成过程</strong> <span class="math display">\[p_\theta(x_{t-1} \mid x_t) = \mathcal{N}\left(x_{t-1}; \mu_\theta(x_t,t), \sigma_t^2 I \right)\]</span> 其中均值的预测通常与噪声调度参数相关： <span class="math display">\[\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t -\frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t)\right)\]</span></p><p><strong>噪声调度器的作用</strong></p><ol type="1"><li><strong>控制前向加噪速度</strong>：<ul><li>线性调度：早期加噪较慢，后期加速。<br></li><li>余弦调度：早期和后期加噪较慢，中期较快，避免两端噪声突变。<br></li><li>平方调度：更平缓的噪声增加，适合高分辨率图像生成。</li></ul></li><li><strong>影响训练稳定性</strong>：<ul><li>若 $ _t $ 过大，数据会过快被破坏，模型难以学习有效去噪。<br></li><li>若 $ _t $ 过小，需要更多时间步 $ T $才能将数据破坏为噪声，增加计算成本。</li></ul></li><li><strong>决定生成质量与速度</strong>：<ul><li>某些调度器（如DDIM）允许大步长跳跃采样（减少总步数 $ T$），加速生成。<br></li><li>调度器的选择直接影响生成结果的清晰度和多样性。</li></ul></li></ol><hr><p><strong>常见噪声调度器类型</strong></p><table><colgroup><col style="width: 18%"><col style="width: 51%"><col style="width: 30%"></colgroup><thead><tr class="header"><th><strong>调度器</strong></th><th><strong>特点</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr class="odd"><td><strong>DDPM（线性）</strong></td><td>线性增加 $ _t $，简单但可能生成模糊</td><td>基础扩散模型</td></tr><tr class="even"><td><strong>DDIM（确定性）</strong></td><td>允许大步长跳跃采样，生成速度快，质量高</td><td>快速生成（如Stable Diffusion）</td></tr><tr class="odd"><td><strong>Cosine</strong></td><td>基于余弦函数调整 $ {}_t $，噪声变化更平滑</td><td>高质量图像生成（如改进版DDPM）</td></tr><tr class="even"><td><strong>PNDM</strong></td><td>结合伪数值方法，平衡速度与质量</td><td>低步数采样（如20步生成）</td></tr><tr class="odd"><td><strong>Karras</strong></td><td>噪声调度偏向后期，适合高分辨率生成</td><td>大模型（如DALL·E 3）</td></tr></tbody></table><p>噪声调度器是扩散模型的“节奏控制器”，通过定义 <span class="math inline">\(\beta_t\)</span> 和 <span class="math inline">\(\alpha_t\)</span>的演化规律，决定了数据被噪声破坏和恢复的路径。其参数选择直接影响模型的训练稳定性、生成速度与质量。理解调度器的数学原理和实际影响，是优化扩散模型性能的关键一步。</p><h3 id="cos-noise-scheduler有什么优点">18. Cos Noisescheduler有什么优点?</h3><p>Cosine NoiseScheduler（余弦噪声调度器）是扩散模型中一种重要的噪声调度策略，它通过余弦函数来调整不同时间步（timestep）的噪声添加或去除的程度，相较于其他调度器，具有以下优点：</p><p><strong>生成样本质量高</strong></p><ul><li><strong>平滑的噪声衰减</strong>：在正向扩散过程中，余弦噪声调度器会根据余弦函数的特性，让噪声的添加和去除过程更加平滑。这有助于模型在反向去噪过程中更好地学习数据的潜在结构，避免因噪声变化过于剧烈而导致的信息丢失或生成结果的不稳定性，从而生成更加清晰、细节丰富且符合真实数据分布的样本。</li><li><strong>有效保留数据特征</strong>：余弦调度器在早期阶段会相对缓慢地添加噪声，使得原始数据的关键特征在较长的时间步内得以保留。这为模型在反向去噪时提供了更多有用的信息，有助于模型更准确地恢复出原始数据的特征，提高生成样本的质量和真实性。</li></ul><p><strong>训练效率提升</strong></p><ul><li><strong>适应模型学习能力</strong>：余弦噪声调度器的设计能够更好地匹配模型在不同训练阶段的学习能力。在训练初期，模型对数据的理解还不够深入，此时缓慢的噪声变化可以让模型逐步学习到数据的基本特征；而在训练后期，随着模型能力的提升，噪声的变化速度可以适当加快，使模型能够更快地学习到数据的复杂特征，从而提高整体的训练效率。</li><li><strong>减少训练步数</strong>：由于余弦调度器能够更有效地引导模型学习数据的分布，在某些情况下可以减少达到相同生成质量所需的训练步数。这意味着可以在更短的时间内完成模型的训练，节省计算资源和时间成本。</li></ul><p><strong>数值稳定性好</strong></p><ul><li><strong>避免极端噪声值</strong>：余弦函数的取值范围相对稳定，不会出现像线性调度器那样在某些时间步可能产生极端噪声值的情况。这有助于避免在训练和推理过程中出现数值不稳定的问题，如梯度爆炸或梯度消失，使得模型的训练过程更加稳定可靠。</li><li><strong>提高模型鲁棒性</strong>：稳定的噪声添加和去除过程可以增强模型对不同输入数据的鲁棒性。即使输入数据存在一定的噪声或异常值，模型也能够在余弦噪声调度器的引导下，更稳定地进行去噪和生成操作，减少因数据波动而导致的生成结果变差的情况。</li></ul><blockquote><p>在扩散模型中，<strong>余弦噪声调度（Cosine Noise Schedule）</strong>的公式定义如下：</p><p>首先，定义一个辅助函数：</p><p><span class="math display">\[ \alpha_t = \cos\left(\frac{t / T + s}{1+ s} \cdot \frac{\pi}{2}\right)^2 \]</span></p><p>其中：</p><ul><li>$ t $ 是当前时间步，取值范围为 $ 0 t T $。</li><li>$ T $ 是总的时间步数。</li><li>$ s $ 是一个小的常数偏移量，通常设定为 $ s = 0.008$，控制余弦曲线的平滑程度，用于避免在 $ t = 0 $ 时出现数值问题。</li></ul><p>然后，利用该辅助函数计算前向过程中的方差调度参数 $ _t $：</p><p><span class="math display">\[ \beta_t = \min\left(1 -\frac{f(t+1)}{f(t)}, \beta_{\text{max}}\right) \]</span></p><p>其中：</p><ul><li>$ _{} $ 是设定的最大方差值，用于限制 $ _t $的最大值，防止数值不稳定。</li></ul><p>通过上述公式，余弦调度策略在扩散过程中平滑地调整噪声的添加，使得信噪比（SNR）以余弦函数的形式变化，从而优化模型的性能和生成质量。</p></blockquote><h3 id="guidance-scale较大为什么会破坏噪声预测分布">19. GuidanceScale较大为什么会破坏噪声预测分布？</h3><p>在扩散模型中，<strong>引导尺度（Guidance Scale）</strong>是调节条件生成与无条件生成影响力的超参数。当引导尺度增大时，模型更倾向于遵循给定的条件信息（如文本描述），生成与条件更匹配的内容。然而，过大的引导尺度可能会破坏噪声预测的分布，导致生成质量下降。其原因主要包括：</p><ul><li><strong>过度强调条件信息</strong>：较大的<code>Guidance Scale</code>会使模型过于依赖条件信息，如文本描述或图像特征等。在生成过程中，模型会更倾向于生成与条件信息紧密相关的样本，而忽略了噪声的随机性和多样性。这会导致生成结果过于集中在符合条件信息的局部区域，而偏离了原本噪声预测分布所涵盖的更广泛的可能性空间。</li><li><strong>抑制模型的探索能力</strong>：扩散模型在生成样本时，需要通过对噪声的逐步处理来探索数据空间。<code>Guidance Scale</code>过大时，模型会被强烈引导朝着满足条件信息的方向生成，从而限制了模型对其他潜在数据模式的探索。这使得模型难以充分利用噪声预测分布中的各种可能性，破坏了分布的平衡性和多样性，生成的样本变得单一、缺乏变化。</li><li><strong>加剧模型偏差</strong>：如果<code>Guidance Scale</code>过大，模型可能会对条件信息中的某些特征过度敏感，从而产生偏差。例如，在文本到图像的生成中，对于某些描述性词语可能会过度解读，导致生成的图像在这些特征上表现得过于突出，而与真实数据分布产生偏差。这种偏差会进一步破坏噪声预测分布，使模型生成的样本不符合预期的分布特性。</li></ul><h3 id="有哪些常见的经典的diffusion-models加速方法">20.有哪些常见的/经典的Diffusion models加速方法？</h3><p>扩散模型（Diffusionmodels）虽然在生成任务中表现出色，但生成过程通常较为耗时，因此加速方法的研究很有必要。以下是一些常见且经典的加速方法：</p><p><strong>减少采样步数</strong></p><ul><li>DDIM（Denoising Diffusion Implicit Models）<ul><li><strong>原理</strong>：传统的扩散模型如 DDPM通常需要大量的采样步数来从噪声中恢复出数据。DDIM通过引入确定性的采样过程，打破了正向扩散和反向去噪之间的马尔可夫链关系，使得可以在较少的步数内完成采样，从而显著提高了生成速度。</li><li><strong>优势</strong>：在不显著损失生成质量的前提下，大幅减少了采样所需的时间。</li></ul></li><li>PNDM（Pseudo Numerical Methods for Diffusion Models）<ul><li><strong>原理</strong>：PNDM利用伪数值方法来近似扩散过程，通过构建高阶的数值积分方案，能够在更少的采样步数下达到与传统方法相近的生成效果。它基于对扩散过程的数学建模，采用更高效的算法来预测中间状态，从而减少了不必要的计算步骤。</li><li><strong>优势</strong>：比 DDIM能进一步减少采样步数，提高生成效率。</li></ul></li></ul><p><strong>潜在空间扩散</strong></p><ul><li>Latent Diffusion Models（LDM）<ul><li><strong>原理</strong>：LDM先使用一个预训练的自编码器将高维数据（如图像）映射到低维的潜在空间，然后在这个潜在空间中进行扩散过程。由于潜在空间的维度远低于原始数据空间，计算量和内存需求都大幅降低，从而加速了训练和生成过程。</li><li><strong>优势</strong>：在处理高分辨率数据时，能显著提高计算效率，同时保持较好的生成质量。</li></ul></li></ul><p><strong>并行计算与硬件优化</strong></p><h3 id="sd-xl相比于sd有哪些区别和改进">21.SD-XL相比于SD有哪些区别和改进?</h3><p>Stable Diffusion XL（SDXL）相较于原始的StableDiffusion（SD）在多个方面进行了改进，主要包括整体结构、网络架构、长宽比处理以及裁剪信息的利用。以下是具体的区别和改进：</p><p><strong>整体结构</strong></p><ul><li><strong>多阶段生成</strong>：SD通常采用单阶段的生成方式，直接从噪声生成目标图像。而 SD - XL采用多阶段生成策略，先通过基础模型生成低分辨率的大致图像结构，然后利用精修模型（Refiner）对低分辨率图像进行细化和提升，生成高分辨率、高质量的图像。这种多阶段的方式让图像生成过程更加可控，且能逐步细化图像细节，提高生成质量。</li></ul><p><strong>网络结构改进</strong></p><ul><li><p><strong>更大的 UNet 架构</strong>：SD - XL 的 UNet 网络规模比 SD更大，包含更多的层和通道。SDXL的UNet主干网络参数量约为26亿，是SD1.5版本的三倍以上（约8.6亿）。更大的网络结构使得模型具有更强的特征提取和表达能力，能够学习到更复杂、更细致的图像特征和模式，从而在生成图像时可以呈现出更丰富的细节和更自然的视觉效果。</p></li><li><p><strong>额外的文本编码器</strong>：SD一般使用单个文本编码器将文本提示转换为特征向量。SD - XL引入了额外的文本编码器，例如采用双文本编码器架构，不同的文本编码器可以捕捉文本不同层次的语义信息，使得模型对文本提示的理解更加全面和深入，从而更精准地根据文本生成对应的图像。</p><blockquote><p>SDXL不仅采用了更大的OpenCLIPViT-bigG（参数量为694M），而且同时也用了OpenAI CLIPViT-L/14，<strong>分别提取两个textencoder的倒数第二层特征</strong>，其中OpenCLIPViT-bigG的特征维度为1280，而CLIPViT-L/14的特征维度是768，两个特征concat在一起总的特征维度大小是2048，这也就是SDXL的contextdim。</p></blockquote></li></ul><p><strong>长宽比和 crop 信息处理</strong></p><ul><li><strong>更好的长宽比支持</strong>：传统的SD模型主要在固定尺寸（如512x512或1024x1024像素）的图像上训练，限制了对不同长宽比图像的生成能力。SDXL通过多长宽比训练，允许模型处理多种长宽比的图像。具体方法是将数据集划分为多个桶，每个桶包含相似像素数量但不同长宽比的图像，并在训练时对这些桶进行交替选择，从而增强模型对不同长宽比图像的适应性。</li><li><strong>利用 crop 信息</strong>：在训练过程中，SDXL引入了图像裁剪坐标作为额外的条件参数，模拟训练时的随机裁剪。这使模型在生成图像时能够更好地保持主体完整，避免出现主体被裁剪的情况。通过提供裁剪坐标信息，模型在生成过程中能够更准确地定位和呈现图像主体。</li></ul><h3 id="常见的微调sd方法有哪些并说一下对应的原理">22.常见的微调SD方法有哪些？并说一下对应的原理</h3><p><strong>DreamBooth</strong></p><p><strong>原理</strong>：</p><ul><li><strong>稀有描述词绑定</strong>：为特定概念（如物体或人物）分配一个稀有标识符（如“sks”），并将其与基础类别（如“bag”）结合（如“asks bag”），避免与模型原有知识冲突。<br></li><li><strong>正则化约束</strong>：通过“类别先验保留损失”（class-specificprior preservationloss），在训练时混合模型生成的通用类别图像（如普通书包）和用户提供的特定图像，防止过拟合和语义漂移。<br></li><li><strong>注意力层微调</strong>：主要调整U-Net中的Cross-Attention和Self-Attention层，使文本条件与图像特征更精准对齐，保留模型原有生成能力。</li></ul><p><strong>特点</strong>：</p><ul><li>适合注入特定对象或风格，需3-5张图像；<br></li><li>支持与LoRA结合（如DreamBooth-LoRA），降低显存需求。</li></ul><hr><p><strong>Textual Inversion</strong></p><p><strong>原理</strong>：</p><ul><li><strong>文本嵌入优化</strong>：通过少量图像（3-5张）训练一个新的文本嵌入向量（如“[V]”），将其映射到CLIP文本编码器的潜在空间，使模型理解新概念。<br></li><li><strong>冻结模型权重</strong>：仅优化嵌入向量，不调整SD模型参数，避免灾难性遗忘。<br></li><li><strong>损失函数</strong>：使用均方误差（MSE）计算生成图像与真实图像的噪声残差差异。</li></ul><p><strong>特点</strong>：</p><ul><li>轻量化（仅需存储嵌入向量，大小约几十KB）；<br></li><li>支持多概念注入，但生成效果受嵌入空间表达能力限制。</li></ul><hr><ol start="3" type="1"><li><strong>LoRA（Low-Rank Adaptation）</strong></li></ol><p><strong>原理</strong>：</p><ul><li><strong>低秩矩阵分解</strong>：在模型权重矩阵旁添加低秩矩阵（如 $W_{} = W + BA $，其中 $ B ^{d×r} <span class="math inline">\(，\)</span>A ^{r×k} <span class="math inline">\(，\)</span> r d,k$），仅训练新增的低秩参数。<br></li><li><strong>参数高效性</strong>：通过调整注意力层的Query、Key、Value投影矩阵，适配新任务，减少显存占用（通常仅需1%-5%参数量）。<br></li><li><strong>应用场景</strong>：常与DreamBooth或DataDream结合，优化生成对齐真实数据分布。</li></ul><p><strong>特点</strong>：</p><ul><li>兼容性强，支持快速切换不同任务；<br></li><li>在DataDream中用于生成细粒度特征（如飞机螺旋桨）。</li></ul><hr><ol start="4" type="1"><li><strong>Embedding Fine-Tuning</strong></li></ol><p><strong>原理</strong>：</p><ul><li><strong>全量微调（FullFine-Tuning）</strong>：直接调整SD模型的所有参数，适配新数据集。计算成本高，易导致过拟合。<br></li><li><strong>参数高效微调（PEFT）</strong>：仅微调部分层（如文本编码器或U-Net高层），平衡性能与计算效率。</li></ul><p><strong>特点</strong>：</p><ul><li>全量微调适合大规模数据，但需高算力；<br></li><li>PEFT方法（如Prefix Tuning）通过调整提示词前缀优化生成效果。</li></ul><hr><ol start="5" type="1"><li><strong>DataDream（结合LoRA的合成数据生成）</strong></li></ol><p><strong>原理</strong>：</p><ul><li><strong>LoRA微调生成器</strong>：使用少量真实图像微调SD的LoRA权重，使生成图像更贴近真实分布（如准确呈现“衣物熨斗”而非模糊金属物体）。<br></li><li><strong>多模式优化</strong>：分两种策略：<ul><li><strong>DataDream-cls</strong>：为每个类别单独训练LoRA；<br></li><li><strong>DataDream-dset</strong>：为整个数据集训练统一LoRA。<br></li></ul></li><li><strong>损失对齐</strong>：通过CLIP特征对比损失，确保生成数据与真实数据语义一致。</li></ul><hr><ol start="6" type="1"><li><strong>World Knowledge Distillation（WKD）与Tool UsageAdaptation（TUA）</strong></li></ol><p><strong>原理</strong>：</p><ul><li><strong>知识蒸馏（WKD）</strong>：通过工具生成答案供模型学习，积累领域知识（如科学问题解答）；<br></li><li><strong>工具使用适配（TUA）</strong>：模型动态选择依赖内部知识或外部工具，提升复杂问题解决能力（如判断是否调用计算器）。</li></ul><hr><p><strong>方法对比</strong></p><table style="width:100%;"><colgroup><col style="width: 19%"><col style="width: 26%"><col style="width: 13%"><col style="width: 13%"><col style="width: 27%"></colgroup><thead><tr class="header"><th><strong>方法</strong></th><th><strong>核心调整对象</strong></th><th><strong>数据需求</strong></th><th><strong>计算成本</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr class="odd"><td>DreamBooth</td><td>U-Net注意力层</td><td>3-5张图像</td><td>中</td><td>特定对象/风格注入</td></tr><tr class="even"><td>Textual Inversion</td><td>文本嵌入向量</td><td>3-5张图像</td><td>低</td><td>轻量化概念扩展</td></tr><tr class="odd"><td>LoRA</td><td>低秩矩阵参数</td><td>少量数据</td><td>低</td><td>参数高效适配多任务</td></tr><tr class="even"><td>DataDream</td><td>LoRA权重 + 生成分布对齐</td><td>少量真实数据</td><td>中</td><td>合成数据增强下游分类任务</td></tr><tr class="odd"><td>WKD+TUA</td><td>知识蒸馏与工具选择逻辑</td><td>领域数据集</td><td>高</td><td>复杂问题解答与工具协同</td></tr></tbody></table><h3 id="controlnet的原理是什么">23. ControlNet的原理是什么？</h3><p>ControlNet是一种神经网络架构，旨在为大型预训练文本到图像的扩散模型（如StableDiffusion）添加额外的条件控制，允许模型在生成图像时遵循特定的输入条件，如边缘图、深度图、姿势关键点等，从而实现对生成内容的精确控制。</p><p><strong>ControlNet的核心原理包括：</strong></p><ol type="1"><li><strong>模型复制与权重锁定：</strong> 将预训练的扩散模型（例如StableDiffusion）的权重复制出两个副本：一个是“锁定”副本（lockedcopy），保持原始模型的权重不变；另一个是“可训练”副本（trainablecopy），用于在引入额外条件的情况下进行训练。</li><li><strong>条件注入模块：</strong>新增一个并行的网络分支，将外部条件（如边缘图、深度图）编码后融入主网络。在“可训练”副本中，使用权重和偏置均初始化为零的1×1卷积层（称为“<strong>零卷积</strong>”）。<strong>这种设计确保在训练初期，新增的条件控制不会对原始模型的性能产生干扰，随着训练的进行，零卷积的参数逐渐从零增长，学习新的条件控制。</strong></li><li><strong>梯度隔离</strong>：通过控制训练信号的传播，防止微调过程破坏原始模型的泛化性。</li></ol><p><strong>核心组件与流程</strong></p><p><strong>(1) 网络结构拆分</strong></p><ul><li><strong>锁定副本（Locked Copy）</strong>： 复制原始 UNet编码器的权重并冻结，保留其预训练知识。</li><li><strong>可训练副本（Trainable Copy）</strong>：复制相同结构，但权重可训练，用于融合外部条件信息。</li></ul><p><strong>(2) 条件编码与融合</strong></p><ol type="1"><li><p><strong>条件输入处理</strong>：外部条件（如边缘图）通过特定编码器（如 Canny边缘检测）转换为与图像特征尺寸匹配的张量。</p></li><li><p><strong>特征融合</strong>：条件特征与可训练副本的输出相加，再通过零卷积调整权重后与锁定副本的特征相加：<span class="math display">\[F_{\text{out}} = F_{\text{locked}} +\text{ZeroConv}(F_{\text{trainable}} + C)\]</span></p><ul><li>$ C $：编码后的条件特征<br></li><li>$ $：初始权重为零的卷积层，逐步学习条件影响。</li></ul></li></ol><p><strong>(3) 零卷积（Zero Convolution）</strong></p><ul><li><strong>定义</strong>：卷积层的权重和偏置初始化为零，保证训练初期条件分支的输出为零，避免干扰原始模型。</li><li><strong>作用</strong>：<ul><li>训练初期：条件分支无贡献，模型行为与原始扩散模型一致。<br></li><li>训练后期：逐步激活条件控制，平滑过渡到条件生成模式。</li></ul></li></ul><hr><p><strong>训练与推理过程</strong></p><p><strong>(1) 训练阶段</strong></p><ul><li><p><strong>目标</strong>：最小化生成图像与真实图像的噪声残差差异，同时对齐条件信号。</p></li><li><p><strong>损失函数</strong>： <span class="math display">\[\mathcal{L} = \mathbb{E}_{x_0, c, t, \epsilon} \left[ \| \epsilon -\epsilon_\theta(x_t, t, c) \|^2 \right]\]</span></p><ul><li>$ c $：外部条件（如边缘图）<br></li><li>$ _$：包含 ControlNet 的噪声预测网络。</li></ul></li></ul><p><strong>(2) 推理阶段</strong></p><ul><li><strong>条件输入</strong>：用户提供控制图（如人体姿势骨架图），模型按条件生成对应图像。</li><li><strong>灵活控制</strong>：支持多条件组合（如同时使用边缘+深度图），通过权重调整各条件的影响强度。</li></ul><hr><p><strong>支持的常见条件类型</strong></p><table><colgroup><col style="width: 21%"><col style="width: 44%"><col style="width: 33%"></colgroup><thead><tr class="header"><th><strong>条件类型</strong></th><th><strong>编码方式</strong></th><th><strong>应用场景</strong></th></tr></thead><tbody><tr class="odd"><td><strong>Canny 边缘</strong></td><td>Canny 边缘检测</td><td>保留物体轮廓的结构生成</td></tr><tr class="even"><td><strong>深度图</strong></td><td>MiDaS 深度估计</td><td>3D 空间层次控制</td></tr><tr class="odd"><td><strong>人体姿势</strong></td><td>OpenPose 关键点检测</td><td>人物动作与姿态控制</td></tr><tr class="even"><td><strong>语义分割图</strong></td><td>语义分割模型（如 Mask R-CNN）</td><td>物体类别与布局控制</td></tr><tr class="odd"><td><strong>涂鸦草图</strong></td><td>用户手绘线条</td><td>自由创作与构图引导</td></tr></tbody></table><p><strong>ControlNet的优势在于：</strong></p><ul><li><strong>精确控制生成内容：</strong>通过引入额外的条件输入，用户可以在生成图像时对姿势、轮廓、深度等特征进行精确控制，满足特定需求。</li><li><strong>保留原始模型能力：</strong>由于“锁定”了原始模型的权重，ControlNet在引入新条件的同时，保留了原始模型在大规模数据集上学习到的生成能力，避免对原始性能的破坏。</li><li><strong>高效训练：</strong>通过使用零卷积层，ControlNet在训练新条件时避免了随机噪声的干扰，使训练过程更加稳定和高效。</li></ul><h3 id="为什么stablediffusion可能会出现细节信息失真">24.为什么StableDiffusion可能会出现细节信息失真？</h3><ul><li><strong>计算资源与算法限制</strong>：AI在生成图像时受到计算能力与算法的限制，无法完美模拟真实世界的细节。要生成一个特定尺寸的图像，模型需要进行一系列运算，包括模板提取、特征表示、搜索和匹配等，这些都需要计算资源。在有限的资源下，对图像不同部分的优化可能会增加计算成本，可能会简化处理流程，从而导致细节信息失真。</li><li><strong>图像分辨率问题</strong>： StableDiffusion的性能依赖于其训练数据集的质量和多样性。如果训练数据中缺乏高分辨率或细节丰富的图像，模型在生成时可能无法准确再现复杂的细节。</li><li><strong>训练数据偏差</strong>：如果训练数据集中包含了大量高清的半身像而非全身像，StableDiffusion模型可能会倾向于专注于处理这些半身像。由于全身像包含更多的图像元素和更高的维度，模型在绘制时需要投入更多的计算能力。因此，它在半身像的处理上可能会更有优势，而在生成全身像等其他类型图像时，可能出现细节失真的情况。</li><li><strong>生成算法的局限性</strong>：当前的生成算法在处理尺寸不同的对象时，可能存在一些限制。例如，脸部区域是一个复杂且细节丰富的部分，而当算法处理全身图像时，可能难以保持对脸部细节质量的关注，从而导致细节信息失真。</li><li><strong>采样器的影响</strong>：不同的采样器在生成图像时会有不同的表现。例如，Euler采样器速度快，但可能导致一些图像细节受损，因为过度的去噪可能会丢失一些微妙的边缘信息。一些采样器为了换取生成速度的提升，会牺牲一定的图像质量。</li><li><strong>参数设置不当</strong>：如重绘幅度、Eulera值等参数设置不合适会影响生成图像的质量。重绘幅度较小时，生成的图像可能会比较模糊或粗糙；重绘幅度较大时，生成的图像可能会出现明显的噪点或瑕疵。适当的Eulera值能够捕捉到细节和纹理，但如果值太大会导致过度拟合，生成图像出现噪点等不良效果。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h3 id=&quot;生成对抗网络gans请解释gans是什么以及它们的构成要素&quot;&gt;1.
生成对抗网络（GANs）：请解释GANs是什么，以及它们的构成要素&lt;/h3&gt;
&lt;p&gt;生成对抗网络（G</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="http://junlei-zhou.com/2024/07/25/transformer-description/"/>
    <id>http://junlei-zhou.com/2024/07/25/transformer-description/</id>
    <published>2024-07-25T06:22:27.000Z</published>
    <updated>2025-04-01T07:14:05.528Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="transformer-attention-is-all-you-need">Transformer: Attention IsAll You Need</h1><h2 id="网络结构">网络结构</h2><p>整体架构，Transformer由两部分构成，Encoder和Decoder。都包含了6个<strong><em><span style="color: #ff7700">block</span></em></strong></p><p><img src="https://imgur.la/images/2024/07/25/PPKV7RHB.png" alt="PPKV7RHB" border="0"></p><h2 id="section"></h2><h2 id="第一步获取输入句子的每一个单词的表示向量-xx-由单词的-embeddingembedding就是从原始数据提取出来的feature-和单词位置的-embedding-相加得到">第一步：获取输入句子的每一个单词的表示向量<span class="math inline">\(X\)</span><strong><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">，</span></span></strong><span class="math inline">\(X\)</span> 由单词的Embedding（Embedding就是从原始数据提取出来的Feature） 和单词位置的Embedding 相加得到。</h2><p><img src="https://imgur.la/images/2024/07/25/YR9I534X.png" alt="YR9I534X" border="0"></p><center><p>Transformer的输入表示</p></center><ul><li><p>词Embedding方法：<a href="https://arxiv.org/abs/1301.3781">Word2Vec</a> 这种方式在 2018年之前比较主流，但是随着 BERT、GPT2.0的出现，这种方式已经不算效果最好的方法了), <a href="https://aclanthology.org/D14-1162/">Glove</a>等算法预训练得到，也可以在 Transformer 中训练得到。</p></li><li><p>位置Embedding方法：Transformer与RNN不同，Transformer是统观全局将所有单词的位置信息也进行编码作为输入，而RNN则是使用单词的顺序信息，通过使用前一步的输出作为当前步的输入来获取位置信息。</p><p>通常，位置 Embedding 用 <strong>PE</strong>表示。<strong>PE</strong> 的维度与单词 Embedding 是一样的。PE可以通过训练得到，也可以使用某种公式计算得到。在 Transformer中采用了后者，计算公式如下：</p></li></ul><p><span class="math display">\[PE_{(pos,2i)}=sin(pos/10000^{2i/d}) \\PE_{(pos,2i+1)}=cos(pos/10000^{2i/d})\]</span></p><p>其中，pos 表示单词在句子中的位置，<span class="math inline">\(d\)</span> 表示 <strong>PE</strong> 的维度 (与词Embedding 一样)，<span class="math inline">\(2i\)</span>表示偶数的维度，<span class="math inline">\(2i+1\)</span> 表示奇数维度(即 <span class="math inline">\(2i≤d, 2i+1≤d\)</span>)。使用这种公式计算<strong>PE</strong> 有以下的好处：</p><ul><li><p>使 PE能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第21 位的 Embedding。</p></li><li><p>可以让模型容易地计算出相对位置，对于固定长度的间距 <span class="math inline">\(k\)</span>，<strong>PE(pos+k)</strong>可以用 <strong>PE(pos)</strong>计算得到。因为 <span class="math display">\[Sin(A+B) = Sin(A)Cos(B) + Cos(A)Sin(B),\\Cos(A+B) = Cos(A)Cos(B) - Sin(A)Sin(B)\]</span></p></li></ul><p><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">将单词的词 Embedding 和位置Embedding 相加，就可以得到单词的表示向量 </span></span><strong><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">x</span></span></strong><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">，</span></span><strong><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">x </span></span></strong><span style="color: rgb(18, 18, 18)"><span style="background-color: rgb(255, 255, 255)">就是 Transformer的输入。</span></span></p><blockquote><p><strong>为什么Transformer能够识别词 Embedding 和位置 Embedding相加后的编码？</strong></p><p>充足的训练数据能够保证Transformer理解出这种特殊的"词向量+位置编码"的编码格式。</p></blockquote><h2 id="第二步将得到的单词表示向量矩阵-如上图所示每一行是一个单词的表示-x-传入-encoder-中经过-6-个-encoder-block-后可以得到句子所有单词的编码信息矩阵-c">第二步：将得到的单词表示向量矩阵(如上图所示，每一行是一个单词的表示 x) 传入 Encoder 中，经过 6 个Encoder block 后可以得到句子所有单词的编码信息矩阵 C</h2><p>如下图。单词向量矩阵用 <span class="math inline">\(X_{n×d}\)</span>表示， <span class="math inline">\(n\)</span> 是句子中单词个数，<span class="math inline">\(d\)</span> 是表示向量的维度 (论文中 <span class="math inline">\(d=512\)</span>)。每一个 Encoder block输出的矩阵维度与输入完全一致。</p><p><img src="https://imgur.la/images/2024/07/25/BWNSQFCB.png" alt="BWNSQFCB" border="0" style="zoom:50%;"></p><center><p>Transformer Encoder 编码句子信息</p></center><h3 id="encoder-block">Encoder  block</h3><p>        <img src="https://imgur.la/images/2024/07/25/architecture.png" alt="architecture" border="0" style="zoom:50%;"></p><p>左侧为 <strong>Encoder block</strong>，右侧为 <strong>Decoderblock</strong>。<strong>Multi-HeadAttention</strong>，是由多个 <strong>Self-Attention</strong>组成的，可以看到 <strong>Encoder block</strong> 包含一个<strong>Multi-Head Attention</strong>，而 <strong>Decoder block</strong>包含两个 <strong>Multi-Head Attention</strong> (其中有一个用到Masked)。<strong>Add &amp; Norm</strong> 层，Add 表示残差连接 (ResidualConnection) 用于防止网络退化，<strong>Norm</strong> 表示 LayerNormalization，用于对每一层的激活值进行归一化。</p><h4 id="self-attention-结构"><strong>Self-Attention 结构</strong></h4><p><img src="https://imgur.la/images/2024/07/25/3FSEDRY4.png" alt="3FSEDRY4" border="0" style="zoom:50%;"></p><p>在进行softmax之前，必须要对注意力进行Scale（即对应公式中的除以<span class="math inline">\(\sqrt{d_k}\)</span>），对 <strong>Q</strong> 和<strong>K</strong> 的点积进行缩放。</p><blockquote><p><strong>进行Scale的作用：</strong></p><p><strong>防止数值不稳定性：</strong> 当 <span class="math inline">\(d_k\)</span>较大时，未经缩放的点积结果可能会变得非常大，导致 Softmax函数的输入值过大，从而使得梯度变得极小，可能引发梯度消失问题。通过除以<span class="math inline">\(\sqrt{d_k}\)</span>，可以将点积结果的数值范围控制在一个合理的范围内，避免数值不稳定性。</p><p><strong>保持梯度的有效性：</strong>缩放因子有助于保持梯度的有效性，避免在反向传播过程中出现梯度消失或爆炸的情况，从而提高模型的训练稳定性。</p><!--假设查询向量 $\mathbf{q}$ 和键向量 $k\mathbf{k}$ 的各分量独立同分布，均值为 0，方差为 1。它们的点积 $\mathbf{q} \cdot \mathbf{k}$ 的均值为 0，方差为 $d_k$。为了防止点积的方差随维度 $d_k$ 增加而变大，需要对其进行缩放处理。通过将点积除以 $\sqrt{d_k}$，可以使缩放后的点积的方差为 1，与 $d_k$ 无关。--></blockquote><h5 id="qquerykkeyvvalue"><strong>Q(Query)、K(Key)、V(Value)</strong></h5><p>计算自注意力的第一步是从编码器的每个输入向量（在本例中为每个单词的嵌入）创建三个向量。因此，对于每个单词，我们创建一个<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>。<strong>WQ</strong>、<strong>WK</strong>、<strong>WV</strong>三个矩阵是在训练的时候创建的。</p><p><img src="https://imgur.la/images/2024/07/25/V97S38NR.png" alt="V97S38NR" border="0" style="zoom:50%;"></p><h5 id="self-attention计算输出即计算self-attention的分数"><strong>Self-Attention计算输出(即计算self-Attention的分数）</strong></h5><p>假设我们正在计算这个例子中第一个词“我”的自我注意力。我们需要根据这个单词对输入句子的每个单词进行评分。分数决定了当我们在某个位置对单词进行编码时，对输入句子的其他部分的关注程度。</p><p><span class="math display">\[Attention（Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}}V)\]</span></p><p>公式中计算矩阵 <span class="math inline">\(Q\)</span> 和 <span class="math inline">\(K\)</span>每一行向量的内积，为了防止内积过大，因此除以 <span class="math inline">\(d_k\)</span> 的平方根。<span class="math inline">\(Q\)</span> 乘以 <span class="math inline">\(K\)</span> 的转置后，得到的矩阵行列数都为 <span class="math inline">\(n\)</span>，<span class="math inline">\(n\)</span>为句子单词数，这个矩阵可以表示单词之间的 attention 强度。下图为 <span class="math inline">\(Q\)</span> 乘以<span class="math inline">\(K^T\)</span>，1234 表示的是句子中的单词。</p><p><img src="https://imgur.la/images/2024/07/25/BY3PA8IB.png" alt="BY3PA8IB" border="0"></p><p>得到 <span class="math inline">\(QK^T\)</span>之后，使用 Softmax计算每一个单词对于其他单词的 attention 系数，公式中的 Softmax是对矩阵的每一行进行 Softmax，即每一行的和都变为 1. softmax分数决定了每个单词在此位置的表达量。显然，这个位置的单词将具有最高的softmax分数，但有时关注与当前单词相关的另一个单词是有用的。</p><p><img src="https://imgur.la/images/2024/07/25/YAAYRBU9.png" alt="YAAYRBU9" border="0"></p><p>得到 Softmax 矩阵之后可以和 <span class="math inline">\(V\)</span>相乘，得到最终的输出 <span class="math inline">\(Z\)</span>.</p><p><img src="https://imgur.la/images/2024/07/25/IEIZUYE5.png" alt="IEIZUYE5" border="0"></p><p>Softmax 矩阵的第 1 行表示单词 1 与其他所有单词的 attention系数，最终单词 1 的输出 <span class="math inline">\(V_i\)</span> 等于所有单词 i 的值 <span class="math inline">\(V_i\)</span> 根据 attention系数的比例加在一起得到，如下图所示：</p><p><img src="https://imgur.la/images/2024/07/25/B6LPEG5N.png" alt="B6LPEG5N" border="0"></p><h4 id="multi-head-attention">Multi-Head Attention</h4><p>Multi-Head Attention 包含多个 Self-Attention 层，首先将输入 <span class="math inline">\(X\)</span> 分别传递到 <span class="math inline">\(h\)</span> 个不同的 Self-Attention 中，计算得到<span class="math inline">\(h\)</span> 个输出矩阵 <span class="math inline">\(Z\)</span>。下图是 <span class="math inline">\(h=8\)</span> 时候的情况，此时会得到 8 个输出矩阵<span class="math inline">\(Z\)</span>.</p><p><img src="https://imgur.la/images/2024/07/25/ILJMUQNZ.png" alt="ILJMUQNZ" border="0" style="zoom:50%;"></p><p>得到 8 个输出矩阵 <span class="math inline">\(Z1\)</span> 到 <span class="math inline">\(Z8\)</span> 之后，Multi-Head Attention将它们拼接在一起 (Concat)，然后传入一个<strong>Linear</strong> 层，得到Multi-Head Attention 最终的输出 <span class="math inline">\(Z\)</span>。Multi-Head Attention 输出的矩阵 <span class="math inline">\(Z\)</span> 与其输入的矩阵 <span class="math inline">\(X\)</span> 的维度是一样的。</p><p><img src="https://imgur.la/images/2024/07/25/T7JWQ9UY.png" alt="T7JWQ9UY" border="0"></p><h5 id="add-norm">Add &amp; Norm</h5><p>Add &amp; Norm 层由 Add 和 Norm 两部分组成,</p><p><span class="math display">\[LayerNorm(X+MultiHeadAttention(X)) \\LayerNorm(X+FeedForward(X))\]</span></p><p>其中 <span class="math inline">\(X\)</span> 表示 Multi-Head Attention或者 Feed Forward 的输入，MultiHeadAttention(<span class="math inline">\(X\)</span>) 和 FeedForward(<span class="math inline">\(X\)</span>) 表示输出 (输出与输入 <span class="math inline">\(X\)</span>维度是一样的，所以可以相加)。<strong>Add</strong> 指 <span class="math inline">\(X\)</span>+MultiHeadAttention(<span class="math inline">\(X\)</span>)，是一种残差连接，通常用于解决多层网络训练的问题，可以让网络只关注当前差异的部分：</p><p><img src="https://imgur.la/images/2024/07/25/E5CVMKZS.png" alt="E5CVMKZS" border="0"></p><p><strong>Norm</strong> 指 Layer Normalization，通常用于 RNN结构，Layer Normalization会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。</p><h5 id="feed-forward">Feed forward</h5><p><strong>Feed Forward</strong>是一个两层的全连接层，第一层的激活函数为Relu，第二层不使用激活函数，对应的公式如下: <span class="math display">\[FFN(x)=max(0,xW_1+b_1)W_2+b_2\]</span></p><p>通过 <strong>Multi-Head Attention, Add &amp; Norm, Feedforward</strong> 三个部分可以构成一个<strong>Encoder Block,EncoderBlock</strong> 通过接收输入 <span class="math inline">\(X_{(n×d)}\)</span>,并通过 <strong>EncoderBlock</strong> 得到输出 <span class="math inline">\(O_{(n×d)}\)</span>，通过多个 <strong>Encoderblock</strong> 叠加就可以组成 <strong>Encoder</strong>。经过<strong>Encoder</strong> 部分我们可以得到信息编码矩阵 <span class="math inline">\(C\)</span>。</p><h2 id="第三步将-encoder-输出的编码信息矩阵-c-传递到-decoder-中decoder-依次会根据当前翻译过的单词-1sim-i翻译下一个单词-i1如下图所示在使用的过程中翻译到单词-i1-的时候需要通过-mask操作遮盖住-i1-之后的单词">第三步：将Encoder 输出的编码信息矩阵 <span class="math inline">\(C\)</span> 传递到Decoder 中，Decoder 依次会根据当前翻译过的单词 <span class="math inline">\(1\sim i\)</span>翻译下一个单词 <span class="math inline">\(i+1\)</span>，如下图所示。在使用的过程中，翻译到单词<span class="math inline">\(i+1\)</span> 的时候需要通过 Mask操作遮盖住<span class="math inline">\(i+1\)</span> 之后的单词。</h2><h3 id="decoder-block">Decoder  block</h3><p><img src="https://imgur.la/images/2024/07/25/architecture.png" alt="architecture" border="0" style="zoom:50%;"></p><center><p>Decoder block 包含两个 Multi-Head Attention 层。</p></center><p>第一个 Multi-Head Attention 层采用了 Masked操作。(在Transformer模型中，使用Masked可以避免在预测当前位置是使用到后续序列中的信息。在预测当前位置时使用未来位置的信息会导致信息泄露和模型过拟合的原因是因为这会造成未来信息的“泄漏”。在自注意力机制中，每个位置都可以与其他位置进行关联，因此如果模型在预测当前位置时使用了未来位置的信息，那么模型实际上是“知道”了未来的信息，这就相当于信息泄漏。信息泄漏会导致模型在训练时过度依赖未来位置的信息，从而导致模型过拟合训练数据，失去了对真实数据的泛化能力。过拟合的模型在未见过的数据上表现不佳，因为它们过度依赖于训练数据中的特定模式和关联，而无法很好地推广到新的数据。因此，在Transformer中，为了避免信息泄漏和过拟合，需要使用masked来确保模型只能使用当前位置之前的信息，这样可以更好地捕捉序列中的依赖关系和上下文信息，同时保持模型的泛化能力)</p><h4 id="第一个multi-head-attentionmasked">第一个Multi-HeadAttention（Masked）：</h4><p>Decoder block 的第一个 Multi-Head Attention 采用了 Masked操作，因为在翻译的过程中是顺序翻译的，即翻译完第 i 个单词，才可以翻译第i+1 个单词。通过 Masked 操作可以防止第 i 个单词知道 i+1个单词之后的信息。以 "我有一只猫" 翻译成 "I have a cat" 为例，在 Decoder的时候，是需要根据之前的翻译，求解当前最有可能的翻译，如下图所示。首先根据输入"<Begin>" 预测出第一个单词为 "I"，然后根据输入 "<Begin> I"预测下一个单词 "have"。</Begin></Begin></p><p><img src="https://imgur.la/images/2024/07/25/3C7JYEUH.png" alt="3C7JYEUH" border="0"></p><p>Decoder 可以在训练的过程中使用 Teacher Forcing并且并行化训练，即将正确的单词序列 (&lt;Begin&gt; I have a cat)和对应输出 (I have a cat &lt;end&gt;) 传递到 Decoder。那么在预测第 i个输出时，就要将第 i+1 之后的单词掩盖住，注意 Mask 操作是在Self-Attention 的 Softmax 之前使用的，下面用 0 1 2 3 4 5 分别表示"&lt;Begin&gt; I have a cat &lt;end&gt;"。</p><p><strong>第一步：</strong>是 Decoder 的输入矩阵和<strong>Mask</strong> 矩阵，输入矩阵包含 "<Begin> I have a cat" (0, 1,2, 3, 4) 五个单词的表示向量，<strong>Mask</strong> 是一个 5×5 的矩阵。在<strong>Mask</strong> 可以发现单词 0 只能使用单词 0 的信息，而单词 1可以使用单词 0, 1 的信息，即只能使用之前的信息。</Begin></p><p><img src="https://imgur.la/images/2024/07/25/IYX8T5F3.png" alt="IYX8T5F3" border="0"></p><center><p>输入矩阵与 Mask 矩阵</p></center><p><strong>第二步：</strong>接下来的操作和之前的 Self-Attention一样，通过输入矩阵 <span class="math inline">\(X\)</span> 计算得到 <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, <span class="math inline">\(V\)</span>矩阵。然后计算 <span class="math inline">\(Q\)</span> 和 <span class="math inline">\(K^T\)</span> 的乘积 <span class="math inline">\(QK^T\)</span> 。</p><p><img src="https://imgur.la/images/2024/07/25/83YBXRLY.png" alt="83YBXRLY" border="0"></p><center><p>Q乘以K的转置</p></center><p><strong>第三步：</strong>在得到 <span class="math inline">\(QK^T\)</span> 之后需要进行 Softmax，计算 attentionscore，我们在 Softmax之前需要使用<strong>Mask</strong>矩阵遮挡住每一个单词之后的信息，遮挡操作如下：</p><p><img src="https://imgur.la/images/2024/07/25/YU3MAKSS.png" alt="YU3MAKSS" border="0"></p><center><p>Softmax 之前 Mask</p></center><p>得到 <strong>Mask</strong> <span class="math inline">\(QK^T\)</span>之后在 <strong>Mask</strong> <span class="math inline">\(QK^T\)</span>上进行 Softmax，每一行的和都为1。但是单词 0 在单词 1, 2, 3, 4 上的 attention score 都为 0。</p><p><strong>第四步：</strong>使用 <strong>Mask</strong> <span class="math inline">\(QK^T\)</span> 与矩阵 <span class="math inline">\(V\)</span> 相乘，得到输出 <span class="math inline">\(Z\)</span>，则单词 1 的输出向量 <span class="math inline">\(Z_1\)</span> 是只包含单词 1 信息的。</p><p><img src="https://imgur.la/images/2024/07/25/2JJ24Y9A.png" alt="2JJ24Y9A" border="0"></p><center><p>Mask 之后的输出</p></center><p><strong>第五步：</strong>通过上述步骤就可以得到一个 MaskSelf-Attention 的输出矩阵 <strong>Zi</strong>，然后和 Encoder 类似，通过Multi-Head Attention 拼接多个输出<strong>Zi</strong> 然后计算得到第一个Multi-Head Attention的输出<strong>Z</strong>，<strong>Z</strong>与输入<strong>X</strong>维度一样。</p><h4 id="第二个-multi-head-attention">第二个 Multi-Head Attention</h4><p>第二个 Multi-Head Attention 层的<strong>K, V</strong>矩阵使用 Encoder的<strong>编码信息矩阵C</strong>进行计算，而<strong>Q</strong>使用上一个Decoder block 的输出计算。根据 Encoder 的输出 <strong>C</strong>计算得到<strong>K, V</strong>，根据上一个 Decoder block 的输出<strong>Z</strong> 计算 <strong>Q</strong> (如果是第一个 Decoder block则使用输入矩阵 <strong>X</strong>进行计算)，后续的计算方法与之前描述的一致。这样做的好处是在 Decoder的时候，每一位单词都可以利用到 Encoder 所有单词的信息 (这些信息无需<strong>Mask</strong>)。</p><p><img src="https://imgur.la/images/2024/07/25/8ARNRACC.png" alt="8ARNRACC" border="0"></p><h4 id="最后的-softmax-层">最后的 Softmax 层</h4><p>计算下一个翻译单词的概率。</p><p>Decoder block 最后的部分是利用 Softmax预测下一个单词，在之前的网络层我们得到一个最终的输出<strong>Z</strong>，因为 Mask 的存在，使得单词 0 的输出 Z0 只包含单词 0的信息，如下：</p><p><img src="https://imgur.la/images/2024/07/25/H7ZPFVIX.png" alt="H7ZPFVIX" border="0"></p><hr><blockquote><p>Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J].Advances in neural information processing systems, 2017, 30.</p><p>知乎：Transformer模型详解 https://zhuanlan.zhihu.com/p/338817680</p><p>李宏毅：Transformerhttps://youtu.be/ugWDIIOHtPA?si=S9Iut52lR-5wD-kp</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h1 id=&quot;transformer-attention-is-all-you-need&quot;&gt;Transformer: Attention Is
All You Need&lt;/h1&gt;
&lt;</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="http://junlei-zhou.com/tags/Deep-Learning/"/>
    
    <category term="Sequence Model" scheme="http://junlei-zhou.com/tags/Sequence-Model/"/>
    
  </entry>
  
  <entry>
    <title>symbols</title>
    <link href="http://junlei-zhou.com/2024/06/20/symbols/"/>
    <id>http://junlei-zhou.com/2024/06/20/symbols/</id>
    <published>2024-06-20T06:04:02.000Z</published>
    <updated>2025-02-27T07:18:28.283Z</updated>
    
    <content type="html"><![CDATA[<h1 id="greek-alphabet-希腊字母">Greek Alphabet (希腊字母)</h1><table><colgroup><col style="width: 30%"><col style="width: 29%"><col style="width: 20%"><col style="width: 20%"></colgroup><thead><tr class="header"><th style="text-align: center;">Letter</th><th style="text-align: center;">LaTex</th><th style="text-align: center;">Letter</th><th style="text-align: center;">LaTex</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\alpha\)</span></td><td style="text-align: center;">\alpha</td><td style="text-align: center;"><span class="math inline">\(A\)</span></td><td style="text-align: center;">\Alpha</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\beta\)</span></td><td style="text-align: center;">\beta</td><td style="text-align: center;"><span class="math inline">\(B\)</span></td><td style="text-align: center;">\Beta</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\gamma\)</span></td><td style="text-align: center;">\gamma</td><td style="text-align: center;"><span class="math inline">\(\Gamma\)</span></td><td style="text-align: center;">\Gamma</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\delta\)</span></td><td style="text-align: center;">\delta</td><td style="text-align: center;"><span class="math inline">\(\Delta\)</span></td><td style="text-align: center;">\Delta</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\epsilon\)</span> <span class="math inline">\(\varepsilon\)</span></td><td style="text-align: center;">\epsilon / \varepilon</td><td style="text-align: center;"><span class="math inline">\(E\)</span></td><td style="text-align: center;">\Epsilon</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\eta\)</span></td><td style="text-align: center;">\eta</td><td style="text-align: center;"><span class="math inline">\(H\)</span></td><td style="text-align: center;">\Eta</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\zeta\)</span></td><td style="text-align: center;">\zeta</td><td style="text-align: center;"><span class="math inline">\(Z\)</span></td><td style="text-align: center;">\Zeta</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\theta\)</span> <span class="math inline">\(\vartheta\)</span></td><td style="text-align: center;">\theta</td><td style="text-align: center;"><span class="math inline">\(\Theta\)</span></td><td style="text-align: center;">\Theta</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\iota\)</span></td><td style="text-align: center;">\iota</td><td style="text-align: center;"><span class="math inline">\(I\)</span></td><td style="text-align: center;">\Iota</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\kappa\)</span></td><td style="text-align: center;">\kappa</td><td style="text-align: center;"><span class="math inline">\(K\)</span></td><td style="text-align: center;">\Kappa</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\lambda\)</span></td><td style="text-align: center;">\lambda</td><td style="text-align: center;"><span class="math inline">\(\Lambda\)</span></td><td style="text-align: center;">\Lambda</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\mu\)</span></td><td style="text-align: center;">\mu</td><td style="text-align: center;"><span class="math inline">\(M\)</span></td><td style="text-align: center;">\Mu</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\nu\)</span></td><td style="text-align: center;">\nu</td><td style="text-align: center;"><span class="math inline">\(N\)</span></td><td style="text-align: center;">\Nu</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\omicron\)</span></td><td style="text-align: center;">\omicron</td><td style="text-align: center;"><span class="math inline">\(O\)</span></td><td style="text-align: center;">\Omicron</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\xi\)</span></td><td style="text-align: center;">\xi</td><td style="text-align: center;"><span class="math inline">\(\Xi\)</span></td><td style="text-align: center;">\Xi</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\pi\)</span></td><td style="text-align: center;">\pi</td><td style="text-align: center;"><span class="math inline">\(\Pi\)</span></td><td style="text-align: center;">\Pi</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\rho\)</span> <span class="math inline">\(\varrho\)</span></td><td style="text-align: center;">\rho</td><td style="text-align: center;"><span class="math inline">\(P\)</span></td><td style="text-align: center;">\Rho</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\sigma\)</span></td><td style="text-align: center;">\sigma</td><td style="text-align: center;"><span class="math inline">\(\Sigma\)</span></td><td style="text-align: center;">\Sigma</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\tau\)</span></td><td style="text-align: center;">\tau</td><td style="text-align: center;"><span class="math inline">\(T\)</span></td><td style="text-align: center;">\Tau</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\upsilon\)</span></td><td style="text-align: center;">\upsilon</td><td style="text-align: center;"><span class="math inline">\(\Upsilon\)</span></td><td style="text-align: center;">\Upsilon</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\phi\)</span> <span class="math inline">\(\varphi\)</span></td><td style="text-align: center;">\phi / \varphi</td><td style="text-align: center;"><span class="math inline">\(\Phi\)</span> <span class="math inline">\(\varPhi\)</span></td><td style="text-align: center;">\Phi / \varPhi</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\chi\)</span></td><td style="text-align: center;">\chi</td><td style="text-align: center;"><span class="math inline">\(X\)</span></td><td style="text-align: center;">\Chi</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\psi\)</span></td><td style="text-align: center;">\psi</td><td style="text-align: center;"><span class="math inline">\(\Psi\)</span></td><td style="text-align: center;">\Psi</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\omega\)</span></td><td style="text-align: center;">\omega</td><td style="text-align: center;"><span class="math inline">\(\Omega\)</span></td><td style="text-align: center;">\Omega</td></tr></tbody></table><h2 id="symbolic-meaning">Symbolic Meaning</h2><h3 id="set">Set</h3><table><thead><tr class="header"><th style="text-align: center;">symbol</th><th style="text-align: left;">meaning</th><th style="text-align: left;">LaTex</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\mathbb{R}\)</span></td><td style="text-align: left;"><strong><em>real numbers set</em></strong>实数集</td><td style="text-align: left;">\mathbb{R}</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\mathbb{Q}\)</span></td><td style="text-align: left;"><strong><em>rational numbersset</em></strong> 有理数集合</td><td style="text-align: left;">\mathbb{Q}</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\mathbb{Z}\)</span></td><td style="text-align: left;"><strong><em>integers set</em></strong>整数集合</td><td style="text-align: left;">\mathbb{Z}</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\mathbb{N}\)</span></td><td style="text-align: left;"><strong><em>natural numbers</em></strong>自然数集合</td><td style="text-align: left;">\mathbb{N}</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\mathbb{C}\)</span></td><td style="text-align: left;"><strong><em>plural set</em></strong>虚数集合</td><td style="text-align: left;">\mathbb{C}</td></tr></tbody></table><h3 id="variables">Variables</h3><table><thead><tr class="header"><th style="text-align: center;">symbol</th><th>meaning</th><th>LaTex</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\top\)</span></td><td>矩阵的转置</td><td>\top</td></tr><tr class="odd"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="even"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="odd"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="even"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="odd"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="even"><td style="text-align: center;"></td><td></td><td></td></tr><tr class="odd"><td style="text-align: center;"></td><td></td><td></td></tr></tbody></table><h3 id="mathematical">Mathematical</h3><table><colgroup><col style="width: 14%"><col style="width: 12%"><col style="width: 12%"><col style="width: 10%"><col style="width: 16%"><col style="width: 14%"><col style="width: 12%"><col style="width: 10%"></colgroup><thead><tr class="header"><th style="text-align: center;">Symbol</th><th style="text-align: center;">LaTex</th><th style="text-align: center;">Symbol</th><th style="text-align: center;">LaTex</th><th style="text-align: center;">Symbol</th><th style="text-align: center;">LaTex</th><th style="text-align: center;">Symbol</th><th style="text-align: center;">LaTex</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\pm\)</span></td><td style="text-align: center;">\pm</td><td style="text-align: center;"><span class="math inline">\(\mp\)</span></td><td style="text-align: center;">\mp</td><td style="text-align: center;"><span class="math inline">\(\times\)</span></td><td style="text-align: center;">\times</td><td style="text-align: center;"><span class="math inline">\(\div\)</span></td><td style="text-align: center;">\div</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\cdot\)</span></td><td style="text-align: center;">\cdot</td><td style="text-align: center;"><span class="math inline">\(\ast\)</span></td><td style="text-align: center;">\ast</td><td style="text-align: center;"><span class="math inline">\(\star\)</span></td><td style="text-align: center;"></td><td style="text-align: center;"><span class="math inline">\(\leq\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(\geq\)</span></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr></tbody></table><h2 id="abbreviation">Abbreviation</h2><table style="width:100%;"><colgroup><col style="width: 15%"><col style="width: 50%"><col style="width: 33%"></colgroup><thead><tr class="header"><th>abbreviation</th><th>full name</th><th>CN</th></tr></thead><tbody><tr class="odd"><td>w.r.t</td><td>with respect to</td><td>关于、谈到、涉及</td></tr><tr class="even"><td>i.i.d</td><td>independent and identically distributed</td><td>独立同分布</td></tr><tr class="odd"><td>PDF</td><td>Probability Density Function</td><td>概率密度函数</td></tr><tr class="even"><td>w/；w/o</td><td>with；without</td><td>消融实验表中的对比实验设置</td></tr><tr class="odd"><td>subject to</td><td></td><td>限制条件（优化中常用）</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;greek-alphabet-希腊字母&quot;&gt;Greek Alphabet (希腊字母)&lt;/h1&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 30%&quot;&gt;
&lt;col style=&quot;width: 29%&quot;&gt;
&lt;col style</summary>
      
    
    
    
    
    <category term="LaTex" scheme="http://junlei-zhou.com/tags/LaTex/"/>
    
    <category term="MarkDown" scheme="http://junlei-zhou.com/tags/MarkDown/"/>
    
    <category term="Deep Learning Knowledge" scheme="http://junlei-zhou.com/tags/Deep-Learning-Knowledge/"/>
    
  </entry>
  
  <entry>
    <title>Mamba</title>
    <link href="http://junlei-zhou.com/2024/06/19/Mamba/"/>
    <id>http://junlei-zhou.com/2024/06/19/Mamba/</id>
    <published>2024-06-19T02:35:00.000Z</published>
    <updated>2025-02-25T07:57:29.886Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="mamba">Mamba</h1><!--本文是根据Mamba论文原作者撰写的Blog进行阅读的重点解读--><p>The Transformer architecture has been a major component in thesuccess of Large Language Models (LLMs). It has been used for nearly allLLMs that are being used today, from open-source models like Mistral toclosed-source models like ChatGPT.</p><p>To further improve LLMs, new architectures are developed that mighteven outperform the Transformer architecture. One of these methods is<em>Mamba</em>, a <em>State Space Model</em>.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f6bc1ca-a387-47ed-a9a6-077af838b359_1148x892.png" style="zoom:50%;"></p><p>Mamba was proposed in the paper <a href="https://arxiv.org/abs/2312.00752">Mamba: Linear-Time SequenceModeling with Selective State Spaces</a>.<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state#footnote-1-141228095">1</a>You can find its official implementation and model checkpoints in its <a href="https://github.com/state-spaces/mamba">repository</a>.</p><p>In this post, I will introduce the field of State Space Models in thecontext of language modeling and explore concepts one by one to developan intuition about the field. Then, we will cover how Mamba mightchallenge the Transformers architecture.</p><p>As a visual guide, expect many visualizations to develop an intuitionabout Mamba and State Space Models!</p><h2 id="part-1-the-problem-with-transformers">Part 1: The Problem withTransformers</h2><p>To illustrate why Mamba is such an interesting architecture, let’s doa short re-cap of transformers first and explore one of itsdisadvantages.</p><p>A Transformer sees any textual input as a <em>sequence</em> thatconsists of <em>tokens</em>.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b8c299a-c0c0-46fe-86cf-b22e08a91b32_1776x544.png" style="zoom:50%;"></p><p>A major benefit of Transformers is that whatever input it receives,it can look back at any of the earlier tokens in the sequence to deriveits representation.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2c01c75-1105-4aeb-a608-f00c85bbe5f7_1776x532.png" style="zoom:50%;"></p><h3 id="the-core-components-of-transformers">The Core Components ofTransformers</h3><p>Remember that a Transformer consists of two structures, a set ofencoder blocks for representing text and a set of decoder blocks forgenerating text. Together, these structures can be used for severaltasks, including translation.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62a21d60-2e84-4c19-a6fb-d2eff501af1c_1776x952.png" style="zoom:50%;"></p><p>We can adopt this structure to create generative models by using onlydecoders. This Transformer-based model, <em>Generative Pre-trainedTransformers</em> (GPT), uses decoder blocks to complete some inputtext.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58e51959-d4ef-4fa9-a1c7-dab0e5ca4dc0_1776x1012.png" style="zoom: 50%;"></p><p>Let’s take a look at how that works!</p><h3 id="a-blessing-with-training">A Blessing with Training…</h3><p>A single decoder block consists of two main components, maskedself-attention followed by a feed-forward neural network.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b5af9c5-5266-4c2b-b583-b20a19f19fcc_1776x464.png" style="zoom:50%;"></p><p>Self-attention is a major reason why these models work so well. Itenables an uncompressed view of the entire sequence with fasttraining.</p><p>So how does it work?</p><p>It creates a matrix comparing each token with every token that camebefore. The weights in the matrix are determined by how relevant thetoken pairs are to one another.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F167cfe80-2863-47c8-a969-cb2eeedbd353_1776x860.png" style="zoom:50%;"></p><p>During training, this matrix is created in one go. The attentionbetween “<em>My</em>” and “<em>name</em>” does not need to be calculatedfirst before we calculate the attention between “<em>name</em>” and“<em>is</em>”.</p><p>It enables <strong>parallelization</strong>, which speeds up trainingtremendously!</p><h3 id="and-the-curse-with-inference">And the Curse with Inference!</h3><p>There is a flaw, however. When generating the next token, we need tore-calculate the attention for the <em>entire sequence</em>, even if wealready generated some tokens.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb66f1965-fc44-4a61-b9c6-912c8120ecad_2420x580.png" style="zoom:50%;"></p><p>Generating tokens for a sequence of length <em>L</em> needs roughly<em>L²</em> computations which can be costly if the sequence lengthincreases.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405074ed-aa8c-44b4-88a5-bae1dad0412e_2072x392.png" style="zoom:50%;"></p><p>This need to recalculate the entire sequence is a major bottleneck ofthe Transformer architecture.</p><p>Let’s look at how a “classic” technique, Recurrent Neural Networks,solves this problem of slow inference.</p><hr><blockquote><p><strong>为什么Transformer的推理速度会很慢？</strong></p><p>因为Transformer在推理当前的状态时，需要计算包含之前所有状态的信息，也就是说，当计算到第N个状态时，需要同时计算包含前N个状态的信息以得出当前状态的取值，这也就时为什么以Transformer为基础的模型在输入时会有长度限制的前提条件。而相比较于Transformer，RNN模型有着比较快的推理速度因为它只用重点关注前面重点的状态，根据此来推理出当前状态，故而其计算速度快，但由于只关注之前的部分状态，也导致了其推理的准确度相比较于Transformer略有不及。</p><p>例如：当输入的Batch Size=b, Sequence length=N,那么一个具有 <span class="math inline">\(l\)</span> 层的Transformer模型的计算量为 <span class="math inline">\(l*(24bNd^2+4bN^2d)\)</span>, <span class="math inline">\(d\)</span>为词向量的维度或者是隐藏层的维度，详细的计算过程见<a href="https://blog.csdn.net/v_JULY_v/article/details/133619540">原文</a>。</p></blockquote><h3 id="are-rnns-a-solution">Are RNNs a Solution?</h3><p>Recurrent Neural Networks (RNN) is a sequence-based network. It takestwo inputs at each time step in a sequence, namely the input at timestep <strong><em>t</em></strong> and a hidden state of the previous timestep <strong><em>t-1</em></strong>, to generate the next hidden stateand predict the output.</p><p>RNNs have a looping mechanism that allows them to pass informationfrom a previous step to the next. We can “unfold” this visualization tomake it more explicit.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddc71706-8da8-4c28-921b-675e9164c7ab_2404x872.png" style="zoom:50%;"></p><p>When generating the output, the RNN only needs to consider theprevious hidden state and current input. It prevents recalculating allprevious hidden states which is what a Transformer would do.</p><p>In other words, RNNs can do inference fast as it scales linearly withthe sequence length! In theory, it can even have an <em>infinite contextlength</em>.</p><p>To illustrate, let’s apply the RNN to the input text we have usedbefore.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2484541-f7b1-4950-b04f-5a3177596fbb_2228x808.png" style="zoom:50%;"></p><p>Each hidden state is the aggregation of all previous hidden statesand is typically a compressed view.</p><p>There is a problem, however…</p><p>Notice that the last hidden state, when producing the name“<em>Maarten</em>” does not contain information about the word“<em>Hello</em>” anymore. RNNs tend to forget information over timesince they only consider one previous state.</p><p>This sequential nature of RNNs creates another problem. Trainingcannot be done in parallel since it needs to go through each step at atime sequentially.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819fcf9b-ea31-4954-8496-4b66c5b46dc2_2236x828.png" style="zoom:50%;"></p><p>The problem with RNNs, compared to Transformers, is completely theopposite! Its inference is incredibly fast but it is notparallelizable.</p><blockquote><p><strong>RNN存在的问题</strong></p><ol type="1"><li><p>虽然在RNN中，每个状态都是先前所有隐藏状态的聚合，然而随着时间的推移，RNN会忘记掉一部分信息。</p></li><li><p>RNN没办法并行训练，即推理速度快但训练慢，而且因为RNN的结构，也无法进行卷积运算。</p></li></ol><p>由于RNN的每个时间 <span class="math inline">\(t\)</span>的输出需要依赖前一个时间 <span class="math inline">\(t-1\)</span> 的输出，导致其循环操作无法并行训练。</p><p>RNN中通过循环结构来实现权重共享，而CNN中通过卷积操作实现局部链接和全局共享。</p></blockquote><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7af6befe-e99d-4350-b555-21ce543cae53_2072x580.png" style="zoom:50%;"></p><p>Can we somehow find an architecture that does parallelize traininglike Transformers whilst still performing inference that scales linearlywith sequence length?</p><p>Yes! This is what Mamba offers but before diving into itsarchitecture, let’s explore the world of State Space Models first.</p><h2 id="part-2-the-state-space-model-ssm">Part 2: The <strong>StateSpace Model (SSM)</strong></h2><p>A State Space Model (SSM), like the Transformer and RNN, processessequences of information, like text but also signals. In this section,we will go through the basics of SSMs and how they relate to textualdata.</p><h3 id="what-is-a-state-space">What is a State Space?</h3><p>A State Space contains the minimum number of variables that fullydescribe a system. It is a way to mathematically represent a problem bydefining a system's possible states.</p><p>Let’s simplify this a bit. Imagine we are navigating through a maze.The “<em>state space</em>” is the map of all possible locations(states). Each point represents a unique position in the maze withspecific details, like how far you are from the exit.</p><p>The “<em>state space representation</em>” is a simplified descriptionof this map. It shows where you are (current state), where you can gonext (possible future states), and what changes take you to the nextstate (going right or left).</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6480800-2449-456a-87a7-27c8a4e9e718_2520x1388.png" style="zoom:50%;"></p><p>Although State Space Models use equations and matrices to track thisbehavior, it is simply a way to track where you are, where you can go,and how you can get there.</p><p>The variables that describe a state, in our example the X and Ycoordinates, as well as the distance to the exit, can be represented as“<em>state vectors</em>”.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42c79eba-2559-4d9d-8999-bee33666f2e3_2364x736.png" style="zoom:50%;"></p><p>Sounds familiar? That is because embeddings or vectors in languagemodels are also frequently used to describe the “state” of an inputsequence. For instance, a vector of your current position (state vector)could look a bit like this:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ff8812a-64d2-4fc6-8e54-eb86222333b0_1496x444.png" style="zoom:50%;"></p><p>In terms of neural networks, the “state” of a system is typically itshidden state and in the context of Large Language Models, one of themost important aspects of generating a new token.</p><p>What is a State Space Model?</p><p>SSMs are models used to describe these state representations and makepredictions of what their next state could be depending on someinput.</p><p>Traditionally, at time <strong><em>t</em></strong>, SSMs:</p><ul><li><p>map an input sequence <strong><em>x(t)</em></strong> — (e.g.,moved left and down in the maze)</p></li><li><p>to a latent state representation <strong><em>h(t)</em></strong> —(e.g., distance to exit and x/y coordinates)</p></li><li><p>and derive a predicted output sequence<strong><em>y(t)</em></strong> — (e.g., move left again to reach theexit sooner)</p><blockquote><p><strong>A:</strong> 当前状态如何影响下一状态</p><p><strong>B:</strong> 输入序列 <strong>x</strong>如何影响当前的状态</p><p><strong>C:</strong> 当前的状态如何影响当前的输出</p><p><strong>D:</strong> 输入序列 <strong>x</strong>如何影响当前的输出</p></blockquote></li></ul><p>However, instead of using <em>discrete</em> <em>sequences</em> (likemoving left once) it takes as input a <em>continuous</em><em>sequence</em> and predicts the output sequence.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5788c3e4-8794-4492-af87-3a45f7a6aa70_1992x624.png" style="zoom:50%;"></p><p>SSMs assume that dynamic systems, such as an object moving in 3Dspace, can be predicted from its state at time<strong><em>t</em></strong> through two equations.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32401c6d-39b6-4619-a75e-6b33d3268bca_2520x388.png" style="zoom:50%;"></p><blockquote><p>这里的 <span class="math inline">\(h&#39;(t)\)</span>是SSM一阶微分方程中的导数，指的是连续状态下的当前状态是由上一状态得出的。</p><p>写成离散形态的即为 <span class="math inline">\(h_t=Ah_{t-1}+Bx_t\)</span>.</p><p>通过求解这两个方程，可以根据观察到的数据“输入序列 x 和先前的状态 h(t)，即可实现对未来状态 y(t) 进行预测。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-Con_dis.png" alt="Mamba Con dis" border="0" style="zoom:50%;"></p></blockquote><p>By solving these equations, we assume that we can uncover thestatistical principles to predict the state of a system based onobserved data (input sequence and previous state).</p><p>==Its goal is to find this state representation<strong><em>h(t)</em></strong> such that we can go from an input to anoutput sequence.==</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ca5c7ae-3dbe-44d8-8b13-7f4dcc14a29b_2008x624.png" style="zoom:50%;"></p><p>These two equations are the core of the State Space Model.</p><p>The two equations will be referenced throughout this guide. To makethem a bit more intuitive, they are <strong>color-coded</strong> so youcan quickly reference them.</p><p>The <strong>state equation</strong> describes how the state changes(through <em>matrix A</em>) based on how the input influences the state(through <em>matrix B</em>).</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0876819d-8a46-4187-9826-14391bfd47b9_1796x624.png" style="zoom:50%;"></p><p>As we saw before, <strong><em>h(t)</em></strong> refers to our latentstate representation at any given time <strong><em>t</em></strong>, and<strong><em>x(t)</em></strong> refers to some input.</p><p>The <strong>output equation</strong> describes how the state istranslated to the output (through <em>matrix C</em>) and how the inputinfluences the output (through <em>matrix D</em>).</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2e87708-9676-4a1c-b32c-d703026f64d9_1796x624.png" style="zoom:50%;"></p><blockquote><p><strong>NOTE</strong>: Matrices <em>A</em>, <em>B</em>, <em>C</em>,and <em>D</em> are also commonly refered to as <em>parameters</em> sincethey are learnable.</p></blockquote><p>Visualizing these two equations gives us the followingarchitecture:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc358439e-c507-49f1-ac2e-5dedaccc2a8b_1728x364.png" style="zoom:50%;"></p><p>Let’s go through the general technique step-by-step to understand howthese matrices influence the learning process.</p><p>Assume we have some input signal <strong><em>x(t)</em></strong>, thissignal first gets multiplied by <em>matrix B</em> which describes howthe inputs influence the system.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd6f8dae-2281-47af-8ba3-06bbdc594d1c_1956x360.png" style="zoom: 67%;"></p><p>The updated state (akin to the hidden state of a neural network) is alatent space that contains the core “knowledge” of the environment. Wemultiply the state with <em>matrix A</em> which describes how all theinternal states are connected as they represent the underlying dynamicsof the system.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1cedc98a-d200-4fe4-b311-6d68dcaa50af_1956x572.png" style="zoom:50%;"></p><blockquote><p><strong>A</strong>矩阵决定了整个状态的演化，即如何从一个状态演化到下一个状态。其本质为存储着之前所有历史信息的浓缩精华。</p></blockquote><p>As you might have noticed, <em>matrix A</em> is applied beforecreating the state representations and is updated after the staterepresentation has been updated.</p><p>Then, we use <em>matrix C</em> to describe how the state can betranslated to an output.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8599487f-1023-4069-be7a-8056e63b0574_1956x572.png" style="zoom:50%;"></p><p>Finally, we can make use of <em>matrix D</em> to provide a directsignal from the input to the output. This is also often referred to as a<em>skip-connection</em>.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf79721f-5cef-44da-98c5-f63a7839ebc3_1956x756.png" style="zoom:50%;"></p><p>Since <em>matrix D</em> is similar to a skip-connection, the SSM isoften regarded as the following without the skip-connection.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ca1d511-7d31-42a0-9220-2fb85b256efd_1956x864.png" style="zoom:50%;"></p><p>Going back to our simplified perspective, we can now focus onmatrices <em>A</em>, <em>B</em>, and <em>C</em> as the core of theSSM.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e52f4f0-d7ad-453d-a741-6dfa4a998964_1728x352.png" style="zoom:50%;"></p><p>We can update the original equations (and add some pretty colors) tosignify the purpose of each matrix as we did before.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55df8ede-3a16-4473-8ea9-872fe199d3a1_1904x676.png" style="zoom:50%;"></p><p>Together, these two equations aim to predict the state of a systemfrom observed data. Since the input is expected to be continuous, themain representation of the SSM is a <strong>continuous-timerepresentation</strong>.</p><h3 id="from-ssm-to-s4">From SSM to S4</h3><h4 id="from-a-continuous-to-a-discrete-signal">From a Continuous to aDiscrete Signal</h4><p>Finding the state representation <strong><em>h(t)</em></strong> isanalytically challenging if you have a continuous signal. Moreover,since we generally have a discrete input (like a textual sequence), wewant to discretize the model.</p><p>To do so, we make use of the <em>Zero-order hold technique.</em> Itworks as follows.</p><ol type="1"><li>First, every time we receive a discrete signal, we hold its valueuntil we receive a new discrete signal. This process creates acontinuous signal the SSM can use:</li></ol><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2ffb18-2e66-4135-9888-98e9ab88d0d8_1488x472.png" style="zoom:50%;"></p><ol start="2" type="1"><li><p>How long we hold the value is represented by a new learnableparameter, called the <em>step size</em> <span class="math inline">\(\Delta\)</span> . It represents the resolution ofthe input.</p></li><li><p>Now that we have a continuous signal for our input, we cangenerate a continuous output and only sample the values according to thetime steps of the input.</p></li></ol><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F042ff699-81af-4479-b99f-92e4997c4c81_1488x476.png" style="zoom:50%;"></p><p>These sampled values are our discretized output!</p><p>Mathematically, we can apply the <a href="https://en.wikipedia.org/wiki/Zero-order_hold">Zero-order hold</a>as follows:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6df4b59-6f76-4f13-a201-7b69e59df164_6200x1176.png" style="zoom:50%;"></p><p>Together, they allow us to go from a continuous SSM to a discrete SSMrepresented by a formulation that instead of a<em>function-to-function</em>, <span class="math inline">\(x(t)\rightarrow y(t)\)</span>, is now a<em>sequence-to-sequence</em>, <span class="math inline">\(x_k\rightarrow y_k\)</span>:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc29cfbbb-ae41-4dc2-b899-9e0a81cba34d_1980x1012.png" style="zoom:50%;"></p><p>Here, matrices <strong><em>A</em></strong> and<strong><em>B</em></strong> now represent discretized parameters of themodel.</p><p>We use <strong><em>k</em></strong> instead of<strong><em>t</em></strong> to represent discretized timesteps and tomake it a bit more clear when we refer to a continuous versus a discreteSSM.</p><blockquote><p><strong>NOTE:</strong> We are still saving the continuous form of<em>Matrix A</em> and not the discretized version during training.During training, the continuous representation is discretized.</p></blockquote><p>Now that we have a formulation of a discrete representation, let’sexplore how we can actually <em>compute</em> the model.</p><h4 id="the-recurrent-representation">The Recurrent Representation</h4><p>Our discretized SSM allows us to formulate the problem in specifictimesteps instead of continuous signals. A recurrent approach, as we sawbefore with RNNs is quite useful here.</p><p>If we consider discrete timesteps instead of a continuous signal, wecan reformulate the problem with timesteps:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83b70ba4-b068-44d1-8641-9b224d103c51_1980x548.png" style="zoom:50%;"></p><p>At each timestep, we calculate how the current input (<strong><span class="math inline">\(Bx_k\)</span></strong>) influences the previousstate (<strong><span class="math inline">\(Ah_{k-1}\)</span></strong>)and then calculate the predicted output (<strong><span class="math inline">\(Ch_k\)</span></strong>).</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb4d0412-87fb-4507-bedb-4793588bd465_2116x788.png" style="zoom:50%;"></p><p>This representation might already seem a bit familiar! We canapproach it the same way we did with the RNN as we saw before.</p><blockquote><p>对于 <span class="math inline">\(y_2\)</span> 展开计算则有 <span class="math display">\[\begin{align}y_2&amp;=Ch_2 \\&amp;=C(\bar{A}h_1+\bar{B}x_2) \\&amp;=C(\bar{A}(\bar{A}h_0+Bx_1)+\bar{B}x_2) \\&amp;=C(\bar{A}(\bar{A} \cdot \bar{B}x_0 +Bx_1)+\bar{B}x_2) \\&amp;=C\cdot \bar{A}^2\cdot \bar{B}x_0+C\cdot \bar{A}\cdot\bar{B}x_1+C\cdot \bar{B}x_2\end{align}\]</span> 由此可推得 <span class="math inline">\(y_k=C\cdot \bar{A}^k\cdot \bar{B}x_0+C\cdot \bar{A}^{k-1} \cdot \bar{B}x_1+\cdots+C\cdot\bar{A} \cdot \bar{B}x_k\)</span></p></blockquote><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91ca51f7-9b9b-4f17-bccb-32a5a96f3339_2184x868.png" style="zoom:50%;"></p><p>Which we can unfold (or unroll) as such:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1084e8a-a70d-450b-beb0-f18117ade5ed_2184x876.png" style="zoom:50%;"></p><p>Notice how we can use this discretized version using the underlyingmethodology of an RNN.</p><p>This technique gives us both the advantages and disadvantages of anRNN, namely fast inference and slow training.</p><h4 id="the-convolution-representation">The ConvolutionRepresentation</h4><p>Another representation that we can use for SSMs is that ofconvolutions. Remember from classic image recognition tasks where weapplied filters (<em>kernels</em>) to derive aggregate features:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f05950-bfad-4013-b854-679c9a47ada9_3216x2144.png" style="zoom:50%;"></p><p>Since we are dealing with text and not images, we need a1-dimensional perspective instead:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb943872f-de72-43e8-b2f1-cb8213f120a3_3216x1296.png" style="zoom:50%;"></p><p>The kernel that we use to represent this “filter” is derived from theSSM formulation:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05049821-2352-4c04-8fb2-07fe15c20a9c_2620x824.png" style="zoom:50%;"></p><blockquote><p><strong>为什么可以写成卷积的形式？</strong></p><p>如上图，其中 <span class="math inline">\(K\)</span>为卷积核，其中此时的 <strong>A、B、C</strong> 都是常数，可以看出卷积核<span class="math inline">\(K\)</span>是通过固定数值矩阵得到的，只需确定 <strong>A、B、C</strong>即可并行运算。</p></blockquote><p>Let’s explore how this kernel works in practice. Like convolution, wecan use our SSM kernel to go over each set of tokens and calculate theoutput:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9007d03b-c1c9-4b37-8c83-f27bfe8318f4_2620x1080.png" style="zoom:50%;"></p><p>This also illustrates the effect padding might have on the output. Ichanged the order of padding to improve the visualization but we oftenapply it at the end of a sentence.</p><p>In the next step, the kernel is moved once over to perform the nextstep in the calculation:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ed71fb-f237-4173-bb23-bd1bf02ff123_2620x1080.png" style="zoom:50%;"></p><p>In the final step, we can see the full effect of the kernel:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4387b79-5e92-4fe2-8b30-2abf112f5a73_2620x1080.png" style="zoom:50%;"></p><p>A major benefit of representing the SSM as a convolution is that itcan be trained in parallel like Convolutional Neural Networks (CNNs).However, due to the fixed kernel size, their inference is not as fastand unbounded as RNNs.</p><h4 id="the-three-representations">The Three Representations</h4><p>These three representations, <em>continuous</em>, <em>recurrent</em>,and <em>convolutional</em> all have different sets of advantages anddisadvantages:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F682187d6-f402-44aa-8097-8a2e5b6179a7_2072x744.png" style="zoom:50%;"></p><p>Interestingly, we now have efficient inference with the recurrent SSMand parallelizable training with the convolutional SSM.</p><blockquote><ol type="1"><li>在训练的时候怎么使用CNN进行训练？</li></ol><p><span class="math display">\[y=\bar{K}x\]</span></p><p>​ 能够通过使用卷积的方法使其进行并行计算。</p><ol start="2" type="1"><li>在推理的时候怎么进行推理？ <span class="math display">\[\left\{ \begin{array}{lcl}h_k=\bar{A}h_{k-1}+\bar{B}x_k \\y_k=Ch_k+Dx_k\end{array}\right.\]</span></li></ol></blockquote><p>With these representations, there is a neat trick that we can use,namely choose a representation depending on the task. During training,we use the convolutional representation which can be parallelized andduring inference, we use the efficient recurrent representation:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c43c82d-9735-4d55-97bb-8ad6f504909e_1960x1008.png" style="zoom:50%;"></p><p>This model is referred to as the <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/05546b0e38ab9175cd905eebcc6ebb76-Abstract.html">LinearState-Space Layer (LSSL)</a>.<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state#footnote-2-141228095">2</a></p><p>These representations share an important property, namely that of<strong><em>Linear Time Invariance</em></strong> (LTI). LTI states thatthe SSMs parameters, <em>A</em>, <em>B</em>, and <em>C</em>, are fixedfor all timesteps. This means that matrices <em>A</em>, <em>B</em>, and<em>C</em> are the same for every token the SSM generates.</p><p>In other words, regardless of what sequence you give the SSM, thevalues of <em>A</em>, <em>B</em>, and <em>C</em> remain the same. Wehave a static representation that is not content-aware.</p><p>Before we explore how Mamba addresses this issue, let’s explore thefinal piece of the puzzle, <em>matrix A</em>.</p><h4 id="the-importance-of-matrix-a">The Importance of Matrix<em>A</em></h4><blockquote><p><strong>A</strong>矩阵决定了整个状态的演化，即如何从一个状态演化到下一个状态。其本质为存储着之前所有历史信息的浓缩精华，<strong>A</strong> 决定了系统的动态特性，但 <strong>A</strong>可能存在一个问题，即 <strong>A</strong>只记住了之前的部分状态，像RNN那样忘记了部分状态，从而会导致SSM在性能上与RNN相似。</p><p><strong>A</strong> 设计的关键是如何在有限的空间中保留更多的记忆！</p></blockquote><p>Arguably one of the most important aspects of the SSM formulation is<em>matrix A</em>. As we saw before with the recurrent representation,it captures information about the <em>previous</em> state to build the<em>new</em> state.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07542fb1-d4b6-421e-8b2a-a3f0a7790939_2028x876.png" style="zoom:50%;"></p><p>In essence, <em>matrix</em> <em>A</em> produces the hidden state:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47635355-6b9a-4981-af3a-7ee6a12b87b3_1412x468.png" style="zoom:50%;"></p><p>Creating <em>matrix A</em> can therefore be the difference betweenremembering only a few previous tokens and capturing every token we haveseen thus far. Especially in the context of the Recurrent representationsince it only <em>looks back</em> <em>at the previous state</em>.</p><p>So how can we create <em>matrix A</em> in a way that retains a largememory (context size)?</p><p>We use Hungry Hungry Hippo! Or <a href="https://proceedings.neurips.cc/paper/2020/hash/102f0bb6efb3a6128a3c750dd16729be-Abstract.html">HiPPO</a><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state#footnote-3-141228095">3</a>for <strong>Hi</strong>gh-order <strong>P</strong>olynomial<strong>P</strong>rojection <strong>O</strong>perators. HiPPO attemptsto compress all input signals it has seen thus far into a vector ofcoefficients.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07985a64-fc26-4ee8-9ec2-c488e4cb709a_1492x488.png" style="zoom:50%;"></p><p>It uses <em>matrix A</em> to build a state representation thatcaptures recent tokens well and decays older tokens. Its formula can berepresented as follows:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc7c768-7f0c-4983-a21e-70a4f587e6aa_2520x628.png" style="zoom:50%;"></p><p>Assuming we have a square <em>matrix <strong>A</strong></em>, thisgives us:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef8f5de9-6448-43d5-9878-c8cd1d938b7c_1436x708.png" style="zoom:50%;"></p><p>Building <em>matrix A</em> using HiPPO was shown to be much betterthan initializing it as a random matrix. As a result, it more accuratelyreconstructs <em>newer</em> signals (recent tokens) compared to<em>older</em> signals (initial tokens).</p><p>The idea behind the HiPPO Matrix is that it produces a hidden statethat memorizes its history.</p><p>Mathematically, it does so by tracking the coefficients of a <a href="https://proceedings.neurips.cc/paper/2019/hash/952285b9b7e7a1be5aa7849f32ffff05-Abstract.html">Legendrepolynomial</a> which allows it to approximate all of the previoushistory.<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state#footnote-4-141228095">4</a></p><p>HiPPO was then applied to the recurrent and convolutionrepresentations that we saw before to handle long-range dependencies.The result was <a href="https://arxiv.org/abs/2111.00396">StructuredState Space for Sequences (S4)</a>, a class of SSMs that can efficientlyhandle long sequences.<a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state#footnote-5-141228095">5</a></p><p>It consists of three parts:</p><ul><li><p>State Space Models</p></li><li><p>HiPPO for handling <strong>long-rangedependencies</strong></p></li><li><p>Discretization for creating <strong>recurrent</strong> and<strong>convolution</strong> representations</p></li></ul><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb055ec5-f8c7-4862-ab88-f4fb38abf042_1892x844.png" style="zoom:50%;"></p><p>This class of SSMs has several benefits depending on therepresentation you choose (recurrent vs. convolution). It can alsohandle long sequences of text and store memory efficiently by buildingupon the HiPPO matrix.</p><blockquote><p><strong>NOTE</strong>: If you want to dive into more of the technicaldetails on how to calculate the HiPPO matrix and build a S4 modelyourself, I would HIGHLY advise going through the <a href="https://srush.github.io/annotated-s4/">Annotated S4</a>.</p><p>其中在S4中对 <strong>A</strong> 进行了改进：</p><p><strong>Theorem 1.</strong> All <em>HiPPO</em> matrices have a<em>Normal Plus Low-Rank</em> (NPLR) representation <span class="math display">\[A=VAV^*-PQ^\top=V(\Lambda-(V^*P)(V^*Q))V^*\]</span> for unitary <span class="math inline">\(V\in\mathbb{C}^{N\times N}\)</span>, diagonal <span class="math inline">\(\Lambda\)</span>， and low-rank factorization<span class="math inline">\(P,Q\in\mathbb{R}^{N\times r}\)</span>. Thesematrices <em>HiPPO-LegS, LegT, LagT</em> all satisfy <span class="math inline">\(r=1 \ or \ r=2\)</span>.</p></blockquote><hr><h3 id="introduction-of-s4">Introduction of S4</h3><h4 id="improving-transformer-struggles-with-handling-very-long-sequences">Improvingtransformer struggles with handling very long sequences</h4><p>序列数据一般都是离散的数据 比如文本、图、DNA</p><ol type="1"><li>但现实生活中还有很多连续的数据，比如音频、视频，对于音视频这种信号而言，其一个重要特点就是有极长的contextwindow</li><li>而在transformer长context上往往会失败，或者注意力机制在有着超长上下文长度的任务上并不擅长，而S4擅长这类任务。</li></ol><h4 id="the-definition-and-derivation-of-hippostate-compresses-the-history-of-input">Thedefinition and derivation of HiPPO：State compresses the history ofinput</h4><p>我们已经知道一个RNN网络更擅长于处理这种序列数据，但是RNN网络最大的缺点是由于它的hiddenstate记忆能力有限，导致其会忘记掉一些以前的特征。</p><p>==关键：怎样改善RNN记忆有限的问题？==</p><p>假设我们在 <span class="math inline">\(t_0\)</span>时刻有接收到袁术输入信号 <span class="math inline">\(u(t)\)</span>之前的部分：</p><ol type="1"><li><p>我们希望使用一个记忆单元去压缩之前这段的输入部分来学习特征，我们使用一个多项式去近似这段之前的输入<span class="math display">\[x(t_0)=\begin{bmatrix} 0.1 \\-1.1 \\3.7 \\2.5\end{bmatrix}\]</span></p></li><li><p>当我们在接收更多的signal的时候，我们仍然希望这个记忆单元能够对已经接收到的所有的signal进行压缩，因此需要自动更新多项式的各项系数，如下图所示</p><p><img src="https://imgur.la/images/2024/06/20/Mamba-HiPPO_1.png" alt="Mamba HiPPO 1" border="0" style="zoom:50%;"></p></li><li><p>此时，HiPPO的关键问题就变成了一个优化问题</p><ul><li><p>如何能够找到这些最优的近似？</p></li><li><p>如何快速的更新这些多项式的参数？</p></li></ul><p>因此，我们需要定义一个指标去判断一个近似的好坏程度。这个指标可以解读为</p><p>（1）在距离当下时刻最近的拟合函数 <span class="math inline">\(x\)</span> 与原数据 <span class="math inline">\(u\)</span>保持最大的相似度，距离当下时刻远的保留其大致状态；</p><p>（2）也可以是只关注距离当下时刻最近的拟合函数 <span class="math inline">\(x\)</span> 与原数据 <span class="math inline">\(u\)</span>保持最大的相似度，而不在乎距离当下时刻远的状态；</p><p>（3）还可以是关注整体的拟合程度，使其总体与原数据保持最大........</p><p><img src="https://imgur.la/images/2024/06/20/Mamba-HiPPO_2.png" alt="Mamba HiPPO 2" border="0" style="zoom:50%;"></p><p>(Note: 添加推导过程)</p></li><li><p>HiPPO的定义，两个矩阵 (<strong>A</strong>表示之前的状态怎样影响当前的状态，<strong>B</strong>当前的输入怎样影响当前的状态)与两个信号( <span class="math inline">\(x(t)\)</span> 当前状态之前接收到的signal与<span class="math inline">\(u(t)\)</span> 当前接收到的signal)</p><p><img src="https://imgur.la/images/2024/06/20/Mamba-HiPPO_3.png" alt="Mamba HiPPO 3" border="0" style="zoom:50%;"></p><blockquote><p>需要澄清一点的是作者在这里使用了State spaceModel中状态的定义，与本文前面部分的定义有些许不同. 但事实上这里的 <span class="math inline">\(x(t)\)</span> 就等同于上文中的 <span class="math inline">\(h(t)\)</span> 这里的 <span class="math inline">\(u(t)\)</span> 就等同于上文中的 <span class="math inline">\(x(t)\)</span>。我们更换一下这个表示即可转变为上文中的形式 <span class="math display">\[x&#39;(t)=Ax(t)+Bu(t) \Longrightarrow h&#39;(t)=Ah(t)+Bx(t)\]</span> 其中 <strong>A</strong> 就是HiPPO matrix.</p></blockquote></li><li><p>HiPPO就相当于把一个高维的复杂函数映射压缩成一个简单的函数，这样既保留了基本信息，又节省了空间。如下图所示，<span class="math inline">\(u(t)\)</span> 是原始输入的signal，<span class="math inline">\(x(t)\)</span> 是经过压缩后产生到的signal，即对应上文中的 <span class="math inline">\(h(t)\)</span>.</p><p><img src="https://imgur.la/images/2024/06/20/Mamba-HiPPO_4.png" alt="Mamba HiPPO 4" border="0" style="zoom:50%;"></p></li><li><p>我们对上图进行还原处理即可得到</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_5.png" alt="Mamba HiPPO 5" border="0" style="zoom:50%;"></p><p>说明：图中 <span class="math inline">\(u\)</span>序列是一个原始的长度为10000(横轴的长度为10000)，表示原本的信号总共有10000个1维信号，想要完全表示的话每个信号一个memoryunit，总共需要10000个memory unit。 但我们现在使用一个64个memory unit的信号压缩器(图中的蓝色线，其中这里为了画图清晰只画出了4条曲线，实际上应该是64条，即相当于使用了64个不同的hiddenstate去表示已经接收到的signal，对应的 <strong>A</strong> 矩阵的大小为<span class="math inline">\(\mathbb{R}^{N\times N}\)</span>)去压缩这个10000个memory unit的信号。图像中红色的线是使用压缩后的信号(蓝线：<span class="math inline">\(x\)</span> 序列)还原得到的原始信号序列 (黑线：<span class="math inline">\(u\)</span>序列)，可以看出其中在距离当下时刻最近的还原最准确，距离当下最远的时刻只保留了大致的状态。图中绿色的线是采用了EDM(ExponentialDecaying Measure) 作为评价指标来衡量逼近多项式 <span class="math inline">\(x\)</span> 的好坏。</p></li><li><p>事实上，HiPPO可以推广到任何指标上：</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_6.png" alt="Mamba HiPPO 6" border="0" style="zoom:50%;"></p><p>无论是更关注于当前时刻的状态还是关注于总体的状态，都存在对应的 HiPPOoperator能计算下一时刻的状态。</p></li></ol><h4 id="high-order-hippo-from-state-state-transition-to-state-result-transition">High-orderHiPPO: from state-state transition to state-result transition</h4><p>通过上文，我们已经实现了HiPPO在低阶 (10000个Memoryunit)上的工作流程，然而维度是不断扩大的，我们的目标是将其拓展到高阶上的表示，阶数越高其对应的场景与LLM更加相似。</p><ol type="1"><li><p>一个简单的思路就是继续堆叠HiPPO算子 (即 <span class="math inline">\(x\)</span>的维度数)，但这会面临一个问题，不断地堆叠会造成维度爆炸，并且也失去了压缩的意义。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_7.png" alt="Mamba HiPPO 7" border="0" style="zoom:50%;"></p></li><li><p>这里采用了将映射的 state <span class="math inline">\(x\)</span>进行线性组合 <span class="math inline">\(Cx\)</span>，最终得到输出 <span class="math inline">\(y\)</span> （图中红色的线），而 <span class="math inline">\(D\)</span> 是一个skip connection, 是绕开状态 <span class="math inline">\(x\)</span>，直接从输入 <span class="math inline">\(u\)</span>到输出 <span class="math inline">\(y\)</span> 的连接。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_8.png" alt="Mamba HiPPO 8" border="0" style="zoom:50%;"></p><blockquote><p>同样的，这里的 <span class="math inline">\(x\)</span>就等同于上文中的 <span class="math inline">\(h(t)\)</span> 这里的 <span class="math inline">\(u\)</span> 就等同于上文中的 <span class="math inline">\(x\)</span>。我们更换一下这个表示即可转变为上文中的形式 <span class="math display">\[y=Cx+Du\Longrightarrow y_t=Ch(t)+Dx(t)\]</span></p></blockquote></li><li><p>事实上，以上的两个步骤就组成了Kalman在1960年提出的State SpaceMachine：</p></li></ol><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_9.png" alt="Mamba HiPPO 9" border="0"><span class="math display">\[   \left\{ \begin{array}{rcl}  x&#39;=Ax+Bu \\   y=Cx+Du   \end{array}\right.   \ \  \Longrightarrow \ \   \left\{ \begin{array}{rcl} h&#39;(t)=Ah(t)+Bx(t) \\   y(t) = Ch(t)+Dx(t)   \end{array}\right.   \]</span></p><h4 id="the-definition-and-properties-of-s4">The definition andproperties of S4</h4><p><strong>S4， 即Structured State Spaces。</strong> 在一个State SpaceModel中，我们使用HiPPO operate 实现状态的变换，其中的 <span class="math inline">\(A\)</span> 矩阵我们使用 HiPPO Metrix。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_10.png" alt="Mamba HiPPO 10" border="0" style="zoom:50%;"></p><p>S4具有以下特点，能够应对连续序列，离散序列等场景。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-HiPPO_11.png" alt="Mamba HiPPO 11" border="0" style="zoom:50%;"></p><p>在代码实现中，SSM将这些表示作为深度学习pipeline中其中的一层，并且其中的矩阵<span class="math inline">\(A,B,C,D\)</span>是需要优化的变量，通过数据训练得到的。通常有 <span class="math inline">\(d\)</span>层这样的SSM层并行存在，每个对应一个隐藏维度。</p><blockquote><p>To preserve the sequence history, HiPPO projects the history on abasis of <strong>orthogonal polynomials</strong>, which translates tohaving SSMs whose <strong>A,B</strong> matrices are initialized to somematrices.</p><p>This recurrent form of SSMs allows efficient inference (i.e.,generation) : to generate the output of the next time-step, one onlyneeds the state of the current time-step, not the entire inputhistory.</p></blockquote><p>此时的S4, 在训练的时候可以通过卷积的形式进行训练 <span class="math inline">\(y=\bar{K}u\)</span>,这使得S4具有极快的推理速度。</p><blockquote><p>此时仍存在些许疑问，根据上文我们可以知道 <span class="math inline">\(\bar{K}=(C\bar{B},C\bar{A}\bar{B},...,C\bar{A}^k\bar{B},\dots)\)</span>。好像卷积核是随着序列长度不断增长的，这意味着卷积核<span class="math inline">\(\bar{K}\)</span>是无无限长的，但卷积核显然不能是无线长的，因此需要重新设计一个卷积核以适应无限长的输入序列。</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-S4_12.png" alt="Mamba S4 12" border="0" style="zoom:50%;"></p><p>其中，我们不直接计算这个卷积核 <span class="math inline">\(\bar{K}\)</span> ，而是采用 truncated generatingfunction的方式去使用FFT的方法逼近卷积核 <span class="math inline">\(\bar{K}\)</span>.</p><p>此外，文中说的 <span class="math inline">\(\bar{K}\)</span> 是一个<strong>Low-Rank</strong> 的矩阵，是因为 <strong>A</strong> 矩阵是一个<strong>Low-Rank</strong> 的下三角矩阵，而 <span class="math inline">\(\bar{K}=(C\bar{B},C\bar{A}\bar{B},...,C\bar{A}^k\bar{B},\dots)\)</span>因此 <span class="math inline">\(\bar{K}\)</span> 也是一个<strong>Low-Rank</strong> 的矩阵。</p></blockquote><p>但此时的S4似乎仍存在一个问题，<strong>S4中的<span class="math inline">\(A,B,C\)</span>矩阵是始终保持不变的（这里的保持不变是说在inference中始终都使用这三个矩阵），这也就意味着对于不同时刻的输入<span class="math inline">\(x\)</span>我们都使用相同的方式处理，但实际上对于一个序列输入，有些部分重要，有些部分并不重要，对所有的部分都做相同处理，这无法实现对输入的针对性处理</strong></p><p>因为我们在前文中一直说明的SSM模型是线性非时变系统 (Lineartime-invariant system) 的状态空间模型，实际中的SSM可能是一个线性时变系统(Linear time-invariant system),那如何将线性非时变系统的SSM转化称线性时变系统的SSM呢？</p><p><img src="https://imgur.la/images/2024/06/21/Mamba-S4_13.png" alt="Mamba S4 13" border="0" style="zoom:50%;"></p><p>显然，我们只需要将其中的 <span class="math inline">\(A,B,C\)</span>矩阵变成可以跟着状态改变而改变的即可。但如果直接改变，又会引发一系列蝴蝶效应，虽然改变后的SSM模型能够"专注于"输入序列中对当前任务更重要的部分，但由于<span class="math inline">\(\bar{K}=(C\bar{B},C\bar{A}\bar{B},...,C\bar{A}^k\bar{B},\dots)\)</span>而导致其无法实现并行计算了。</p><p>在前文的介绍中，S4可以先计算卷积核 <span class="math inline">\(\bar{K}\)</span> ，保存，然后直接与输入 <span class="math inline">\(x\)</span> 相乘即可得到输出 <span class="math inline">\(y\)</span> ，然而，此时的 <span class="math inline">\(A,B,C\)</span>是会随着输入序列的状态变化的，因而导致了我们无法提前计算卷积核 <span class="math inline">\(\bar{K}\)</span>这也就意味着无法进行卷积运算，并行计算被PASS。</p><p>此时，解决此问题的关键就变成了<strong>如何找到一种无需卷积的并行运算？</strong>这正是Mamba要做的内容....</p><hr><h2 id="part-3-mamba---a-selective-ssm">Part 3: Mamba - A SelectiveSSM</h2><p>We finally have covered all the fundamentals necessary to understandwhat makes Mamba special. State Space Models can be used to modeltextual sequences but still have a set of disadvantages we want toprevent.</p><p>In this section, we will go through Mamba’s two maincontributions:</p><ol type="1"><li><p>A <strong>selective scan algorithm</strong>, which allows themodel to filter (ir)relevant information</p></li><li><p>A <strong>hardware-aware algorithm</strong> that allows forefficient storage of (intermediate) results through <em>parallelscan</em>, <em>kernel fusion</em>, and <em>recomputation</em>.</p></li></ol><p>Together they create the <em>selective SSM</em> or <em>S6</em> modelswhich can be used, like self-attention, to create <em>Mambablocks</em>.</p><p>Before exploring the two main contributions, let’s first explore whythey are necessary.</p><blockquote><p>先回答前一章节留下的问题。</p><p>Mamba解决这一问题的办法是设计了一种简单的选择机制，通过"<strong>参数化SSM的输入</strong>"，让模型对信息有选择性的处理，以便重点关注或忽略特定的输入。因此，模型一方面能够实现对关键信息的长时间记忆，另一方面可以过滤掉与任务无关的序列信息。</p><p>就如前文中所提到的，Mamba每次参考前面所有内容的一个概括，越往后写对前面内容概括得越狠，丢掉细节、保留大意。</p><p>而Transformer每次写之前都要从头到尾重新看一遍前文；RNN则是写着忘着，只关注前面的一句。</p><table><colgroup><col style="width: 6%"><col style="width: 25%"><col style="width: 35%"><col style="width: 32%"></colgroup><thead><tr class="header"><th>模型</th><th><strong>对信息的压缩程度</strong></th><th><strong>训练的效率</strong></th><th><strong>推理的效率</strong></th></tr></thead><tbody><tr class="odd"><td>Transformer</td><td>transformer对每个历史记录都不压缩</td><td>训练消耗算力大</td><td>推理消耗算力大</td></tr><tr class="even"><td>RNN</td><td>随着时间的推移，RNN 往往会忘记某一部分信息</td><td>RNN没法并行训练</td><td>推理时只看一个时间步 故推理高效(<em>相当于推理快但训练慢</em>)</td></tr><tr class="odd"><td>CNN</td><td></td><td>训练效率高，可并行「<em>因为能够绕过状态计算，并实现仅包含(B, L,D)的卷积核</em>」</td><td></td></tr><tr class="even"><td>SSM</td><td>SSM压缩每一个历史记录</td><td></td><td>矩阵不因输入不同而不同，无法针对输入做针对性推理</td></tr><tr class="odd"><td>Mamba</td><td>选择性的关注必须关注的、过滤掉可以忽略的</td><td>mamba每次参考前面所有内容的一个概括，兼备训练、推理的效率</td><td></td></tr></tbody></table><p>总之，序列模型的效率与效果的权衡点在于它们对状态的压缩程度：</p><ul><li>高效的模型必须有一个小的状态(比如RNN或S4)</li><li>而有效的模型必须有一个包含来自上下文的所有必要信息的状态(比如transformer)</li></ul></blockquote><h3 id="what-problem-does-it-attempt-to-solve">What Problem does itattempt to Solve?</h3><p>State Space Models, and even the S4 (Structured State Space Model),perform poorly on certain tasks that are vital in language modeling andgeneration, namely <em>the ability to focus on or ignore particularinputs</em>.</p><p>We can illustrate this with two synthetic tasks, namely<strong>selective copying</strong> and <strong>inductionheads</strong>.</p><p>In the <strong>selective copying</strong> task, the goal of the SSMis to copy parts of the input and output them in order:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3f1d1fb-7603-4f86-a2e4-88e0496a1f08_2120x464.png" style="zoom:50%;"></p><p>However, a (recurrent/convolutional) SSM performs poorly in this tasksince it is <strong><em>Linear Time Invariant</em>.</strong> As we sawbefore, the matrices <em>A</em>, <em>B</em>, and <em>C</em> are the samefor every token the SSM generates.</p><p>As a result, an SSM cannot perform <em>content-aware reasoning</em>since it treats each token equally as a result of the fixed A, B, and Cmatrices. This is a problem as we want the SSM to reason about the input(prompt).</p><p>The second task an SSM performs poorly on is <strong>inductionheads</strong> where the goal is to reproduce patterns found in theinput:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27775742-18d2-4f2c-b792-5706976e75e3_2120x744.png" style="zoom:50%;"></p><p>In the above example, we are essentially performing one-shotprompting where we attempt to “teach” the model to provide an“<strong><em>A:</em></strong>” response after every“<strong><em>Q:</em></strong>”. However, since SSMs are time-invariantit cannot select which previous tokens to recall from its history.</p><p>Let’s illustrate this by focusing on <em>matrix B</em>. Regardless ofwhat the input <strong><em>x</em></strong> is, <em>matrix B</em> remainsexactly the same and is therefore independent of<strong><em>x</em></strong>:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee2bd7a-b99b-4871-8396-69cb7dd13cf5_1480x808.png" style="zoom:50%;"></p><p>Likewise, <em>A</em> and <em>C</em> also remain fixed regardless ofthe input. This demonstrates the <em>static</em> nature of the SSMs wehave seen thus far.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fea51ca-8458-4216-bf1c-c880a23504b4_1412x484.png" style="zoom:50%;"></p><p>In comparison, these tasks are relatively easy for Transformers sincethey <em>dynamically</em> change their attention based on the inputsequence. They can selectively “look” or “attend” at different parts ofthe sequence.</p><p>The poor performance of SSMs on these tasks illustrates theunderlying problem with time-invariant SSMs, the static nature ofmatrices <em>A</em>, <em>B</em>, and <em>C</em> results in problems with<em>content-awareness</em>.</p><h3 id="selectively-retain-information">Selectively RetainInformation</h3><p>The recurrent representation of an SSM creates a small state that isquite efficient as it compresses the entire history. However, comparedto a Transformer model which does no compression of the history (throughthe attention matrix), it is much less powerful.</p><p>Mamba aims to have the best of both worlds. A small state that is aspowerful as the state of a Transformer:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84b8a71a-6310-416b-8622-e9166593171e_1540x464.png" style="zoom:50%;"></p><p>As teased above, it does so by compressing data selectively into thestate. When you have an input sentence, there is often information, likestop words, that does not have much meaning.</p><p>To selectively compress information, we need the parameters to bedependent on the input. To do so, let’s first explore the dimensions ofthe input and output in an SSM during training:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9376222e-b232-4458-a72c-bd741d8a031c_1436x500.png" style="zoom:50%;"></p><p>In a Structured State Space Model (S4), the matrices <em>A</em>,<em>B</em>, and <em>C</em> are independent of the input since theirdimensions <strong><em>N</em></strong> and <strong><em>D</em></strong>are static and do not change.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e93b701-df74-4954-be5c-c0d83779d3df_1412x532.png" style="zoom:50%;"></p><p>Instead, Mamba makes matrices <em>B</em> and <em>C,</em> and even the<em>step size</em> <strong>∆</strong><em>,</em> dependent on the inputby incorporating the sequence length and batch size of the input:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdccefffd-5712-45ab-9821-c794bce65d7d_1412x596.png" style="zoom:50%;"></p><p>This means that for every input token, we now have different<em>B</em> and <em>C</em> matrices which solves the problem withcontent-awareness!</p><blockquote><p><strong>NOTE</strong>: Matrix <em>A</em> remains the same since wewant the state itself to remain static but the way it is influenced(through <em>B</em> and <em>C</em>) to be dynamic.</p></blockquote><p>Together, they <em>selectively</em> choose what to keep in the hiddenstate and what to ignore since they are now dependent on the input.</p><p>A smaller <em>step size</em> <strong>∆</strong> results in ignoringspecific words and instead using the previous context more whilst alarger <em>step size</em> <strong>∆</strong> focuses on the input wordsmore than the context:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06b21aab-aa32-450a-ae02-b976a2c9f9d8_2520x616.png" style="zoom:50%;"></p><h3 id="the-scan-operation">The Scan Operation</h3><p>Since these matrices are now <em>dynamic</em>, they cannot becalculated using the convolution representation since it assumes a<em>fixed</em> kernel. We can only use the recurrent representation andlose the parallelization the convolution provides.</p><p>To enable parallelization, let’s explore how we compute the outputwith recurrency:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed3ad33b-7b7f-4b69-b28e-8437c7b71e2e_1540x536.png" style="zoom:50%;"></p><p>Each state is the sum of the previous state (multiplied by<em>A</em>) plus the current input (multiplied by <em>B</em>). This iscalled a <em>scan operation</em> and can easily be calculated with a forloop.</p><p>Parallelization, in contrast, seems impossible since each state canonly be calculated if we have the previous state. Mamba, however, makesthis possible through the <em><a href="https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda">parallelscan</a></em> algorithm.</p><p>It assumes the order in which we do operations does not matterthrough the associate property. As a result, we can calculate thesequences in parts and iteratively combine them:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F191fdabe-6b38-4e6b-a9f0-8240feef0a9d_1640x1100.png" style="zoom:50%;"></p><p>Together, dynamic matrices <em>B</em> and <em>C</em>, and theparallel scan algorithm create the <strong><em>selective scanalgorithm</em></strong> to represent the dynamic and fast nature ofusing the recurrent representation.</p><h3 id="hardware-aware-algorithm">Hardware-aware Algorithm</h3><p>A disadvantage of recent GPUs is their limited transfer (IO) speedbetween their small but highly efficient SRAM and their large butslightly less efficient DRAM. Frequently copying information betweenSRAM and DRAM becomes a bottleneck.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a1d4fa3-526d-488e-8768-c7208f018eb4_1728x300.png" style="zoom:50%;"></p><p>Mamba, like Flash Attention, attempts to limit the number of times weneed to go from DRAM to SRAM and vice versa. It does so through<em>kernel fusion</em> which allows the model to prevent writingintermediate results and continuously performing computations until itis done.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563b3792-701a-42b1-9b68-7b6457f5e63d_1728x344.png" style="zoom:50%;"></p><p>We can view the specific instances of DRAM and SRAM allocation byvisualizing Mamba’s base architecture:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F724eceb1-4356-4ac5-b44e-f7fabce3b472_1728x580.png" style="zoom:50%;"></p><p>Here, the following are fused into one kernel:</p><ul><li><p>Discretization step with <em>step size</em><strong>∆</strong></p></li><li><p>Selective scan algorithm</p></li><li><p>Multiplication with <em>C</em></p></li></ul><p>The last piece of the hardware-aware algorithm is<em>recomputation</em>.</p><p>The intermediate states are not saved but are necessary for thebackward pass to compute the gradients. Instead, the authors recomputethose intermediate states <em>during</em> the backward pass.</p><p>Although this might seem inefficient, it is much less costly thanreading all those intermediate states from the relatively slow DRAM.</p><p>We have now covered all components of its architecture which isdepicted using the following image from its article:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc840fb8-2e24-4103-95c8-afa306ce0cfc_2409x743.png" style="zoom:50%;"></p><p><strong>The Selective SSM.</strong> Retrieved from: Gu, Albert, andTri Dao. "Mamba: Linear-time sequence modeling with selective statespaces." <em>arXiv preprint arXiv:2312.00752</em> (2023).</p><p>This architecture is often referred to as a <strong><em>selectiveSSM</em></strong> or <strong><em>S6</em></strong> model since it isessentially an S4 model computed with the selective scan algorithm.</p><h3 id="the-mamba-block">The Mamba Block</h3><p>The <em>selective SSM</em> that we have explored thus far can beimplemented as a block, the same way we can represent self-attention ina decoder block.</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb76db77-1dba-42bd-8de4-4bce240ff67e_1776x1012.png" style="zoom:50%;"></p><p>Like the decoder, we can stack multiple Mamba blocks and use theiroutput as the input for the next Mamba block:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc94d349d-8620-45a9-8095-7c27de8b7865_1660x1356.png" style="zoom:50%;"></p><p>It starts with a linear projection to expand upon the inputembeddings. Then, a convolution before the <em>Selective SSM</em> isapplied to prevent independent token calculations.</p><p>The <em>Selective SSM</em> has the following properties:</p><ul><li><p><em>Recurrent SSM</em> created through<em>discretization</em></p></li><li><p><em>HiPPO</em> initialization on matrix <em>A</em> to capture<em>long-range dependencies</em></p></li><li><p>S<em>elective scan algorithm</em> to selectively compressinformation</p></li><li><p><em>Hardware-aware algorithm</em> to speed upcomputation</p></li></ul><p>We can expand on this architecture a bit more when looking at thecode implementation and explore how an end-to-end example would looklike:</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67d7341-9a43-4c67-aa88-6e802c0902ae_1660x2040.png" style="zoom:50%;"></p><p>Notice some changes, like the inclusion of normalization layers andsoftmax for choosing the output token.</p><p>When we put everything together, we get both fast inference andtraining and even unbounded context!</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe528e5fa-0dd8-4e6c-b31a-5248aaee6c68_2072x912.png" style="zoom:50%;"></p><p>Using this architecture, the authors found it matches and sometimeseven exceeds the performance of Transformer models of the same size!</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>This concludes our journey in State Space Models and the incredibleMamba architecture using a selective State Space Model. Hopefully, thispost gives you a better understanding of the potential of State SpaceModels, particularly Mamba. Who knows if this is going to replace theTransformers but for now, it is incredible to see such differentarchitectures getting well-deserved attention!</p><h2 id="resources">Resources</h2><p>Hopefully, this was an accessible introduction to Mamba and StateSpace Models. If you want to go deeper, I would suggest the followingresources:</p><ul><li><a href="https://srush.github.io/annotated-s4/">The Annotated S4</a>is a JAX implementation and guide through the S4 model and is highlyadvised!</li><li>A great <a href="https://www.youtube.com/watch?v=ouF-H35atOY">YouTube video</a>introducing Mamba by building it up through foundational papers.</li><li><a href="https://github.com/state-spaces/mamba">The Mambarepository</a> with <a href="https://huggingface.co/state-spaces">checkpoints on HuggingFace</a>.</li><li>An amazing series of blog posts (<a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-1">1</a>, <a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-2">2</a>, <a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3">3</a>)that introduces the S4 model.</li><li>The <a href="https://jameschen.io/jekyll/update/2024/02/12/mamba.html">MambaNo. 5 (A Little Bit Of...)</a> blog post is a great next step to diveinto more technical details about Mamba but still from an amazinglyintuitive perspective.</li><li>And of course, <a href="https://arxiv.org/abs/2312.00752">the Mambapaper</a>! It was even used for DNA modeling and speech generation.</li></ul><hr><h2 id="references">References</h2><blockquote><p>[1]原Blog链接：https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state</p><p>[2] 一文通透想颠覆Transformer的Mamba：从SSM、HiPPO、S4到Mambahttps://blog.csdn.net/v_JULY_v/article/details/134923301</p><p>[3]</p><p>[4] Gu, A., &amp; Dao, T. (2023). Mamba: Linear-time sequencemodeling with selective state spaces. <em>arXiv preprintarXiv:2312.00752</em>.</p><p>[5]</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h1 id=&quot;mamba&quot;&gt;Mamba&lt;/h1&gt;
&lt;!--本文是根据Mamba论文原作者撰写的Blog进行阅读的重点解读--&gt;
&lt;p&gt;The Transformer architec</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="http://junlei-zhou.com/tags/Deep-Learning/"/>
    
    <category term="Sequence Model" scheme="http://junlei-zhou.com/tags/Sequence-Model/"/>
    
    <category term="State space model" scheme="http://junlei-zhou.com/tags/State-space-model/"/>
    
  </entry>
  
  <entry>
    <title>Support-Vector-Machine</title>
    <link href="http://junlei-zhou.com/2024/05/29/Support-Vector-Machine/"/>
    <id>http://junlei-zhou.com/2024/05/29/Support-Vector-Machine/</id>
    <published>2024-05-29T07:56:16.000Z</published>
    <updated>2025-02-25T07:58:11.627Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="支持向量机-support-vector-machine">支持向量机 (Support VectorMachine)</h1><h2 id="简介">简介</h2><p>支持向量机是无监督机器学习中一个经典的算法，具有完善的数学理论和推理证明。本文将从SVM问题定义，模型建立，数学推理对SVM进行详细的论述。</p><h2 id="线性可分-linear-separable">线性可分 (Linear Separable)</h2><h4 id="问题定义">问题定义</h4><p>在一个样本空间中，给定训练样本集，在样本空间中能够找到一个划分超平面，将不同类别的样本区分开。</p><p><img src="https://imgur.la/images/2024/06/03/image-20240530093244843.png" alt="SVM_image1" style="zoom:33%;"></p><center><p>图1：线性可分，存在多个超平面将两类训练样本分开</p></center><p><strong>结论1：在一个空间中，如果存在一条直线能够划分两个点集，那么将存在无数条直线能够划分这两个点集。(证明见附录)</strong></p><h4 id="数学定义"><strong>数学定义</strong></h4><p><span class="math inline">\(D_1\)</span>和 <span class="math inline">\(D_2\)</span> 是 n 维欧氏空间中的两个点集。如果存在n 维向量 <span class="math inline">\(w\)</span> 和实数 <span class="math inline">\(b\)</span> 使得所有属于 <span class="math inline">\(D_0\)</span> 的点 <span class="math inline">\(x_i\)</span> 都有 <span class="math inline">\(wx_i+b&gt;0\)</span>, 而对于所有属于 <span class="math inline">\(D_1\)</span> 的点 <span class="math inline">\(x_j\)</span> 则有 <span class="math inline">\(wx_j+b&lt;0\)</span>，则我们称 <span class="math inline">\(D_0\)</span> 和 <span class="math inline">\(D_1\)</span> 线性可分。</p><h2 id="svm解决线性问题">SVM解决线性问题</h2><h4 id="线性问题定义">线性问题定义</h4><p>由 <strong>结论1</strong>可得，对于一个线性可分的问题，存在无数条满足要求的直线，那么究竟哪一条直线是最好的？</p><p><img src="https://imgur.la/images/2024/06/03/image-20240530104549138.png" alt="image-20240530104549138" style="zoom: 33%;"></p><center><p>图2：线性可分，存在多个超平面将两类训练样本分开</p></center><p>直观上看，应该去找位于两类训练样本“正中间”的划分超平面，即图中红色的直线，因为该划分超平面对训练样本局部扰动的“容忍”性最好，例如，由于训练集的局限性或噪声的因素，训练集外的样本可能比图中的训练样本更接近两个类的分隔界，这将使许多划分超平面出现错误，而红色的超平面受影响最小，换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见示例的泛化能力最强。</p><p><strong>问题1：我们怎样定义这样一个最好的直线？</strong>答：为每条直线定义一个性能指标，将每条直线平移直至该直线能够插到最边缘的样本点，如下图所示：</p><p><img src="https://imgur.la/images/2024/06/03/image-20240530112035809.png" alt="image-20240530112035809" style="zoom: 33%;"></p><center><p>图3：支持向量与间隔</p></center><p>如图3所示，我们做如下定义：</p><p><span class="math inline">\(r\)</span> :间隔(Margin)，将平行线平移直至插到支持向量的距离</p><p><span class="math inline">\(x\)</span> : 训练集中的样本</p><p><span class="math inline">\(y\)</span> : 训练集中样本对应的标签</p><p><span class="math inline">\(D=\{(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)\},y_i\in\{-1,+1\}\)</span> : 训练样本集</p><p><span class="math inline">\(w^Tx+b=0\)</span> :超平面(Hypeplane)，即上文中提到的直线，在二维空间中是一条直线，在高维空间中，则是超平面(hyperplane)。</p><h4 id="svm基本型">SVM基本型</h4><p>支持向量机——线性可分，本质为最大化 <strong>Margin</strong>问题，属于凸优化中的 <strong>二次规划</strong> 问题。</p><ul><li>最小化 (Minimize) : <span class="math inline">\(\frac{1}{2}||w||^2\)</span></li><li>限制条件 (Subject to) : <span class="math inline">\(y_i[w^Tx_i+b]\geq1, \ \ \ \ \ \ \ \ \ \ \ \i=1，2,\dots,n\)</span></li></ul><p><strong>解释：</strong></p><p><strong>定理1：</strong><span class="math inline">\(w^T+b=0\)</span>与 <span class="math inline">\(aw^T+ab=0\)</span> 是同一个超平面，若<span class="math inline">\((w,b)\)</span> 满足 <span class="math inline">\(y_i[w^Tx_i+b]\geq1\)</span> 那么 <span class="math inline">\((aw,ab)\)</span> 也满足 <span class="math inline">\(y_i[aw^Tx_i+ab]\geq1\)</span> 。</p><p><strong>定理2：</strong>点 <span class="math inline">\((x_0,y_0)\)</span> 到直线 <span class="math inline">\(ax+by+c=0\)</span> 的距离 <span class="math inline">\(d=\frac{|ax_0+by_0+c|}{\sqrt{a^2+b^2}}\)</span> ;点到超平面 <span class="math inline">\(H\)</span> 的距离即 <span class="math inline">\(r=\frac{|w^Tx_0+b|}{||w||}\)</span>.</p><p>由 <strong>定理1</strong>我们可以通过缩放将 <span class="math inline">\(|w^Tx_0+b|\)</span> 通过乘以一个缩放因子 <span class="math inline">\(a\)</span> 使得 <span class="math inline">\(|aw^Tx_0+ab|=1\)</span>, 则此时 <span class="math inline">\(r=\frac{1}{||w||}\)</span>, 故而最大化<strong>Margin</strong> 即可以转变为最小化 <span class="math inline">\(||w||\)</span>问题。由于我们在计算机中使用梯度下降进行最优化求解，为了求导数方便，因此常常使用<span class="math inline">\(||w||^2\)</span> 或者 <span class="math inline">\(\frac{1}{2}||w||^2\)</span> 的形式来代替 <span class="math inline">\(||w||\)</span> 。</p><p>限制条件 :即对于所有的样本点，除了支持向量，其他的点都必须比支持向量到超平面的距离要远。</p><p>到此，SVM的基本型便定义完成，这是一个简单的凸优化问题，我们可以使用简单的凸优化求解方法来实现计算(如梯度下降法)。</p><h2 id="svm解决非线性问题">SVM解决非线性问题</h2><h4 id="非线性可分">非线性可分</h4><p><img src="https://imgur.la/images/2024/06/05/SVM_image4_5.png" alt="SVM image4 5" border="0" style="zoom: 33%;"></p><center><p>图4：非线性可分，在二维空间中，我们无法找到一条直线来分离这两个类别</p></center><p>如图4所示，对于非线性可分的情况，在二维空间中我们无法使用一条直线或者一个平面将两个类别完全区分。在低维空间中我们无法有效地将这两类点完全区分，但在高维空间中，我们可以找到一个超平面来完全区分这两类点(<a href="https://en.wikipedia.org/wiki/Cover%27s_theorem"><strong>Cover’stheorem</strong></a>) .</p><p><img src="https://imgur.la/images/2024/06/03/SVM_image64b9b723ba732350b.png" alt="SVM image6" border="0" style="zoom: 25%;"></p><center><p>图5：在低维空间中非线性可分，但将这些点映射到高维空间中则线性可分</p></center><p>因此，为了寻找一个超平面，我们需要将原本的样本点 <span class="math inline">\(x\)</span> 映射到一个高维空间中去，即设 <span class="math inline">\(\varphi(x)\)</span> 为映射函数，<span class="math inline">\(\varphi(x): \mathcal{X}\longrightarrow\mathcal{H}\)</span>，其中 <span class="math inline">\(\mathcal{X}\)</span> 为原输入空间，<span class="math inline">\(\mathcal{H}\)</span> 为特征空间( <span class="math inline">\(\mathcal{H}\)</span> 是Hibert Space，即完备的内积空间) <span class="math display">\[x \stackrel{\varphi}{\longrightarrow}\varphi(x)\]</span> <strong>问题2: 如何寻找这个高维映射方法？</strong> 直接将<span class="math inline">\(x\)</span> 映射为为无限维。</p><p>但此时由于 <span class="math inline">\(\varphi(x)\)</span>是无限维，无法计算。 此时我们使用 <strong>核技巧(kernel trick) :在输入空间中找到一个核函数(kernel function) <span class="math inline">\(K(x_1,x_2)\)</span> 使得 <span class="math inline">\(K(x_1,x_2)=&lt;\varphi(x_1),\varphi(x_2)&gt;\)</span>,从而可以直接在低维空间中计算出结果，加速核方法计算。</strong>(相关性质及定义请见 <strong>附录：核函数</strong>)</p><p><strong>问题3：如何实现非线性中完全区分不同类的点？</strong></p><p>为了使线性可分的SVM优化泛化到非线性可分的情况，我们允许支持向量机在一些样本上出错，为此引入了<strong>软间隔 (Soft Margin)</strong>，允许少部分样本可以不满足约束<span class="math inline">\(y_i[w^Tx_i+b]\geq1\)</span>,但在最大化间隔的同时，应该保证不满足约束的样本数量尽可能的少，因此优化目标进一步可以变为：<span class="math display">\[\mathop{\min}_{w,b}\  \frac{1}{2}||w||^2+C\sum\limits_{i=1}^{N}\mathscr{l}_{0/1}(y_i[w^Tx_i+b]-1)\]</span> 其中 <span class="math inline">\(C&gt;0\)</span>是一个常数，<span class="math inline">\(\mathscr{l}_{0/1}\)</span>是"0/1损失函数" <span class="math display">\[\mathscr{l}_{0/1}(z)= \left \{ \begin{array}{rcl} 1, &amp; \mbox{if}\ \z&lt;0; \\ 0, &amp; \mbox{otherwise.} \end{array} \right.\]</span> 其中，当 <span class="math inline">\(C\)</span>为无穷大时，新的优化目标式子能够迫使所有的样本均满足约束式子。此时 <span class="math inline">\(\frac{1}{2}||\omega||^2+C\sum\limits_{i=1}^{N}\mathscr{l}_{0/1}(y_i[w^Tx_i+b]-1)\)</span> 与 <span class="math inline">\(\frac{1}{2}||w||^2\)</span> 等价；当 <span class="math inline">\(C\)</span>为有限值时，新的优化目标允许一部分样本不满足约束。</p><p>然而，<span class="math inline">\(\mathscr{l}_{0/1}\)</span>非凸、非连续，数学性质不好，导致不易直接求解，故而我们通常使用其他的一些函数代替<span class="math inline">\(\mathscr{l}_{0/1}\)</span> 并称之为"替代损失 (surrogateloss)"。这些替代损失通常具有较好的数学性质，通常是凸的连续函数且是 <span class="math inline">\(\mathscr{l}_{0/1}\)</span>的上界。如我们采用hinge损失代替 <span class="math inline">\(\mathscr{l}_{0/1}\)</span> 则优化目标可以变为<span class="math display">\[\mathop{\min}_{w,b}\  \frac{1}{2}||\omega||^2+C\sum\limits_{i=1}^{N}\max(0,\ 1-y_i[w^Tx_i+b])\]</span> 实际中我们可以引入<strong>松弛变量 (Slack Variable) <span class="math inline">\(\xi_i\geq0\)</span></strong>来代替上式中的替代损失，得到 <span class="math display">\[\mathop{\min}_{w,b}\ \frac{1}{2}||\omega||^2+C\sum\limits_{i=1}^{N}\xi_i\]</span>从机器学习的角度来看，非线性SVM的优化目标可以看作为对线性的SVM优化目标添加了一个<strong>正则项 (Regulation) <span class="math inline">\(C\sum\limits_{i=1}^{N}\xi_i\)</span></strong></p><h4 id="非线性svm优化">非线性SVM优化</h4><p>支持向量机——非线性可分 ("软间隔"支持向量机)</p><ul><li>最小化 (Minimize) : <span class="math inline">\(\frac{1}{2}||w||^2+C\sum\limits_{i=1}^{N}\xi_i\)</span></li><li>限制条件 (Subject to) :<ul><li>​ <span class="math inline">\(y_i[w^T\varphi(x_i)+b]\geq1-\xi_i, \ \\ \ \ \ \ \ \ \ \ \ i=1，2,\dots,n\)</span></li><li>​ <span class="math inline">\(\xi_i\geq0\)</span></li></ul></li></ul><p>在这个式子中存在高维映射 <span class="math inline">\(\varphi(x_i)\)</span>,因而无法直接求解，因此我们要将该优化问题转换为可以求解的形式。</p><h4 id="解非线性svm的优化问题">解非线性SVM的优化问题</h4><p><strong>关键：将非线性的SVM优化问题转换为其对应的对偶问题，利用求其对偶问题的解来代替求原非线性SVM问题的解</strong></p><p>(原问题与对偶问题的关系证明见附录——优化理论：原问题与对偶问题)</p><ul class="task-list"><li><p><label><input type="checkbox"><strong>Step 1:</strong>为了方便转换为其对应的对偶问题，首先要转变原问题的形式，使其与附录中的原问题的形式相一致。</label></p><p><img src="https://imgur.la/images/2024/06/05/SVM_image7.png" alt="SVM image7" border="0"></p><center><p></p><p>图6：将非线性SVM的优化问题形式转换，与原问题中的形式保持一致</p><p></p></center><p><strong>解释：</strong>其中 <span class="math inline">\(\xi_i\)</span> 是松弛变量，我们调整其取值范围为<span class="math inline">\(\xi_i\leq0\)</span>,相比较于原式子，只是在原来的 <span class="math inline">\(\xi_i\)</span>前面加了一个 "负号"。因此保证之前的优化目标不变，故而要变为 <span class="math inline">\(\frac{1}{2}||w||^2-C\sum\limits_{i=1}^{N}\xi_i\)</span> ,限制条件变为 <span class="math inline">\(y_i[w^T\varphi(x_i)+b]\geq1+\xi_i\)</span> ,将其移项得 <span class="math inline">\(1+\xi_i-y_iw^T\varphi(x_i)-y_ib\leq0\)</span>。此时原问题中的 <span class="math inline">\(f(w)\Longrightarrow\frac{1}{2}||\omega||^2-C\sum \limits_{i=1}^{N}\xi_i\)</span> , <span class="math inline">\(g_i(w)\leq0 \Longrightarrow1+\xi_i-y_iw^T\varphi(x_i)-y_ib\leq0 和 \xi_i\leq0\)</span> 。</p><h5 id="非线性svm优化-转换后">非线性SVM优化 (转换后)</h5><p>支持向量机——非线性可分 ("软间隔"支持向量机)</p><ul><li>最小化 (Minimize) : <span class="math inline">\(\frac{1}{2}||\omega||^2-C\sum\limits_{i=1}^{N}\xi_i\)</span></li><li>限制条件 (Subject to) :<ul><li>​ <span class="math inline">\(1+\xi_i-y_iw^T\varphi(x_i)-y_ib\leq0, \\ \ \ \ \ \ \ \ \ \ \ i=1，2,\dots,n\)</span></li><li>​ <span class="math inline">\(\xi_i\leq0\)</span></li></ul></li></ul></li><li><p><label><input type="checkbox"><strong>Step 2: </strong>寻找转换后的非线性SVM优化问题的对偶问题，根据<strong>附录——优化理论：原问题与对偶问题</strong>我们可得其对偶问题为：</label></p><h5 id="非线性svm优化问题的对偶问题">非线性SVM优化问题的对偶问题</h5><ul><li>最大化 (Maximum) : <span class="math inline">\(\theta(\alpha,\beta)=\inf\limits_{w,\xi_i,b}\{\frac{1}{2}||\omega||^2-C\sum\limits_{i=1}^N\xi_i+\sum\limits_{i=1}^{N}\alpha_i[1+\xi_i-y_iw^T\varphi(x_i)-y_ib]+\sum\limits_{i=1}^{N}\beta_i\xi_i\}\)</span></li><li>限制条件 (Subject to) : <span class="math inline">\(i=1,2,\dots,N\)</span><ul><li><span class="math inline">\(\alpha_i\geq0\)</span> or <span class="math inline">\(\alpha\succeq0\)</span></li><li><span class="math inline">\(\beta_i\geq0\)</span> or <span class="math inline">\(\beta\succeq0\)</span></li></ul></li></ul><p><strong>解释：</strong>其中优化目标中的 <span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\beta\)</span> 与<strong>附录——优化理论：原问题与对偶问题</strong>中的拉格朗日乘子中稍微有些不同，在原拉格朗日乘子中<span class="math inline">\(\alpha\)</span> 控制限制条件中不等式， <span class="math inline">\(\beta\)</span>控制限制条件中的等式。由于我们转换后的非线性SVM优化问题的限制条件中不存在等式<span class="math inline">\(h_i(w)=0\)</span>这一项，故而非线性SVM优化问题对应的拉格朗日乘子 <span class="math inline">\(L(w,\alpha,\beta)=f(w)+\sum\limits_{i=1}^{K}\alpha_ig_i(w)+\sum\limits_{i=1}^{M}\beta_ih_i(w)\)</span> 中不存在 <span class="math inline">\(\sum \limits_{i=1}^{M}\beta_ih_i(w)\)</span>项。而我们转换后的非线性SVM优化问题的限制条件中存在两个不等式，故而非线性SVM优化问题对应的拉格朗日乘子包含了两个控制不等式的<span class="math inline">\(\alpha\)</span>,这里是为了在同一个式子中便于区分故而分别写为了 <span class="math inline">\(\alpha,\beta\)</span>, 我们转化后的对偶问题中的<span class="math inline">\(\alpha,\beta\)</span> 都对应拉格朗日乘子中的<span class="math inline">\(\alpha\)</span>. 对于限制条件中 <span class="math inline">\(\alpha_i\geq0\)</span> 与 $$0的写法不同但含义相同，只不过前者表示向量 <span class="math inline">\(\alpha\)</span> 中的每一项都大于0，而后者表示向量<span class="math inline">\(\alpha\)</span> 大于0.</p></li><li><p><label><input type="checkbox"><strong>Step 3:</strong>求对偶问题的解，即要求出一组 <span class="math inline">\(w,\xi_i,b\)</span> 使优化目标中 <span class="math inline">\(\{\cdots\}\)</span> 部分最小。</label></p><p>利用求导法，令 <span class="math display">\[\begin{align}&amp;\frac{\partial L}{\partial\omega}=0 \ \ \ \Longrightarroww-\sum_{i=1}^{N}\alpha_iy_i\varphi(x_i)=0 \ \ \ \Longrightarroww=\sum_{i=1}^{N}\alpha_iy_i\varphi(x_i) \\&amp;\frac{\partial L}{\partial\xi_i}=0 \ \ \ \Longrightarrow\alpha_i+\beta_i=C \ \ \ \Longrightarrow \alpha_i+\beta_i=C \\&amp;\frac{\partial L}{\partial b}=0 \ \ \ \Longrightarrow\sum_{i=1}^{N}\alpha_iy_i=0\end{align}\]</span> 将上式代入 <span class="math inline">\(\theta(\alpha,\beta)\)</span> 得： <span class="math display">\[\begin{align}\theta(\alpha,\beta)&amp;=\inf \limits_{w,\xi_i,b}\{\frac{1}{2}||w||^2-C\sum\limits_{i=1}^N\xi_i+\sum_{i=1}^{N}\alpha_i[1+\xi_i-y_iw^T\varphi(x_i)-y_ib]+\sum_{i=1}^{N}\beta_i\xi_i\} \\&amp;=\inf \limits_{w,\xi_i,b}\{\frac{1}{2}w^Tw-\bcancel{\sum_{i=1}^{N}\alpha_i\xi_i}-\bcancel{\sum_{i=1}^{N}\beta_i\xi_i}+\sum_{i=1}^{N}\alpha_i+\bcancel{\sum_{i=1}^{N}\alpha_i\xi_i}-\sum_{i=1}^{N}\alpha_iy_i\varphi(x_i)w^T-\bcancel{\sum_{i=1}^{N}\alpha_iy_ib}+\bcancel{\sum_{i=1}^{N}\beta_i\xi_i}\} \\&amp;=\inf \limits_{w,\xi_i,b}\{\frac{1}{2}\big(\sum_{i=1}^{N}\alpha_iy_i\varphi(x_i)\big)^T\big(\sum_{j=1}^{N}\alpha_jy_j\varphi(x_j)\big)+\sum_{i=1}^{N}\alpha_i-\big(\sum_{i=1}^{N}\alpha_iy_i\varphi(x_i)\big)^T\big(\sum_{j=1}^{N}\alpha_jy_j\varphi(x_j)\big)\} \\&amp;=\inf \limits_{w,\xi_i,b}\{\sum_{i=1}^{N}\alpha_i-\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\underbrace{\alpha_i\alpha_j}_{常数}\underbrace{y_iy_j}_{y=\pm1}\underbrace{\varphi(x_i)^T\varphi(x_j)}_{K(x_i,x_j)}\}\end{align}\]</span> 最后，对偶问题可以转换为：</p><h5 id="非线性svm优化问题的对偶问题-求解后">非线性SVM优化问题的对偶问题(求解后)</h5><ul><li>最大化 (Maximum) : <span class="math inline">\(\theta(\alpha)=\sum\limits_{i=1}^{N}\alpha_i-\frac{1}{2}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N}\alpha_i\alpha_j\underbrace{y_jy_i}_{已知}\underbrace{K(x_i,x_j)}_{已知}\)</span></li><li>限制条件 (Subject to) : <span class="math inline">\(i=1,2,\dots,N\)</span><ul><li><span class="math inline">\(\alpha\geq0, \&amp;\&amp;\  \beta_i\geq0\ \ \ \Longrightarrow\ 0\leq\alpha_i\leq C\)</span></li><li><span class="math inline">\(\sum\limits_{i=1}^{N}\alpha_iy_i=0\)</span></li></ul></li></ul><p>此时，该问题变为了一个基本的凸优化问题，我们可以使用 <a href="https://en.wikipedia.org/wiki/Sequential_minimal_optimization"><strong>SMO算法</strong></a>对其进行求解。</p></li><li><p><label><input type="checkbox"><strong>Step 4: </strong>将求<span class="math inline">\(\alpha\)</span> 转化为求 <span class="math inline">\(w,b\)</span>.</label></p><p>由 <strong>Step 3</strong> 有 <span class="math inline">\(w=\sum\limits_{i=1}^{N}\alpha_iy_i\varphi(x_i)\)</span>，但其中仍然存在高维向量 <span class="math inline">\(\varphi(x_i)\)</span>似乎无法求解，但实际上，我们对于一个测试样本 <span class="math inline">\(x\)</span> ,则有: <span class="math display">\[\left\{ \begin{array}{rcl}若w^T\varphi(x)+b\geq0,则\ y=+1\\若w^T\varphi(x)+b&lt;0,则\ y=-1\end{array}\right.\]</span> 其中 <span class="math inline">\(w^T\varphi(x)=\sum\limits_{i=1}^{N}\alpha_iy_i\varphi(x_i)^T\varphi(x_i)\\  \Longrightarrow \sum\limits_{i=1}^{N}\alpha_iy_iK(x_i,x)\)</span> ,即我们不需要知道 <span class="math inline">\(w\)</span>具体是多少，我们可以直接算出 <span class="math inline">\(w^T\varphi(x)\)</span> 的值。</p><p>现在只需要求出 <span class="math inline">\(b\)</span> 即可，利用<strong>KKT条件</strong> 求 <span class="math inline">\(b\)</span>.</p><p><strong>KKT条件：</strong>对于 <span class="math inline">\(\foralli=1,2,\dots,K.\)</span> 则有 <span class="math inline">\(\alpha_i^*=0\)</span> 或者 <span class="math inline">\(g_i(w^*)=0\)</span> .</p><p><strong>转化为SVM中的KKT</strong>，则有 <span class="math inline">\(\forall\  i=1,2,\dots,N\)</span></p><p><span class="math inline">\(\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\ \ \ \blacktriangleright\)</span> 要么 $ _i=0$, 要么 <span class="math inline">\(\xi_i=0\)</span></p><p><span class="math inline">\(\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\ \ \ \blacktriangleright\)</span> 要么 <span class="math inline">\(\alpha_i=0\)</span>, 要么 <span class="math inline">\(1+\xi_i-y_iw^T\varphi(x_i)-y_ib=0\)</span></p><p>因此，我们随机选取一个 <span class="math inline">\(\alpha_i\)</span>, 则 <span class="math inline">\(0&lt;\alpha_i&lt;C\)</span>， 故而<span class="math inline">\(\beta_i=C-\alpha_i&gt;0\)</span></p><p><span class="math inline">\(\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\therefore \beta_i\neq0, \ 则\ \xi_i=0\)</span>,</p><p><span class="math inline">\(\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\therefore \alpha_i\neq0, \ 则 \1+\xi_i-y_iw^T\varphi(x_i)-y_ib=0\)</span></p><p><span class="math inline">\(\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\thereforeb=\frac{1}{y_i}-\sum_{i=1}^{N}\alpha_iy_iK(x_i,x)\)</span></p><p>至此，非线性SVM的优化问题求解完毕！</p></li></ul><h2 id="总结">总结</h2><h4 id="svm算法训练过程">SVM算法：训练过程</h4><p>输入 <span class="math inline">\(\{(x_i,y_i)\}_{i=1,2,\dots,N}\)</span>，解优化问题</p><ul><li>最大化 (Maximum) : <span class="math inline">\(\theta(\alpha)=\sum\limits_{i=1}^{N}\alpha_i-\frac{1}{2}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N}\alpha_i\alpha_j\underbrace{y_jy_i}_{已知}\underbrace{K(x_i,x_j)}_{已知}\)</span></li><li>限制条件 (Subject to) : <span class="math inline">\(i=1,2,\dots,N\)</span><ul><li><span class="math inline">\(\alpha\geq0, \&amp;\&amp;\  \beta_i\geq0\ \ \ \Longrightarrow\ 0\leq\alpha_i\leq C\)</span></li><li><span class="math inline">\(\sum\limits_{i=1}^{N}\alpha_iy_i=0\)</span></li></ul></li></ul><p>利用SMO算法求解最优化问题，得出 <span class="math inline">\(\alpha\)</span>, 下一步寻找一个 <span class="math inline">\(0&lt;\alpha_i&lt;0\)</span>，计算 <span class="math inline">\(b\)</span> :</p><p>​ <span class="math inline">\(b=\frac{1}{y_i}-\sum_{i=1}^{N}\alpha_iy_iK(x_i,x)\)</span></p><h4 id="svm算法测试过程">SVM算法：测试过程</h4><p>输入样本 <span class="math inline">\(x\)</span>：</p><ul><li>若 <span class="math inline">\(\sum\limits_{i=1}^{N}\alpha_iy_iK(x_i,x)+b\geq0\)</span>,则 $ y=+1$,</li><li>若 <span class="math inline">\(\sum\limits_{i=1}^{N}\alpha_iy_iK(x_i,x)+b&lt;0\)</span>,则 $ y=+1$.</li></ul><h2 id="附录">附录</h2><h4 id="结论1证明">结论1证明：</h4><h5 id="二维平面上的证明">二维平面上的证明</h5><p>假设我们有两个点集 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span>，并且这两个点集是线性可分的。这意味着存在一条直线可以将这两个点集分开。为了证明存在无数条直线能够划分这两个点集，我们可以如下进行证明：</p><ol type="1"><li><p><strong>存在一条直线</strong>：假设存在一条直线 <span class="math inline">\(L\)</span> 可以将点集 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。直线 <span class="math inline">\(L\)</span> 可以表示为： <span class="math display">\[𝑦=k𝑥+b\]</span> 其中 <span class="math inline">\(k\)</span> 是斜率，<span class="math inline">\(b\)</span> 是截距。</p></li><li><p><strong>平行直线的性质</strong>：对于任何一个固定的斜率𝑚<em>m</em>，不同的截距 𝑐<em>c</em>会产生不同的平行直线。设我们有另一条直线 𝐿′<em>L</em>′ 其方程为： <span class="math display">\[𝑦=𝑚𝑥+b^′\]</span> 其中 <span class="math inline">\(b&#39;\neq b\)</span>，则<span class="math inline">\(L&#39;\)</span> 与 <span class="math inline">\(L\)</span> 平行。</p></li><li><p><strong>平行直线的分离能力</strong>：由于 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 是线性可分的，这意味着可以找到一个间隔<span class="math inline">\(\epsilon\)</span> 使得在直线 <span class="math inline">\(L\)</span>的一侧存在一个空隙，其中没有任何点在此区域。换句话说，我们可以调整<span class="math inline">\(b\)</span> 的值，使得新的直线 <span class="math inline">\(L&#39;\)</span> 依然可以将 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。</p></li><li><p><strong>无数条平行直线</strong>：由于 <span class="math inline">\(b\)</span>可以在实数范围内任意取值，因此存在无数个不同的 <span class="math inline">\(b\)</span> 值，这意味着存在无数条平行直线可以将<span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。</p></li><li><p><strong>非平行直线</strong>：除了平行直线之外，我们还可以选择不同的斜率<span class="math inline">\(k&#39;\)</span>。对任何新的斜率 <span class="math inline">\(k&#39;\)</span>，只要新的直线方程能够满足分离点集的条件，我们就可以调整其截距<span class="math inline">\(b&#39;\)</span> 使得新的直线 <span class="math inline">\(y=k&#39;x+b&#39;\)</span> 依然可以将 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。</p></li></ol><h5 id="高维空间的推广">高维空间的推广</h5><p>在高维空间中，能够分离点集的“直线”实际上是一个超平面。假设我们有两个点集<span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span>，并且它们是线性可分的，即存在一个超平面<span class="math inline">\(H\)</span>可以将它们分开。超平面方程可以表示为： <span class="math display">\[w\cdot x+b=0\]</span> 其中 <span class="math inline">\(w\)</span> 是法向量，<span class="math inline">\(b\)</span> 是偏置项。</p><ol type="1"><li><strong>存在一个超平面</strong>：假设存在一个超平面 <span class="math inline">\(H\)</span> 可以将 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。</li><li><strong>平行超平面</strong>：对于任何固定的法向量 <span class="math inline">\(w\)</span>，不同的偏置 <span class="math inline">\(b\)</span> 会产生不同的平行超平面。</li><li><strong>无数个平行超平面</strong>：由于 <span class="math inline">\(b\)</span>可以在实数范围内任意取值，因此存在无数个不同的 <span class="math inline">\(b\)</span> 值，这意味着存在无数个平行超平面可以将𝐴<em>A</em> 和 𝐵<em>B</em> 分开。</li><li><strong>非平行超平面</strong>：我们还可以选择不同的法向量 <span class="math inline">\(w&#39;\)</span>。对于任何新的法向量 <span class="math inline">\(w&#39;\)</span>，只要新的超平面方程能够满足分离点集的条件，我们就可以调整其偏置<span class="math inline">\(b\)</span> 使得新的超平面 <span class="math inline">\(w&#39;\cdot x+b&#39;=0\)</span> 依然可以将 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 分开。</li></ol><h4 id="核函数">核函数</h4><ul><li><p>在实际应用时，映射函数 <span class="math inline">\(\varphi(x)\)</span>不需要是已知的。换句话说，核技巧的目的就是在不需要显式地定义特征空间和映射函数的条件下，计算映射之后的内积</p></li><li><p>核函数 <span class="math inline">\(K(x_1,x_2)=&lt;\varphi(x_1),\varphi(x_2)&gt;\)</span>需要满足的充要条件 (不需要 <span class="math inline">\(\varphi(x)\)</span> 已知) (<a href="%5BMercer&#39;s%20theorem%20-%20Wikipedia%5D(https://en.wikipedia.org/wiki/Mercer&#39;s_theorem)">Mercer'sTheorem</a>):</p><ul><li><p>对称性: <span class="math inline">\(K(x_1,x_2)=K(x_2,x_1)\)</span></p></li><li><p>半正定性: 对于任意 <span class="math inline">\(n\)</span> 和任意<span class="math inline">\(x_1,x_2,\dots,x_n∈\mathcal{X}\)</span>，由<span class="math inline">\(K(x_i,x_j)\)</span> 定义的 Gram matrix总是半正定的，即 <span class="math display">\[对于\forall C_i,x_i, (i=1，2,\dots,n),有\sum_{i=1}^N\sum_{j=1}^NC_iC_jK(x_1,x_2)\geq0\ \ \ \ \ \ \ \ \ \ \ \ \ \\ C_i为任意实数，x_i为任意的向量.\]</span></p></li></ul></li><li><p>只要 <span class="math inline">\(K\)</span>是核函数，那么一定存在一个Hilbert space和一个映射函数 <span class="math inline">\(\varphi(x)\)</span>，使得 <span class="math inline">\(K(x_1,x_2)=&lt;\varphi(x_1),\varphi(x_2)&gt;\)</span></p></li><li><p>常见核函数</p><table><colgroup><col style="width: 9%"><col style="width: 47%"><col style="width: 42%"></colgroup><thead><tr class="header"><th>名称</th><th>表达式</th><th>参数</th></tr></thead><tbody><tr class="odd"><td>线性核</td><td><span class="math inline">\(K(x_1,x_2)=x_i^Tx_j\)</span></td><td></td></tr><tr class="even"><td>多项式核</td><td><span class="math inline">\(K(x_1,x_2)=(x_i^Tx_j)^d\)</span></td><td><span class="math inline">\(d\geq1\)</span>为多项式的次数</td></tr><tr class="odd"><td>高斯核</td><td><span class="math inline">\(K(x_1,x_2)=\exp(-\frac{||x_i-x_j||^2}{2\sigma^2})\)</span></td><td><span class="math inline">\(\sigma&gt;0\)</span>，为高斯核的带宽(width)</td></tr><tr class="even"><td>拉普拉斯核</td><td><span class="math inline">\(K(x_1,x_2)=\exp(-\frac{||x_i-x_j||}{\sigma})\)</span></td><td><span class="math inline">\(\sigma&gt;0\)</span></td></tr><tr class="odd"><td>Sigmoid核</td><td><span class="math inline">\(K(x_1,x_2)=\tanh(\betax_i^Tx_j+\theta)\)</span></td><td><span class="math inline">\(\tanh\)</span> 为双曲正切函数，<span class="math inline">\(\beta&gt;0,\ \ \theta&lt;0\)</span></td></tr></tbody></table><h4 id="替代损失函数">替代损失函数</h4><table><colgroup><col style="width: 44%"><col style="width: 55%"></colgroup><thead><tr class="header"><th>名称</th><th>表达式</th></tr></thead><tbody><tr class="odd"><td>hinge损失函数</td><td><span class="math inline">\(\mathscr{l}_{hinge}(z)=\max(0,1-z)\)</span></td></tr><tr class="even"><td>指数损失函数 (exponential loss)</td><td><span class="math inline">\(\mathscr{l}_{exp}(z)=\exp(-z)\)</span></td></tr><tr class="odd"><td>对率损失 (logistic loss)</td><td><span class="math inline">\(\mathscr{l}_{log}(z)=\log(1+\exp(-z))\)</span></td></tr></tbody></table><p><img src="https://imgur.la/images/2024/06/04/surrogate_loss.png" alt="surrogate loss" border="0" style="zoom: 5%;"></p><center><p></p><p>图7：三种常见的替代损失函数: hinge损失、指数损失、对率损失</p><p></p></center></li></ul><h4 id="优化理论原问题与对偶问题">优化理论：原问题与对偶问题</h4><p><strong>1. 原问题 (Prime Problem)</strong></p><ul><li>最小化 (Minimize) : <span class="math inline">\(f(w)\)</span></li><li>限制条件 (Subject to) :<ul><li><span class="math inline">\(g_i(w)\leq0 \ \ \ \(i=1,2,\dots,K)\)</span></li><li><span class="math inline">\(h_i(w)=0 \ \ \ \(i=1,2,\dots,M)\)</span></li></ul></li></ul><p>对原问题使用拉格朗日乘子法可以得到其"对偶问题" <span class="math display">\[\begin{align}&amp;L(w,\alpha,\beta) \\=&amp;f(w)+\sum \limits_{i=1}^{K}\alpha_ig_i(w)+\sum\limits_{i=1}^{M}\beta_ih_i(w) \\=&amp;f(w)+\alpha^Tg(w)+\beta^Th(w)\end{align}\]</span> 根据您上述过程，我们可以得到原问题的对偶问题：</p><p><strong>2. 对偶问题 (Dual Problem)</strong></p><ul><li>最大化 (Maximum) : <span class="math inline">\(\theta(\alpha,\beta)=\inf\{L(w,\alpha,\beta)\}\)</span></li><li>限制条件 (Subject to) :<ul><li><span class="math inline">\(\alpha_i\geq0 \ \ \ \(i=1,2,\dots,K)\)</span></li></ul></li></ul><p><strong>解释：</strong></p><p>其中 <span class="math inline">\(\inf\{L(w,\alpha,\beta)\}\)</span>表示在限定的 <span class="math inline">\(\alpha,\beta\)</span>的条件下，遍历所有的 <span class="math inline">\(w\)</span>，求 <span class="math inline">\(L(w,\alpha,\beta)\)</span>的最小值。因此对于每确定的一组 <span class="math inline">\(\alpha,\beta\)</span> 都可以算出 <span class="math inline">\(L(w,\alpha,\beta)\)</span>的最小值。而我们此时要找的就是所有的能算出 <span class="math inline">\(L(w,\alpha,\beta)\)</span> 最小值的 <span class="math inline">\(\alpha,\beta\)</span> 中最大的那一组 <span class="math inline">\(\alpha,\beta\)</span>。</p><p><strong>3. 将原问题的解转化为对偶问题的解</strong></p><p><strong>定理：</strong>如果 <span class="math inline">\(w^*\)</span>是原问题的解，而<span class="math inline">\(\alpha^*,\beta^*\)</span>是对偶问题的解，则有<span class="math inline">\(f(w^*)\geq\theta(\alpha^*,\beta^*)\)</span></p><p>证明：(其中 <span class="math inline">\(\alpha^*\geq0, \ \g_i(w^*)\leq0, \ \ h_i(w)=0\)</span>) <span class="math display">\[\begin{align}\theta(\alpha^*,\beta^*)&amp;=\inf\{L(w,\alpha^*,\beta^*)\} \\&amp;\leq L(w^*,\alpha^*,\beta^*) \\&amp;=f(w^*)+\sum \limits_{i=1}^{K}\alpha_i^*g_i(w^*)+\sum\limits_{i=1}^{M}\beta_i^*h_i(w^*) \\&amp;\leq f(w^*)\end{align}\]</span> <strong>定义：</strong><span class="math inline">\(G=f(\omega^*)-\theta(\alpha^*,\beta^*)\geq0\)</span>,<span class="math inline">\(G\)</span> 为原问题与对偶问题的间距 (DualityGap)。</p><p><strong>强对偶定理：</strong>若 <span class="math inline">\(f(w)\)</span> 为凸函数，且 <span class="math inline">\(g(w)=aw+b, \ \ h(w)=cw+d\)</span>(即其约束条件均为线性函数), 则此优化问题得原问题与对偶问题的对偶间距<span class="math inline">\(G=0\)</span>.</p><p>由强对偶性定理得： <span class="math display">\[f(w^*)=\theta(\alpha^*,\beta^*)\]</span> 此时意味着，对于 <span class="math inline">\(\foralli=1,2,\dots,K.\)</span> 则有 <span class="math inline">\(\alpha_i^*=0\)</span> 或者 <span class="math inline">\(g_i(w^*)=0\)</span> .<strong>——KKT条件</strong></p><hr><h2 id="references">References</h2><blockquote><p>[1] 周志华，机器学习，清华大学出版社，2016</p><p>[2] Boyd S P, Vandenberghe L. Convex optimization[M]. Cambridgeuniversity press, 2004.</p><p>[3] Cortes C, Vapnik V. Support-vector networks[J]. Machine learning,1995, 20: 273-297.</p><p>[4] Ruszczyński A P. Nonlinear optimization[M]. Princeton universitypress, 2006.</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h1 id=&quot;支持向量机-support-vector-machine&quot;&gt;支持向量机 (Support Vector
Machine)&lt;/h1&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2</summary>
      
    
    
    
    
    <category term="Machine Learning" scheme="http://junlei-zhou.com/tags/Machine-Learning/"/>
    
    <category term="Supervised machine learning" scheme="http://junlei-zhou.com/tags/Supervised-machine-learning/"/>
    
    <category term="Convex optimization" scheme="http://junlei-zhou.com/tags/Convex-optimization/"/>
    
    <category term="Dural Problem" scheme="http://junlei-zhou.com/tags/Dural-Problem/"/>
    
  </entry>
  
  <entry>
    <title>markov_process</title>
    <link href="http://junlei-zhou.com/2023/12/27/markov-process/"/>
    <id>http://junlei-zhou.com/2023/12/27/markov-process/</id>
    <published>2023-12-27T09:33:42.000Z</published>
    <updated>2024-01-17T10:28:21.516Z</updated>
    
    <content type="html"><![CDATA[<h2 id="马尔可夫过程-state-probability">马尔可夫过程 (State +Probability)</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Markov_process-example.svg/2880px-Markov_process-example.svg.png" alt="undefined" style="zoom:50%;"></p><h3 id="状态state">状态（State）</h3><p><strong>定义：</strong>具有<strong>马尔可夫性质</strong>的有限随机状态序列<strong><span class="math inline">\(S_1, S_2, ......\)</span></strong></p><p>马尔可夫性质（markovproperty）：当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；</p><p><span class="math inline">\(P(S_{t+1} | S_t) = P(S_{t+1}|S_1, ...,S_t)\)</span> <strong>无后效性</strong></p><p>解释：从<span class="math inline">\(S_1, ...,S_t\)</span>所蕴含的信息与<span class="math inline">\(S_t\)</span>是等价的，当前的状态只由上一个状态所决定，而不受更早之前状态影响。</p><h3 id="转移概率transition-probability">转移概率（TransitionProbability）</h3><p>状态转移矩阵</p><p><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231228110315549.png" alt="image-20231228110315549" style="zoom:50%;"><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231228110454720.png" alt="image-20231228110454720" style="zoom:50%;"></p><h2 id="马尔可夫奖励过程state-probabilityreward">马尔可夫奖励过程（State+ Probability+Reward）</h2><p>马尔可夫过程+奖励=马尔可夫奖励过程</p><p>奖励：</p><p>即时奖励：<span class="math inline">\(R_{t+1}\)</span></p><p>其中即时奖励与状态转移相伴随： <span class="math inline">\(R_{t+1}=f(S_t \rightarrow S_{t+1})\)</span></p><p>只要发生状态转移就会产生即时奖励。</p><p>长期奖励：<span class="math inline">\(G_t\)</span></p><p><span class="math inline">\(G_t = R_{t+1}+\gamma R_{t+2}+\gamma ^2R_{t+3}+\dots=\sum \limits_{k=0}^{\infty}\gamma^kR_{t+k+1}\)</span></p><p><span class="math inline">\(\gamma:\)</span>衰减系数，表示即时奖励在当前的折扣值， <span class="math inline">\(\gamma \in [0,1]\)</span></p><p><span class="math inline">\(\gamma\)</span> 越接近0，更喜欢现在的reward；<span class="math inline">\(\gamma\)</span>越接近1， 越不关心现在已经得到的reward。</p><p>长期奖励与状态转移链相伴随， 不同的状态转移链对应不同的长期奖励。</p><p>价值函数：<span class="math inline">\(V(s)\)</span></p><p>评价状态 <span class="math inline">\(S\)</span>的质量，使用以当前状态 <span class="math inline">\(S\)</span>起点的所有状态转移链的 <span class="math inline">\(G_t\)</span>的期望来作为衡量 <span class="math inline">\(S\)</span> 的价值指标 <span class="math display">\[\begin{align}V(S)&amp;=E[G_t | S_t=S]  \\&amp;=E[R_{t+1}+\gamma R_{t+2}+\gamma ^ 2R_{t+3}+\dots | S_t = S] \\&amp;=E[R_{t+1}+(\gamma R_{t+2}+\gamma ^ 2R_{t+3}+\dots) | S_t = S] \\&amp;=E[R_{t+1}+\gamma G_{t+1} | S_t = S] \\&amp;=E[R_{t+1}+\gamma V(S_t+1) | S_t = S]\end{align}\]</span> <span class="math inline">\(V(S)\)</span>取决于前一个状态的奖励 <span class="math inline">\(R_{t+1}\)</span>，也取决于当前状态的</p><p>Bellman Equation</p><h3 id="马尔可夫决策过程-state-probability-reward-action">马尔可夫决策过程（State + Probability + Reward + Action）</h3><p>MDP 元组定义 <span class="math inline">\(\langleS,A,P,R,\gamma\rangle\)</span>：</p><p><span class="math inline">\(S\)</span> 有限状态集</p><p><span class="math inline">\(A\)</span> 有限动作集</p><p><span class="math inline">\(P\)</span> 状态转移概率矩阵， <span class="math inline">\(P_{ss&#39;}^a=P[S_{t+1}=s&#39; | S_t=s,A_t=a]\)</span></p><p><span class="math inline">\(R\)</span> 奖励函数， <span class="math inline">\(R_s^a=E[R_{t+1}|S_t=s, A_t=a]\)</span></p><p><span class="math inline">\(\gamma\)</span> 折扣函数， <span class="math inline">\(\gamma\in[0, 1]\)</span></p><p>目标：找到一条最佳路径，使得这条路径上的Reward最大</p><p>给定状态的动作概率分布（policy）：<span class="math inline">\(\pi\)</span> <span class="math display">\[\pi(a | s)=P[A_t=a|S_t=s]\]</span> 状态价值函数 <span class="math inline">\(v_{\pi}(s)\)</span><span class="math display">\[\begin{align}v_\pi(s) &amp;= E_\pi[G_t | S_t=s] \\&amp;=E_\pi[R_{t+1}+\gamma v_\pi(S_{t+1}) | S_t=s]\end{align}\]</span> 从状态 <span class="math inline">\(s\)</span> 开始，遵循policy<span class="math inline">\(\pi\)</span>，期望获得的累计奖励。</p><p>动作价值函数 <span class="math inline">\(q_\pi(s,a)\)</span> <span class="math display">\[\begin{align}q_\pi(s,a)&amp;=E_\pi [G_t|S_t=s, A_t=a] \\&amp;=E_\pi [R_{t+1}+\gamma q_\pi(S_{t+1}, A_{t+1})|S_t=s, A_t=a] \\&amp;=R_s^a+\gamma \sum \limits_{s&#39;\in S}P_{ss&#39;}^av_\pi(s&#39;)\end{align}\]</span> 从状态 <span class="math inline">\(s\)</span> 开始，执行动作<span class="math inline">\(a\)</span>, 遵循policy <span class="math inline">\(\pi\)</span> 期望获得的累计奖励。</p><p>包含动作的状态转移过程：</p><p><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231229150527704.png" alt="image-20231229150527704" style="zoom:50%;"><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231229150542970.png" alt="image-20231229150542970" style="zoom:50%;"><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231229150558157.png" alt="image-20231229150558157" style="zoom:50%;"><img src="/2023/12/27/markov-process/Users\S\AppData\Roaming\Typora\typora-user-images\image-20231229160323899.png" alt="image-20231229160323899" style="zoom:50%;"></p><p>贝尔曼期望方程求解 <span class="math inline">\(V^\pi\)</span> <span class="math display">\[v_\pi(S)=\sum \limits_{a\in A}\pi(a|s)q_\pi(s,a)\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;马尔可夫过程-state-probability&quot;&gt;马尔可夫过程 (State +
Probability)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://junlei-zhou.com/2023/12/08/hello-world/"/>
    <id>http://junlei-zhou.com/2023/12/08/hello-world/</id>
    <published>2023-12-08T12:50:07.908Z</published>
    <updated>2023-12-08T12:50:07.908Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very
first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; fo</summary>
      
    
    
    
    
  </entry>
  
</feed>
